11:02:52,151 graphrag.cli.index INFO Logging enabled at /Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/logs/indexing-engine.log
11:02:58,597 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:00,539 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:03:00,541 graphrag.cli.index INFO Starting pipeline run. dry_run=False
11:03:00,543 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
11:03:00,543 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/output
11:03:00,544 graphrag.index.input.factory INFO loading input from root_dir=input
11:03:00,544 graphrag.index.input.factory INFO using file storage for input
11:03:00,546 graphrag.storage.file_pipeline_storage INFO search /Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/input for files matching .*\.txt$
11:03:00,551 graphrag.index.input.util INFO Found 1 InputFileType.text files, loading 1
11:03:00,551 graphrag.index.input.util INFO Total number of unfiltered InputFileType.text rows: 1
11:03:00,554 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 1
11:03:00,586 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:03:00,665 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:03:00,667 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:03:00,685 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:03:06,874 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:07,830 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,830 openai._base_client INFO Retrying request to /chat/completions in 2.694000 seconds
11:03:07,831 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,832 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,832 openai._base_client INFO Retrying request to /chat/completions in 2.686000 seconds
11:03:07,833 openai._base_client INFO Retrying request to /chat/completions in 2.374000 seconds
11:03:07,838 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,839 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:07,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,855 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:07,858 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,859 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:07,864 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,865 openai._base_client INFO Retrying request to /chat/completions in 2.346000 seconds
11:03:07,879 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,880 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:08,352 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:08,446 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:08,582 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:08,596 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:08,658 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:08,698 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:08,699 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:08,877 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:08,878 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:08,938 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:08,939 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:08,950 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:08,951 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:09,14 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:09,17 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:10,66 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:10,450 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:10,451 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:10,556 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:10,556 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:10,558 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:10,558 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:10,867 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:10,868 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:10,879 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:10,883 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:12,413 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:12,790 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:12,791 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:03:12,969 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:12,971 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:13,198 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:13,198 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:13,602 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:13,616 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:13,618 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:13,931 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:13,932 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:13,936 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:13,937 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:13,938 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:13,938 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:13,960 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:13,961 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:14,126 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:14,126 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:14,296 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:14,297 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:14,405 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:14,784 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:14,786 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:14,832 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:14,882 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:15,74 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:15,175 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,176 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:15,190 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:15,202 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,203 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:15,236 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,237 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:15,424 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,424 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:03:15,518 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,519 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:15,542 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,542 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:15,543 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,543 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:15,733 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,736 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:16,74 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:16,75 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:16,90 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:16,92 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:16,752 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:16,951 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:17,106 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:17,107 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:03:17,329 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:17,330 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:03:18,154 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:18,156 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:18,524 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:18,525 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:18,890 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:18,891 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:18,986 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:18,987 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:19,182 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:19,184 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:03:19,192 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:19,194 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:19,195 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:19,197 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:19,372 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:19,374 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:19,382 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:19,383 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:19,715 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:19,717 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:20,461 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:20,491 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:20,494 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:20,534 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:20,535 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:20,579 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:20,580 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:20,811 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:20,812 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:03:20,850 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:20,852 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:20,944 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:20,945 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:20,951 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:20,952 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:21,285 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:21,286 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:21,300 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:21,301 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:21,311 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:21,312 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:21,324 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:21,325 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:21,343 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:21,349 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:03:21,567 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:21,990 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:21,992 openai._base_client INFO Retrying request to /chat/completions in 6.112000 seconds
11:03:23,109 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:23,110 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:03:23,266 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:23,266 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:23,391 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:23,392 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:03:23,912 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:23,913 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:23,914 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:23,914 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:24,97 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:24,98 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:24,432 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:24,433 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:24,628 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:24,629 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:24,857 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:24,858 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:25,144 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:25,146 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:25,147 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:25,148 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:25,517 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:25,518 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:03:25,531 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:25,532 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:25,670 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:25,671 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:26,193 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:26,193 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:26,198 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:26,198 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:26,525 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:26,527 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:26,530 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:26,531 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:26,720 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:26,722 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:26,822 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:26,823 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:03:26,926 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:26,927 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:27,111 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:27,112 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:27,280 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:27,281 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:03:27,426 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:27,427 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:28,368 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:28,369 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:28,460 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:28,460 openai._base_client INFO Retrying request to /chat/completions in 6.112000 seconds
11:03:28,861 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:28,863 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:29,150 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:29,152 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:29,165 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:29,166 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:03:29,224 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:29,225 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:29,363 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:29,365 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:03:29,681 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:29,682 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:29,910 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:29,911 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:30,88 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:30,89 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:30,530 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:30,531 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:30,548 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:30,549 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:30,737 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:30,737 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:30,912 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:30,913 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:31,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:31,444 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:31,801 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:31,802 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:31,841 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:31,842 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:03:31,963 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:31,965 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:32,141 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:32,142 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:32,488 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:32,489 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:32,493 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:32,495 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:32,842 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:32,843 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:03:32,893 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:32,893 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:33,192 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:33,193 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:03:33,540 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:33,541 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:33,563 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:33,564 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:33,884 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:33,885 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:34,206 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:34,207 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:34,534 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:34,535 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:34,906 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:34,907 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:34,927 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:34,928 openai._base_client INFO Retrying request to /chat/completions in 6.112000 seconds
11:03:35,222 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:35,222 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:35,222 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:35,223 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:03:35,408 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:35,409 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:35,409 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:35,410 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:03:35,762 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:35,762 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:35,810 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:35,811 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:35,930 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:35,931 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:36,604 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:36,605 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:36,669 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:36,670 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:37,5 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:37,6 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:37,345 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:37,347 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:37,651 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:37,651 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:38,148 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:38,149 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:38,169 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:38,169 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:03:38,207 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:38,207 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:38,651 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:38,653 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:38,688 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:38,689 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:38,830 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:38,831 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:38,853 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:38,854 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:03:39,119 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:39,120 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:03:39,311 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:39,313 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:39,683 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:39,685 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:39,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:39,851 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:40,130 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:40,131 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:40,487 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:40,488 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:40,656 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:40,656 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:40,747 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:40,748 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:40,889 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:40,890 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:41,215 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:41,216 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:03:41,304 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:41,304 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:41,380 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:41,381 openai._base_client INFO Retrying request to /chat/completions in 6.112000 seconds
11:03:41,383 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:41,383 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:03:41,773 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:41,774 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:42,229 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:42,230 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:42,427 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:42,427 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:42,564 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:42,565 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:43,339 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:43,339 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:43,796 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:43,797 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:43,797 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:43,798 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:43,799 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:43,800 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:43,919 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:43,920 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:44,350 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:44,351 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:44,494 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:44,494 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:44,501 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:44,502 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:03:44,852 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:44,853 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:03:45,45 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:45,46 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:03:45,172 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:45,173 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:45,365 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:45,366 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:45,738 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:45,739 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:45,748 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:45,749 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:45,891 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:45,892 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:45,895 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:45,896 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:46,416 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:46,417 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:46,746 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:46,748 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:46,947 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:46,948 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:47,266 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:47,268 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:03:47,462 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:47,464 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:03:47,464 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:47,465 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:47,800 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:47,801 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:47,836 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:47,837 openai._base_client INFO Retrying request to /chat/completions in 6.112000 seconds
11:03:48,219 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:48,219 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:48,744 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:48,745 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:48,896 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:48,897 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:49,38 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:49,40 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:49,392 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:49,394 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:49,458 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:49,459 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:49,636 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:49,638 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:50,285 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,287 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:50,489 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,489 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:50,613 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,615 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:50,726 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,727 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:50,836 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,837 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:03:50,854 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,855 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:03:50,955 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,956 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:03:50,988 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,989 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:51,135 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:51,136 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:51,488 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:51,489 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:52,17 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:52,18 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:52,183 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:52,184 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:52,185 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:52,185 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:52,708 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:52,709 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:53,53 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:53,54 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:53,255 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:53,255 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:03:53,455 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:53,456 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:03:53,758 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:53,760 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:53,983 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:53,985 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:54,47 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:54,49 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:54,293 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:54,293 openai._base_client INFO Retrying request to /chat/completions in 6.112000 seconds
11:03:54,443 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:54,445 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:54,822 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:54,823 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:55,166 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:55,166 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:55,352 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:55,353 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:55,709 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:55,724 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: .79155147]),\n, 2.8825456 , 1.72445091]),\n, 2.88019419, 1.65301627]),\n, 2.88195891, 1.57737666]),\n, 2.88257639, 1.50019671]),\n, 2.87738246, 1.42399342]),\n, 2.87838348, 1.34196882]),\n, 2.87819075, 1.25807283]),\n, 2.87837266, 1.17126788]),\n, 2.87954995, 1.08097403]),\n, 2.87461386, 0.99136144]),\n, 2.87753456, 0.8936161 ]),\n, 2.87862803, 0.79343685]),\n, 2.87693487, 0.69125766]),\n, 2.88278875, 0.57993285]),\n, 2.88375547, 0.4673023 ]),\n, 2.8905426 , 0.34569528]),\n, 2.89382002, 0.22104421]),\n, 2.89895922, 0.08901774]),\n]),\n, 2.84407415, 0.\n, 2.77380838, 0.\n, 2.69757572, 0.\n, 2.62431686, 0.\n, 2.54003727, 0.\n, 2.45326688, 0.\n, 2.3624031, 0.\n, 2.26654779, 0.\n, 2.16159776, 0.\n, 2.05106895, 0.\n, 1.93251455, 0.\n, 1.80075548, 0.\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n])]\n不难看出，在对鸢尾花数据集的二、三分类的子数据集进行分类时，仍然还是第三个特征\n会相对重要，因此我们根据上述结果，构建一个正则化项为l1、C取值为0.2的逻辑回归模\n型进行训练，此时由于其他三个特征的参数都被归零，因此该模型训练过程实际上就相当\n于带入第三个特征进行建模：\nIn [69]:\nIn [71]:\nOut[71]:\nIn [72]:\nOut[72]:\nclf = LogisticRegression(penalty=\'l1\', C=0.2, max_iter=int(1e6), solver=\'saga\').\nclf.coef_, clf.intercept_\n(array([[0.\n, 0.\narray([-13.88186328]))\nclf.score(X, y)\n0.93\n, 2.84518611, 0.\n]]),\n\n此时模型准确率为93%，同样，如果构建一个只包含第三、四个特征的特征空间，此时上\n述逻辑回归建模结果的决策边界为x=b，其中b的取值如下：\nIn [75]:\nOut[75]:\nb = 13.88186328 / 2.84518611\nb\n4.87907038179657\n我们可以通过可视化的方法观察此时特征空间中样本分布情况，以及x=b的决策边界的分\n类效果：\nIn [84]:\nplt.plot(X[:, 2][y==1], X[:, 3][y==1], \'ro\')\nplt.plot(X[:, 2][y==2], X[:, 3][y==2], \'bo\')\nplt.plot(np.array([b]*20), np.arange(0.5, 2.5, 0.1), \'r--\')\nOut[84]:\n[<matplotlib.lines.Line2D at 0x7ffb992d39a0>]\nIn [80]:\nIn [79]:\nOut[79]:\n当然，我们也可以简单验算下x=b的决策边界是否是模型真实的分类边界：\ny_pred = clf.predict(X)\nplt.scatter(X[:, 2], X[:, 3], c=y_pred)\nplt.plot(np.array([b]*20), np.arange(0.5, 2.5, 0.1), \'r--\')\n[<matplotlib.lines.Line2D at 0x7ffbab00c4c0>]\n\n注意，在确定第一个分类条件时我们没有直接根据逻辑回归的线性方程计算\n决策边界的主要原因是彼时逻辑回归方程是在mvm分类规则下的三个分类\n方程，其中每个方程其实都会一定程度上受到其他方程影响，导致决策边界\n无法直接通过方程系数进行计算。\n尽管x=b分类边界的准确率不足100%，但其仍然不失为一个不错的分类规则，即分类条\n件为petal length (cm) <=\n######################\nOutput:', 'kwargs': {}}
11:03:55,724 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 30000, Requested 2319. Please try again in 4.638s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:03:55,727 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ".79155147]),\n, 2.8825456 , 1.72445091]),\n, 2.88019419, 1.65301627]),\n, 2.88195891, 1.57737666]),\n, 2.88257639, 1.50019671]),\n, 2.87738246, 1.42399342]),\n, 2.87838348, 1.34196882]),\n, 2.87819075, 1.25807283]),\n, 2.87837266, 1.17126788]),\n, 2.87954995, 1.08097403]),\n, 2.87461386, 0.99136144]),\n, 2.87753456, 0.8936161 ]),\n, 2.87862803, 0.79343685]),\n, 2.87693487, 0.69125766]),\n, 2.88278875, 0.57993285]),\n, 2.88375547, 0.4673023 ]),\n, 2.8905426 , 0.34569528]),\n, 2.89382002, 0.22104421]),\n, 2.89895922, 0.08901774]),\n]),\n, 2.84407415, 0.\n, 2.77380838, 0.\n, 2.69757572, 0.\n, 2.62431686, 0.\n, 2.54003727, 0.\n, 2.45326688, 0.\n, 2.3624031, 0.\n, 2.26654779, 0.\n, 2.16159776, 0.\n, 2.05106895, 0.\n, 1.93251455, 0.\n, 1.80075548, 0.\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n])]\n不难看出，在对鸢尾花数据集的二、三分类的子数据集进行分类时，仍然还是第三个特征\n会相对重要，因此我们根据上述结果，构建一个正则化项为l1、C取值为0.2的逻辑回归模\n型进行训练，此时由于其他三个特征的参数都被归零，因此该模型训练过程实际上就相当\n于带入第三个特征进行建模：\nIn [69]:\nIn [71]:\nOut[71]:\nIn [72]:\nOut[72]:\nclf = LogisticRegression(penalty='l1', C=0.2, max_iter=int(1e6), solver='saga').\nclf.coef_, clf.intercept_\n(array([[0.\n, 0.\narray([-13.88186328]))\nclf.score(X, y)\n0.93\n, 2.84518611, 0.\n]]),\n\n此时模型准确率为93%，同样，如果构建一个只包含第三、四个特征的特征空间，此时上\n述逻辑回归建模结果的决策边界为x=b，其中b的取值如下：\nIn [75]:\nOut[75]:\nb = 13.88186328 / 2.84518611\nb\n4.87907038179657\n我们可以通过可视化的方法观察此时特征空间中样本分布情况，以及x=b的决策边界的分\n类效果：\nIn [84]:\nplt.plot(X[:, 2][y==1], X[:, 3][y==1], 'ro')\nplt.plot(X[:, 2][y==2], X[:, 3][y==2], 'bo')\nplt.plot(np.array([b]*20), np.arange(0.5, 2.5, 0.1), 'r--')\nOut[84]:\n[<matplotlib.lines.Line2D at 0x7ffb992d39a0>]\nIn [80]:\nIn [79]:\nOut[79]:\n当然，我们也可以简单验算下x=b的决策边界是否是模型真实的分类边界：\ny_pred = clf.predict(X)\nplt.scatter(X[:, 2], X[:, 3], c=y_pred)\nplt.plot(np.array([b]*20), np.arange(0.5, 2.5, 0.1), 'r--')\n[<matplotlib.lines.Line2D at 0x7ffbab00c4c0>]\n\n注意，在确定第一个分类条件时我们没有直接根据逻辑回归的线性方程计算\n决策边界的主要原因是彼时逻辑回归方程是在mvm分类规则下的三个分类\n方程，其中每个方程其实都会一定程度上受到其他方程影响，导致决策边界\n无法直接通过方程系数进行计算。\n尽管x=b分类边界的准确率不足100%，但其仍然不失为一个不错的分类规则，即分类条\n件为petal length (cm) <="}
11:03:55,855 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:55,855 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:55,867 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:55,867 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:56,75 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:56,77 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:56,88 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:56,89 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:56,243 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:56,244 openai._base_client INFO Retrying request to /chat/completions in 4.854000 seconds
11:03:56,382 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:56,383 openai._base_client INFO Retrying request to /chat/completions in 4.714000 seconds
11:03:56,544 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:56,546 openai._base_client INFO Retrying request to /chat/completions in 4.360000 seconds
11:03:56,902 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:56,904 openai._base_client INFO Retrying request to /chat/completions in 4.998000 seconds
11:03:56,905 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:56,906 openai._base_client INFO Retrying request to /chat/completions in 4.930000 seconds
11:03:57,238 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:57,239 openai._base_client INFO Retrying request to /chat/completions in 4.942000 seconds
11:03:57,426 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:57,429 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 会计算父节点的基尼系数（Gini(A)），然后计算划分出的\n两个子节点整体基尼系数（Gini(B)），然后通过对比哪种划分方式能够让二者差值更大，\n即能够让子节点的基尼系数下降更快，我们就选用哪个规则。例如对上述例子，我们知道\n在以income <= 1.5为规则划分数据集时，基尼系数下降结果为：\nIn [14]:\nOut[14]:\ngini_A - gini_B\n0.16875\n而如果采用第二个划分规则来进行数据集切分，则此时基尼系数下降结果为：\nIn [15]:\np = 3/4\ngini_B2 = 1 - np.power([p, 1-p], 2).sum()\ngini_B2\nOut[15]:\nIn [16]:\nIn [17]:\nOut[17]:\nIn [18]:\nOut[18]:\n0.375\ngini_B1 = 0\ngini_B = gini_B1 * 1/2 + gini_B2 * 1/2\ngini_B\n0.1875\ngini_A - gini_B\n0.28125\n很明显，第二个规则能够让父节点的基尼系数下降更快，因此第二个规则、即\ncredit_rating <= 1.5划分规则是一个更好的规则，在第一次数据集划分时我们应该采用\n该规则。\n注，如果是ID3或者C4.5，此处则是以信息熵计算结果为准。\n1.4 决策树的生长过程\n当完成一次规则筛选与树生长后，接下来需要考虑的问题是，面对当前划分出的数据\n集B1、B2，是否还需要进一步寻找分类规则对其进行划分。\n1\n\n首先，对于数据集B1来说，由于其基尼系数已经为0，无需再进行计算；而B2数据集\n基尼系数为0.375，还可以进一步提取有效分类规则对其进行分类，以降低其基尼系数。\n此时我们又可以完全重复数据集A的划分过程，首先围绕数据集B2进行备选规则的提取，\n对于B2来说备选规则只有income <= 1.5一条，因此我们就以该规则划分数据集：\n1\n能够看出，最终划分出来的C1和C2基尼系数都是0，因此C的两个数据集整体基尼系数也\n是0，当然我们也无需进一步划分数据集，到此为止决策树也停止生长。\n决策树生长与迭代运算\n此前我们说到，决策树的生长过程本质上也是在进行迭代运算，我们根据上一轮的到\n的结论（数据集划分情况）作为基础条件，来寻找子数据集的最佳分类规则，然后来进行\n数据集划分，以此往复。既然是迭代运算，那就必然需要讨论所有迭代运算都需要考虑的\n两个问题，其一是每一轮的迭代目标、其二是迭代收敛条件。\n首先是每一轮迭代计算的目标，在梯度下降的计算过程中，每一轮迭代其实都是为了\n能够更大程度上降低损失函数值，在K-Means快速聚类中，每一轮迭代其实都是为了能够\n尽快降低组内误差平方和（SSE），而在决策树的建模过程中，每一轮迭代实际上是为了\n更快速的降低基尼系数，也就是希望这一轮划分出来的子数据集纯度尽可能高，从而说明\n该规则会对分类更加有效。因此如果我们可以将每一轮迭代过程中父类的基尼系数看成是\n损失函数值，树的迭代生长过程就是为了能够更快速的降低父类的基尼系数值。\n其次就是迭代计算的收敛条件。对于此前我们所介\n######################\nOutput:', 'kwargs': {}}
11:03:57,430 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29422, Requested 2409. Please try again in 3.662s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:03:57,433 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '会计算父节点的基尼系数（Gini(A)），然后计算划分出的\n两个子节点整体基尼系数（Gini(B)），然后通过对比哪种划分方式能够让二者差值更大，\n即能够让子节点的基尼系数下降更快，我们就选用哪个规则。例如对上述例子，我们知道\n在以income <= 1.5为规则划分数据集时，基尼系数下降结果为：\nIn [14]:\nOut[14]:\ngini_A - gini_B\n0.16875\n而如果采用第二个划分规则来进行数据集切分，则此时基尼系数下降结果为：\nIn [15]:\np = 3/4\ngini_B2 = 1 - np.power([p, 1-p], 2).sum()\ngini_B2\nOut[15]:\nIn [16]:\nIn [17]:\nOut[17]:\nIn [18]:\nOut[18]:\n0.375\ngini_B1 = 0\ngini_B = gini_B1 * 1/2 + gini_B2 * 1/2\ngini_B\n0.1875\ngini_A - gini_B\n0.28125\n很明显，第二个规则能够让父节点的基尼系数下降更快，因此第二个规则、即\ncredit_rating <= 1.5划分规则是一个更好的规则，在第一次数据集划分时我们应该采用\n该规则。\n注，如果是ID3或者C4.5，此处则是以信息熵计算结果为准。\n1.4 决策树的生长过程\n当完成一次规则筛选与树生长后，接下来需要考虑的问题是，面对当前划分出的数据\n集B1、B2，是否还需要进一步寻找分类规则对其进行划分。\n1\n\n首先，对于数据集B1来说，由于其基尼系数已经为0，无需再进行计算；而B2数据集\n基尼系数为0.375，还可以进一步提取有效分类规则对其进行分类，以降低其基尼系数。\n此时我们又可以完全重复数据集A的划分过程，首先围绕数据集B2进行备选规则的提取，\n对于B2来说备选规则只有income <= 1.5一条，因此我们就以该规则划分数据集：\n1\n能够看出，最终划分出来的C1和C2基尼系数都是0，因此C的两个数据集整体基尼系数也\n是0，当然我们也无需进一步划分数据集，到此为止决策树也停止生长。\n决策树生长与迭代运算\n此前我们说到，决策树的生长过程本质上也是在进行迭代运算，我们根据上一轮的到\n的结论（数据集划分情况）作为基础条件，来寻找子数据集的最佳分类规则，然后来进行\n数据集划分，以此往复。既然是迭代运算，那就必然需要讨论所有迭代运算都需要考虑的\n两个问题，其一是每一轮的迭代目标、其二是迭代收敛条件。\n首先是每一轮迭代计算的目标，在梯度下降的计算过程中，每一轮迭代其实都是为了\n能够更大程度上降低损失函数值，在K-Means快速聚类中，每一轮迭代其实都是为了能够\n尽快降低组内误差平方和（SSE），而在决策树的建模过程中，每一轮迭代实际上是为了\n更快速的降低基尼系数，也就是希望这一轮划分出来的子数据集纯度尽可能高，从而说明\n该规则会对分类更加有效。因此如果我们可以将每一轮迭代过程中父类的基尼系数看成是\n损失函数值，树的迭代生长过程就是为了能够更快速的降低父类的基尼系数值。\n其次就是迭代计算的收敛条件。对于此前我们所介'}
11:03:57,546 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:57,547 openai._base_client INFO Retrying request to /chat/completions in 3.668000 seconds
11:03:57,778 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:57,779 openai._base_client INFO Retrying request to /chat/completions in 3.168000 seconds
11:03:57,951 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:57,953 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: cv=10)\n...\n# doctest: +SKIP\n...\narray([ 1.\n, 0.93..., 0.86..., 0.93..., 0.93...,\n0.93..., 0.93..., 1.\n, 0.93..., 1.\n])\n\nFile:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\ns.py\nType:\nSubclasses:\nName\ncriterion\nsplitter\nmax_depth\nmin_samples_split\nmin_samples_leaf\nmin_weight_fraction_leaf\nmax_features\nrandom_state\nmax_leaf_nodes\nmin_impurity_decrease\nmin_impurity_split\nclass_weight\npresort\nccp_alpha\nABCMeta\nExtraTreeClassifier\nDescription\n规则评估指标或损失函数，默认基尼系数，可选信息熵\n树模型生长方式，默认以损失函数取值减少最快方式生长，可选\n随机根据某条件进行划分\n树的最大生长深度，类似max_iter，即总共迭代几次\n内部节点再划分所需最小样本数\n叶节点包含最少样本数\n叶节点所需最小权重和\n在进行切分时候最多带入多少个特征进行划分规则挑选\n随机数种子\n叶节点最大个数\n数据集再划分至少需要降低的损失值\n数据集再划分所需最低不纯度，将在0.25版本中移除\n各类样本权重\n已在0.24版本中移除\n在执行CART树原生原理中的剪枝流程时结构复杂度惩罚因子的\n系数，默认情况下不使用该方法进行剪枝\n接下来围绕一些重点参数进行详细讲解：\ncriterion：不纯度衡量指标\n首先，我们发现尽管sklearn的树模型在默认情况下是CART树，但同样支持使用信息\n熵来衡量不纯度。不过需要注意的是，哪怕我们在criterion参数中选择信息熵，实际树模\n型的建模过程也不是按照ID3或者C4.5的流程执行，此时的树模型只能算是一种混合模\n型。而关于到底应该选择哪个指标来衡量数据集的不纯度，其实大多数情况下选择哪个指\n标并不会实质影响树模型的结构，但相比信息熵，基尼系数复杂度更低、计算速度更快，\n一般情况下推荐使用基尼系数。而如果一定要寻找二者在使用上的不同，一般认为在有些\n情况下，基尼不纯度更倾向于在数据集中分割出多数类，而信息熵则更倾向于生成出更加\n平衡的树。\nccp_alpha：结构风险权重\nccp是复杂度剪枝（Cost-Complexity Pruning）的简称，这是一个在sklearn的0.22\n版本中才加入的参数，这也是唯一一个为实现CART原生原理中的剪枝过程所设置的参\n数。此处首先需要知道的是在sklearn中并不一定要通过该方法进行剪枝，因此该参数其\n实也并不是一个必选参数。其次，带有ccp项的剪枝也被称为最小复杂度剪枝，其原理是\n在决策树的损失函数上加上一个结构风险项，类似于正则化项在线性方程的损失函数中作\n\n用相同。\n我们可以设T为某决策树， 为决策树在训练集上整体不纯度，即代表模型的经验\n风险，令 表示模型结构风险，其中 为参数， 为树的叶节点数量，则我们可以修\n改模型损失函数如下：\nR(T)\nα| ˜T|\nα\n| ˜T|\nRα(T) = R(T) + α| ˜T|\n其中Rα(T)就是加入风险结构项后的损失函数，而α则是风险结构项的系数。由此可\n知， 取值越大、对模型的结构风险惩罚力度就越大、模型结构就越\n######################\nOutput:', 'kwargs': {}}
11:03:57,953 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29136, Requested 2432. Please try again in 3.136s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:03:57,955 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'cv=10)\n...\n# doctest: +SKIP\n...\narray([ 1.\n, 0.93..., 0.86..., 0.93..., 0.93...,\n0.93..., 0.93..., 1.\n, 0.93..., 1.\n])\n\nFile:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\ns.py\nType:\nSubclasses:\nName\ncriterion\nsplitter\nmax_depth\nmin_samples_split\nmin_samples_leaf\nmin_weight_fraction_leaf\nmax_features\nrandom_state\nmax_leaf_nodes\nmin_impurity_decrease\nmin_impurity_split\nclass_weight\npresort\nccp_alpha\nABCMeta\nExtraTreeClassifier\nDescription\n规则评估指标或损失函数，默认基尼系数，可选信息熵\n树模型生长方式，默认以损失函数取值减少最快方式生长，可选\n随机根据某条件进行划分\n树的最大生长深度，类似max_iter，即总共迭代几次\n内部节点再划分所需最小样本数\n叶节点包含最少样本数\n叶节点所需最小权重和\n在进行切分时候最多带入多少个特征进行划分规则挑选\n随机数种子\n叶节点最大个数\n数据集再划分至少需要降低的损失值\n数据集再划分所需最低不纯度，将在0.25版本中移除\n各类样本权重\n已在0.24版本中移除\n在执行CART树原生原理中的剪枝流程时结构复杂度惩罚因子的\n系数，默认情况下不使用该方法进行剪枝\n接下来围绕一些重点参数进行详细讲解：\ncriterion：不纯度衡量指标\n首先，我们发现尽管sklearn的树模型在默认情况下是CART树，但同样支持使用信息\n熵来衡量不纯度。不过需要注意的是，哪怕我们在criterion参数中选择信息熵，实际树模\n型的建模过程也不是按照ID3或者C4.5的流程执行，此时的树模型只能算是一种混合模\n型。而关于到底应该选择哪个指标来衡量数据集的不纯度，其实大多数情况下选择哪个指\n标并不会实质影响树模型的结构，但相比信息熵，基尼系数复杂度更低、计算速度更快，\n一般情况下推荐使用基尼系数。而如果一定要寻找二者在使用上的不同，一般认为在有些\n情况下，基尼不纯度更倾向于在数据集中分割出多数类，而信息熵则更倾向于生成出更加\n平衡的树。\nccp_alpha：结构风险权重\nccp是复杂度剪枝（Cost-Complexity Pruning）的简称，这是一个在sklearn的0.22\n版本中才加入的参数，这也是唯一一个为实现CART原生原理中的剪枝过程所设置的参\n数。此处首先需要知道的是在sklearn中并不一定要通过该方法进行剪枝，因此该参数其\n实也并不是一个必选参数。其次，带有ccp项的剪枝也被称为最小复杂度剪枝，其原理是\n在决策树的损失函数上加上一个结构风险项，类似于正则化项在线性方程的损失函数中作\n\n用相同。\n我们可以设T为某决策树， 为决策树在训练集上整体不纯度，即代表模型的经验\n风险，令 表示模型结构风险，其中 为参数， 为树的叶节点数量，则我们可以修\n改模型损失函数如下：\nR(T)\nα| ˜T|\nα\n| ˜T|\nRα(T) = R(T) + α| ˜T|\n其中Rα(T)就是加入风险结构项后的损失函数，而α则是风险结构项的系数。由此可\n知， 取值越大、对模型的结构风险惩罚力度就越大、模型结构就越'}
11:03:58,152 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:58,153 openai._base_client INFO Retrying request to /chat/completions in 3.832000 seconds
11:03:58,277 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:58,278 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 决策树之后，我们也能够对一个树模型的内部结构来进行说明。\n对上述决策树来说，我们可以将其看成是点（数据集）和线构成的一个图结构（准确来说\n应该是一种有向无环图），而对于任何一个图结构，我们都能够通过点和线来构建对其的\n基本认知，对于决策树来说，我们主要将借助边的方向来定义不同类型点，首先我们知道\n如果一条边从A点引向B点，则我们这条边对于A点来说是出边、对于B点来说是入边，A\n节点是B节点的父节点，据此我们可以将决策树中所有的点进行如下类别划分：\n(1)根节点（root node）：没有入边，但有零条或者多条出边的点；\n(2)内部点（internal node）：只有一条入边并且有两条或多条出边的点；\n(3)叶节点（leaf node）：只有入边但没有出边的点；\n因此，我们知道在一次次划分数据集的过程中，原始的完整数据集对应着决策树的根\n节点，而根结点划分出的子数据集就构成了决策树中的内部节点，同时迭代停止的时候所\n对应的数据集，其实就是决策树中的叶节点。并且在上述二叉树（每一层只有两个分支）\n中，一个父节点对应两个子节点。并且根据上述决策树的建模过程不难理解，其实每个数\n据集都是由一系列分类规则最终划分出来的，我们也可以理解成每个节点其实都对应着一\n系列分类规则，例如上述E节点实际上就是petal length (cm) <= 2.5和petal length\n(cm) <= 4.879同时为False时划分出来的数据集。\n在了解决策树的一般建模过程和模型本质后，接下来我们来简单说明一下目前树模型\n的主流派系，然后详细讨论目前最通用的机器学习流派的决策树模型的建模过程。\n二、决策树的分类与流派\n正如此前所说，树模型并不是一个模型，而是一类模型。需要知道的是，尽管树模型\n的核心思想都是源于一种名为贪心算法的局部最优求解算法，但时至今日，树模型已经有\n数十种之多，并且划分为多个流派。目前主流的机器学习算法类别可划分如下：\nID3(Iterative Dichotomiser 3) 、C4.5、C5.0决策树\n是最为经典的决策树算法、同时也是真正将树模型发扬光大的一派算法。最早的ID3\n决策树由Ross Quinlan在1975年（博士毕业论文中）提出，至此也奠定了现在决策树算\n法的基本框架——确定分类规则判别指标、寻找能够最快速降低信息熵的方式进行数据集\n划分（分类规则提取），不断迭代直至收敛；而C4.5则是ID3的后继者，C4.5在ID3的基\n础上补充了一系列基础概念、同时也优化了决策树的算法流程，一方面使得现在的树模型\n\n能够处理连续变量（此前的ID3只能处理分类变量），同时也能够一定程度提高树模型的\n生长速度，而C4.5也是目前最为通用的决策树模型的一般框架，后续尽管有其他的决策树\n模型诞生，但大都是在C4.5的基本流程上进行略微调整或者指标修改，甚至在C4.5还被\nIEEE评为10大数据\n######################\nOutput:', 'kwargs': {}}
11:03:58,278 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28976, Requested 2429. Please try again in 2.81s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:03:58,279 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '决策树之后，我们也能够对一个树模型的内部结构来进行说明。\n对上述决策树来说，我们可以将其看成是点（数据集）和线构成的一个图结构（准确来说\n应该是一种有向无环图），而对于任何一个图结构，我们都能够通过点和线来构建对其的\n基本认知，对于决策树来说，我们主要将借助边的方向来定义不同类型点，首先我们知道\n如果一条边从A点引向B点，则我们这条边对于A点来说是出边、对于B点来说是入边，A\n节点是B节点的父节点，据此我们可以将决策树中所有的点进行如下类别划分：\n(1)根节点（root node）：没有入边，但有零条或者多条出边的点；\n(2)内部点（internal node）：只有一条入边并且有两条或多条出边的点；\n(3)叶节点（leaf node）：只有入边但没有出边的点；\n因此，我们知道在一次次划分数据集的过程中，原始的完整数据集对应着决策树的根\n节点，而根结点划分出的子数据集就构成了决策树中的内部节点，同时迭代停止的时候所\n对应的数据集，其实就是决策树中的叶节点。并且在上述二叉树（每一层只有两个分支）\n中，一个父节点对应两个子节点。并且根据上述决策树的建模过程不难理解，其实每个数\n据集都是由一系列分类规则最终划分出来的，我们也可以理解成每个节点其实都对应着一\n系列分类规则，例如上述E节点实际上就是petal length (cm) <= 2.5和petal length\n(cm) <= 4.879同时为False时划分出来的数据集。\n在了解决策树的一般建模过程和模型本质后，接下来我们来简单说明一下目前树模型\n的主流派系，然后详细讨论目前最通用的机器学习流派的决策树模型的建模过程。\n二、决策树的分类与流派\n正如此前所说，树模型并不是一个模型，而是一类模型。需要知道的是，尽管树模型\n的核心思想都是源于一种名为贪心算法的局部最优求解算法，但时至今日，树模型已经有\n数十种之多，并且划分为多个流派。目前主流的机器学习算法类别可划分如下：\nID3(Iterative Dichotomiser 3) 、C4.5、C5.0决策树\n是最为经典的决策树算法、同时也是真正将树模型发扬光大的一派算法。最早的ID3\n决策树由Ross Quinlan在1975年（博士毕业论文中）提出，至此也奠定了现在决策树算\n法的基本框架——确定分类规则判别指标、寻找能够最快速降低信息熵的方式进行数据集\n划分（分类规则提取），不断迭代直至收敛；而C4.5则是ID3的后继者，C4.5在ID3的基\n础上补充了一系列基础概念、同时也优化了决策树的算法流程，一方面使得现在的树模型\n\n能够处理连续变量（此前的ID3只能处理分类变量），同时也能够一定程度提高树模型的\n生长速度，而C4.5也是目前最为通用的决策树模型的一般框架，后续尽管有其他的决策树\n模型诞生，但大都是在C4.5的基本流程上进行略微调整或者指标修改，甚至在C4.5还被\nIEEE评为10大数据'}
11:03:58,324 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:58,324 openai._base_client INFO Retrying request to /chat/completions in 2.620000 seconds
11:03:58,625 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:58,626 openai._base_client INFO Retrying request to /chat/completions in 2.468000 seconds
11:03:58,712 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:58,714 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: ]:\nax = plt.gca()\nax.plot(C_l, coef_l)\nax.set_xlim(ax.get_xlim()[::-1])\nplt.xlabel(\'C\')\nplt.ylabel(\'weights\')\nOut[68]:\nText(0, 0.5, \'weights\')\n\nIn [67]:\ncoef_l\n\nOut[67]:\n[array([-1.12493251, -0.96058774, 3.23208646, 4.18486998]),\narray([-1.10210628, -0.91621566, 3.23983307, 4.15696154]),\narray([-1.09239629, -0.89555328, 3.23399288, 4.13377003]),\narray([-1.08811789, -0.88498435, 3.22207551, 4.11256892]),\narray([-1.06705294, -0.84236856, 3.2289702 , 4.08417288]),\narray([-1.05818676, -0.82271916, 3.22212123, 4.06049626]),\narray([-1.04514314, -0.79483425, 3.22012176, 4.034832 ]),\narray([-1.03859953, -0.77953758, 3.21025372, 4.01174608]),\narray([-1.02237904, -0.74473771, 3.21227469, 3.98396209]),\narray([-1.01620836, -0.73001684, 3.20160007, 3.96062442]),\narray([-0.99903143, -0.69243737, 3.20521982, 3.9315887 ]),\narray([-0.98882191, -0.66904752, 3.19966674, 3.90573051]),\narray([-0.97415883, -0.63587402, 3.2003062 , 3.87718618]),\narray([-0.96452518, -0.61330431, 3.19380232, 3.8510462 ]),\narray([-0.95257941, -0.58551283, 3.19060737, 3.8232743 ]),\narray([-0.9405302 , -0.55717711, 3.18755498, 3.79513594]),\narray([-0.92797551, -0.52743767, 3.18526488, 3.76634082]),\narray([-0.92072072, -0.50938749, 3.17475278, 3.74036246]),\narray([-0.90510269, -0.47211112, 3.17719028, 3.70899839]),\narray([-0.89009202, -0.43569901, 3.1788934 , 3.67756566]),\narray([-0.87766924, -0.4050523 , 3.17640578, 3.64738615]),\narray([-0.87286899, -0.39228757, 3.16090415, 3.62179933]),\narray([-0.85425355, -0.34619248, 3.16885758, 3.58676224]),\narray([-0.84887206, -0.33207553, 3.15364443, 3.56032998]),\narray([-0.83147761, -0.28802875, 3.15964514, 3.52515956]),\narray([-0.81352053, -0.24176251, 3.16723112, 3.4889317 ]),\narray([-0.80378813, -0.21608039, 3.15931029, 3.45833305]),\narray([-0.7917758 , -0.1843569 , 3.15554737, 3.42568574]),\narray([-0.7759623 , -0.14232637, 3.15919161, 3.38962502]),\narray([-0.76332702, -0.10825391, 3.15647641, 3.35556836]),\narray([-0.74997069, -0.07184156, 3.15520495, 3.32047552]),\narray([-0.73849732, -0.04031354, 3.14976963, 3.28653383]),\narray([-0.72392909, 0.\n, 3.15076775, 3.24952256]),\narray([-0.72367263, 0.\narray([-0.71773131, 0.\narray([-0.72374493, 0.\narray([-0.7173857 , 0.\narray([-0.70523493, 0.\narray([-0.69782327, 0.\narray([-0.69307433, 0.\narray([-0.65156996, 0.\narray([-0.61274879, 0.\narray([-0.58509755, 0.\n, 3.12039086, 3.22470745]),\n, 3.09818066, 3.19766659]),\n, 3.05891014, 3.1747754 ]),\n, 3.03697755, 3.14715043]),\n, 3.02056866, 3.11785887]),\n,\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:03:58,714 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28763, Requested 2299. Please try again in 2.124s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:03:58,716 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "]:\nax = plt.gca()\nax.plot(C_l, coef_l)\nax.set_xlim(ax.get_xlim()[::-1])\nplt.xlabel('C')\nplt.ylabel('weights')\nOut[68]:\nText(0, 0.5, 'weights')\n\nIn [67]:\ncoef_l\n\nOut[67]:\n[array([-1.12493251, -0.96058774, 3.23208646, 4.18486998]),\narray([-1.10210628, -0.91621566, 3.23983307, 4.15696154]),\narray([-1.09239629, -0.89555328, 3.23399288, 4.13377003]),\narray([-1.08811789, -0.88498435, 3.22207551, 4.11256892]),\narray([-1.06705294, -0.84236856, 3.2289702 , 4.08417288]),\narray([-1.05818676, -0.82271916, 3.22212123, 4.06049626]),\narray([-1.04514314, -0.79483425, 3.22012176, 4.034832 ]),\narray([-1.03859953, -0.77953758, 3.21025372, 4.01174608]),\narray([-1.02237904, -0.74473771, 3.21227469, 3.98396209]),\narray([-1.01620836, -0.73001684, 3.20160007, 3.96062442]),\narray([-0.99903143, -0.69243737, 3.20521982, 3.9315887 ]),\narray([-0.98882191, -0.66904752, 3.19966674, 3.90573051]),\narray([-0.97415883, -0.63587402, 3.2003062 , 3.87718618]),\narray([-0.96452518, -0.61330431, 3.19380232, 3.8510462 ]),\narray([-0.95257941, -0.58551283, 3.19060737, 3.8232743 ]),\narray([-0.9405302 , -0.55717711, 3.18755498, 3.79513594]),\narray([-0.92797551, -0.52743767, 3.18526488, 3.76634082]),\narray([-0.92072072, -0.50938749, 3.17475278, 3.74036246]),\narray([-0.90510269, -0.47211112, 3.17719028, 3.70899839]),\narray([-0.89009202, -0.43569901, 3.1788934 , 3.67756566]),\narray([-0.87766924, -0.4050523 , 3.17640578, 3.64738615]),\narray([-0.87286899, -0.39228757, 3.16090415, 3.62179933]),\narray([-0.85425355, -0.34619248, 3.16885758, 3.58676224]),\narray([-0.84887206, -0.33207553, 3.15364443, 3.56032998]),\narray([-0.83147761, -0.28802875, 3.15964514, 3.52515956]),\narray([-0.81352053, -0.24176251, 3.16723112, 3.4889317 ]),\narray([-0.80378813, -0.21608039, 3.15931029, 3.45833305]),\narray([-0.7917758 , -0.1843569 , 3.15554737, 3.42568574]),\narray([-0.7759623 , -0.14232637, 3.15919161, 3.38962502]),\narray([-0.76332702, -0.10825391, 3.15647641, 3.35556836]),\narray([-0.74997069, -0.07184156, 3.15520495, 3.32047552]),\narray([-0.73849732, -0.04031354, 3.14976963, 3.28653383]),\narray([-0.72392909, 0.\n, 3.15076775, 3.24952256]),\narray([-0.72367263, 0.\narray([-0.71773131, 0.\narray([-0.72374493, 0.\narray([-0.7173857 , 0.\narray([-0.70523493, 0.\narray([-0.69782327, 0.\narray([-0.69307433, 0.\narray([-0.65156996, 0.\narray([-0.61274879, 0.\narray([-0.58509755, 0.\n, 3.12039086, 3.22470745]),\n, 3.09818066, 3.19766659]),\n, 3.05891014, 3.1747754 ]),\n, 3.03697755, 3.14715043]),\n, 3.02056866, 3.11785887]),\n,"}
11:03:59,65 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,66 openai._base_client INFO Retrying request to /chat/completions in 2.824000 seconds
11:03:59,161 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,165 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 如此一来便更加容易造成模型过拟合，而遗憾的是\nID3并没有任何防止过拟合的措施。而这些ID3的缺陷，则正是C4.5算法的改进方向。接\n下来我们继续讨论关于C4.5决策树的建模规则。\n当然，对于ID3来说，规则是和分类变量的取值一一绑定的，\n二、C4.5决策树的基本建模流程\n作为ID3的改进版算法，C4.5在ID3的基础上进行了三个方面的优化，首先在衡量不\n纯度降低的数值计算过程中引入信息值（information value，也被称为划分信息度、分\n支度等）概念来修正信息熵的计算结果，以抑制ID3更倾向于寻找分类水平较多的列来展\n开的情况，从而间接抑制模型过拟合倾向；其二则是新增了连续变量的处理方法，也就是\nCART树中寻找相邻取值的中间值作为切分点的方法；其三是加入了决策树的剪枝流程，\n使得模型泛化能力能够得到进一步提升。但需要注意的是，尽管有如此改进，但C4.5仍然\n只能解决分类问题，其本质仍然还是一种分类树。接下来我们详细讨论C4.5的具体改进策\n略。\n信息值（information value）\nC4.5中信息值（以下简称IV值）是一个用于衡量数据集在划分时分支个数的指标，如\n果划分时分支越多，IV值就越高。具体IV值的计算公式如下：\nK\nInformation Value = −\n∑\ni=1\nP(vi)log2P(vi)\n\nIV值计算公式和信息熵的计算公式基本一致，只是具体计算的比例不再是各\n类样本所占比例，而是各划分后子节点的数据所占比例，或者说信息熵是计\n算标签不同取值的混乱程度，而IV值就是计算特征不同取值的混乱程度\n其中K表示某次划分是总共分支个数， 表示划分后的某样本， 表示该样本数量占\n父节点数据量的比例。对于如下三种数据集划分情况，简单计算IV值：\nvi\nIn [28]:\nOut[28]:\nIn [31]:\nOut[31]:\nIn [32]:\nOut[32]:\n# 父节点按照50%-50%进行划分\n- (1/2 * np.log2(1/2) + 1/2 * np.log2(1/2))\n1.0\n# 父节点按照1/4-1/2-1/4进行划分\n- (1/4 * np.log2(1/4) + 1/2 * np.log2(1/2)+ 1/4 * np.log2(1/4))\n1.5\n# 父节点按照1/4-1/4-1/4-1/4进行划分\n- (1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 * np.log2(\n2.0\n而在实际建模过程中，ID3是通过信息增益的计算结果挑选划分规则，而C4.5采用IV值对\n信息增益计算结果进行修正，构建新的数据集划分评估指标：增益比例（Gain Ratio，被\n称为获利比例或增益率），来指导具体的划分规则的挑选。GR的计算公式如下：\nGain Ratio =\nInformation Gain\nInformation Value\n也就是说，在C4.5的建模过程中，需要先计算GR，然后选择GR计算结果较大的列来\n执行这一次展开。例如对于上述例子来看，以age列展开后Information Gain结果为：\nIn [37]:\nOut[37]:\nIG = ent_A - ent_B\nIG\n0.24674981977443922\n1\nP(vi)\n而IV值为：\nIn [36]:\nOut[36]:\nIV = - (\n######################\nOutput:', 'kwargs': {}}
11:03:59,165 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28517, Requested 2377. Please try again in 1.788s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:03:59,168 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '如此一来便更加容易造成模型过拟合，而遗憾的是\nID3并没有任何防止过拟合的措施。而这些ID3的缺陷，则正是C4.5算法的改进方向。接\n下来我们继续讨论关于C4.5决策树的建模规则。\n当然，对于ID3来说，规则是和分类变量的取值一一绑定的，\n二、C4.5决策树的基本建模流程\n作为ID3的改进版算法，C4.5在ID3的基础上进行了三个方面的优化，首先在衡量不\n纯度降低的数值计算过程中引入信息值（information value，也被称为划分信息度、分\n支度等）概念来修正信息熵的计算结果，以抑制ID3更倾向于寻找分类水平较多的列来展\n开的情况，从而间接抑制模型过拟合倾向；其二则是新增了连续变量的处理方法，也就是\nCART树中寻找相邻取值的中间值作为切分点的方法；其三是加入了决策树的剪枝流程，\n使得模型泛化能力能够得到进一步提升。但需要注意的是，尽管有如此改进，但C4.5仍然\n只能解决分类问题，其本质仍然还是一种分类树。接下来我们详细讨论C4.5的具体改进策\n略。\n信息值（information value）\nC4.5中信息值（以下简称IV值）是一个用于衡量数据集在划分时分支个数的指标，如\n果划分时分支越多，IV值就越高。具体IV值的计算公式如下：\nK\nInformation Value = −\n∑\ni=1\nP(vi)log2P(vi)\n\nIV值计算公式和信息熵的计算公式基本一致，只是具体计算的比例不再是各\n类样本所占比例，而是各划分后子节点的数据所占比例，或者说信息熵是计\n算标签不同取值的混乱程度，而IV值就是计算特征不同取值的混乱程度\n其中K表示某次划分是总共分支个数， 表示划分后的某样本， 表示该样本数量占\n父节点数据量的比例。对于如下三种数据集划分情况，简单计算IV值：\nvi\nIn [28]:\nOut[28]:\nIn [31]:\nOut[31]:\nIn [32]:\nOut[32]:\n# 父节点按照50%-50%进行划分\n- (1/2 * np.log2(1/2) + 1/2 * np.log2(1/2))\n1.0\n# 父节点按照1/4-1/2-1/4进行划分\n- (1/4 * np.log2(1/4) + 1/2 * np.log2(1/2)+ 1/4 * np.log2(1/4))\n1.5\n# 父节点按照1/4-1/4-1/4-1/4进行划分\n- (1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 * np.log2(\n2.0\n而在实际建模过程中，ID3是通过信息增益的计算结果挑选划分规则，而C4.5采用IV值对\n信息增益计算结果进行修正，构建新的数据集划分评估指标：增益比例（Gain Ratio，被\n称为获利比例或增益率），来指导具体的划分规则的挑选。GR的计算公式如下：\nGain Ratio =\nInformation Gain\nInformation Value\n也就是说，在C4.5的建模过程中，需要先计算GR，然后选择GR计算结果较大的列来\n执行这一次展开。例如对于上述例子来看，以age列展开后Information Gain结果为：\nIn [37]:\nOut[37]:\nIG = ent_A - ent_B\nIG\n0.24674981977443922\n1\nP(vi)\n而IV值为：\nIn [36]:\nOut[36]:\nIV = - ('}
11:03:59,359 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,360 openai._base_client INFO Retrying request to /chat/completions in 2.586000 seconds
11:03:59,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,436 openai._base_client INFO Retrying request to /chat/completions in 2.396000 seconds
11:03:59,526 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,529 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\nIn [11]:\nIn [12]:\nOut[12]:\n# 此处提取第3、4个特征放置二维空间进行观察，用第三个特征和其他特征组合也是类似\nd = np.array(iris.data.iloc[:, 2: 4])\nplt.scatter(d[:, 0], d[:, 1], c=t)\nplt.plot(np.array([2.5]*25), np.arange(0, 2.5, 0.1), \'r--\')\n[<matplotlib.lines.Line2D at 0x7ffb7881bd30>]\n3.0\n3.2\n3.1\n3.6\n...\n3.0\n2.5\n3.0\n3.4\n3.0\n1.4\n1.4\n1.3\n1.5\n1.4\n...\n5.2\n5.0\n5.2\n5.4\n5.1\n0.2\n0.2\n0.2\n0.2\n0.2\n...\n2.3\n1.9\n2.0\n2.3\n1.8\n\n我们发现，确实可以通过第三个特征（横坐标）很好的区分第一类（紫色点簇）和其\n他两类（黄色点簇），也就是说，从分类结果来看，我们能够简单通过一个分类规则来区\n分第一类鸢尾花和其他两类，例如从上图可以看出，我们可以以petal length (cm) <=\n2.5作为分类条件，当分类条件满足时，鸢尾花属于第一类，否则就属于第二、三类。至\n此我们集完成了对上述数据集的初步分类，基本分类情况可以通过下图来进行表示：\n1\n当然围绕上述未分类的二、三类鸢尾花数据，我们能否进一步找到类似刚才的分类规\n则对其进行有效分类呢？当然此处由于我们希望分类规则能够尽可能简洁，我们力求找出\n根据某一个特征的取值划分就能对数据集进行有效分类的方法，这时我们可以考虑先利用\n逻辑回归的l1正则化挑选出对二、三类分类最有分类效力的特征（也就是最重要的特\n征），然后根据只有一个特征系数不为0的带l1正则化的逻辑回归建模结果、找到决策边\n界，而该决策边界就是依据该单独特征划分Iris二、三类子数据的最佳方法。我们可以通\n过下述代码实现：\nIn [13]:\n# 提取待分类的子数据集\nX = np.array(iris.data)[t == 1]\ny = np.array(iris.target)[t == 1]\n接下来，我们构建一个包含l1正则化的逻辑回归模型，并通过不断调整C的取值、通过观\n察参数系数变化情况来挑选最重要的特征：\nIn [60]:\nIn [61]:\nC_l = np.linspace(1, 0.1, 100)\ncoef_l = []\nfor C in C_l:\nclf = LogisticRegression(penalty=\'l1\', C=C, max_iter=int(1e6), solver=\'saga\'\ncoef_l.append(clf.coef_.flatten())\nIn [68]:\nax = plt.gca()\nax.plot(C_l, coef_l)\nax.set_xlim(ax.get_xlim()[::-1])\nplt.xlabel(\'C\')\nplt.ylabel(\'weights\')\nOut[68]:\nText(0, 0.5, \'weights\')\n\nIn [67]:\ncoef_l\n\nOut[67]:\n[array([-1.12493251, -0.96058774, 3.23208646, 4.18486998]),\narray([-1.10210628, -0\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:03:59,529 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28043, Requested 2349. Please try again in 784ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:03:59,532 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\nIn [11]:\nIn [12]:\nOut[12]:\n# 此处提取第3、4个特征放置二维空间进行观察，用第三个特征和其他特征组合也是类似\nd = np.array(iris.data.iloc[:, 2: 4])\nplt.scatter(d[:, 0], d[:, 1], c=t)\nplt.plot(np.array([2.5]*25), np.arange(0, 2.5, 0.1), 'r--')\n[<matplotlib.lines.Line2D at 0x7ffb7881bd30>]\n3.0\n3.2\n3.1\n3.6\n...\n3.0\n2.5\n3.0\n3.4\n3.0\n1.4\n1.4\n1.3\n1.5\n1.4\n...\n5.2\n5.0\n5.2\n5.4\n5.1\n0.2\n0.2\n0.2\n0.2\n0.2\n...\n2.3\n1.9\n2.0\n2.3\n1.8\n\n我们发现，确实可以通过第三个特征（横坐标）很好的区分第一类（紫色点簇）和其\n他两类（黄色点簇），也就是说，从分类结果来看，我们能够简单通过一个分类规则来区\n分第一类鸢尾花和其他两类，例如从上图可以看出，我们可以以petal length (cm) <=\n2.5作为分类条件，当分类条件满足时，鸢尾花属于第一类，否则就属于第二、三类。至\n此我们集完成了对上述数据集的初步分类，基本分类情况可以通过下图来进行表示：\n1\n当然围绕上述未分类的二、三类鸢尾花数据，我们能否进一步找到类似刚才的分类规\n则对其进行有效分类呢？当然此处由于我们希望分类规则能够尽可能简洁，我们力求找出\n根据某一个特征的取值划分就能对数据集进行有效分类的方法，这时我们可以考虑先利用\n逻辑回归的l1正则化挑选出对二、三类分类最有分类效力的特征（也就是最重要的特\n征），然后根据只有一个特征系数不为0的带l1正则化的逻辑回归建模结果、找到决策边\n界，而该决策边界就是依据该单独特征划分Iris二、三类子数据的最佳方法。我们可以通\n过下述代码实现：\nIn [13]:\n# 提取待分类的子数据集\nX = np.array(iris.data)[t == 1]\ny = np.array(iris.target)[t == 1]\n接下来，我们构建一个包含l1正则化的逻辑回归模型，并通过不断调整C的取值、通过观\n察参数系数变化情况来挑选最重要的特征：\nIn [60]:\nIn [61]:\nC_l = np.linspace(1, 0.1, 100)\ncoef_l = []\nfor C in C_l:\nclf = LogisticRegression(penalty='l1', C=C, max_iter=int(1e6), solver='saga'\ncoef_l.append(clf.coef_.flatten())\nIn [68]:\nax = plt.gca()\nax.plot(C_l, coef_l)\nax.set_xlim(ax.get_xlim()[::-1])\nplt.xlabel('C')\nplt.ylabel('weights')\nOut[68]:\nText(0, 0.5, 'weights')\n\nIn [67]:\ncoef_l\n\nOut[67]:\n[array([-1.12493251, -0.96058774, 3.23208646, 4.18486998]),\narray([-1.10210628, -0"}
11:03:59,539 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,540 openai._base_client INFO Retrying request to /chat/completions in 2.036000 seconds
11:03:59,737 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,738 openai._base_client INFO Retrying request to /chat/completions in 1.866000 seconds
11:03:59,888 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,889 openai._base_client INFO Retrying request to /chat/completions in 1.180000 seconds
11:04:00,575 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:00,577 openai._base_client INFO Retrying request to /chat/completions in 1.024000 seconds
11:04:00,766 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:00,767 openai._base_client INFO Retrying request to /chat/completions in 1.574000 seconds
11:04:00,810 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:00,810 openai._base_client INFO Retrying request to /chat/completions in 0.680000 seconds
11:04:01,100 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,102 openai._base_client INFO Retrying request to /chat/completions in 0.500000 seconds
11:04:01,245 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,248 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 0.\narray([-0.61274879, 0.\narray([-0.58509755, 0.\n, 3.12039086, 3.22470745]),\n, 3.09818066, 3.19766659]),\n, 3.05891014, 3.1747754 ]),\n, 3.03697755, 3.14715043]),\n, 3.02056866, 3.11785887]),\n, 2.99732931, 3.0900815 ]),\n, 2.97080741, 3.06291264]),\n, 2.97634178, 3.02961721]),\n, 2.97513264, 3.00012166]),\n, 2.96319451, 2.97216583]),\narray([-6.00820243e-01, -3.14038921e-06, 2.91819194e+00, 2.94447850e+00]),\narray([-0.54776078, 0.\n, 2.92305106, 2.91616177]),\narray([-0.49669547, 0.\narray([-0.46034651, 0.\narray([-0.43924183, 0.\narray([-0.42114809, 0.\narray([-0.37710231, 0.\narray([-0.36078815, 0.\narray([-0.32730807, 0.\narray([-0.29040147, 0.\narray([-0.26100188, 0.\narray([-0.23403905, 0.\narray([-0.19633863, 0.\narray([-0.17791327, 0.\narray([-0.12625897, 0.\narray([-0.09535538, 0.\narray([-0.05649025, 0.\n, 2.92482248, 2.88916594]),\n, 2.91500936, 2.8615579 ]),\n, 2.89357789, 2.8326846 ]),\n, 2.86936609, 2.80318528]),\n, 2.86234066, 2.77473542]),\n, 2.83524682, 2.74417042]),\n, 2.81919184, 2.7140471 ]),\n, 2.80460709, 2.68351837]),\n, 2.78395265, 2.6519696 ]),\n, 2.76072855, 2.61970054]),\n, 2.74382518, 2.58723019]),\n, 2.71294983, 2.55340083]),\n, 2.70333197, 2.51992837]),\n, 2.67864753, 2.48510602]),\n, 2.65815739, 2.44967008]),\n\narray([-0.01584183, 0.\narray([0.\n, 0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 2.63763392, 2.41346342]),\n, 2.5995733 , 2.37634385]),\n, 2.90224674, 2.23453556]),\n, 2.90064745, 2.1756571 ]),\n, 2.88959628, 2.11967691]),\n, 2.8984936 , 2.05314704]),\n, 2.89326238, 1.99161195]),\n, 2.89341202, 1.92595881]),\n, 2.89113194, 1.85983192]),\n, 2.88973273, 1.79155147]),\n, 2.8825456 , 1.72445091]),\n, 2.88019419, 1.65301627]),\n, 2.88195891, 1.57737666]),\n, 2.88257639, 1.50019671]),\n, 2.87738246, 1.42399342]),\n, 2.87838348, 1.34196882]),\n, 2.878\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': 'The provided text does not contain any identifiable entities or relationships as per the given instructions. The text appears to be a series of numerical arrays, likely data points or outputs from a computational process, rather than descriptive or narrative content from which entities and relationships can be extracted. Therefore, no entities or relationships can be identified or described based on the given criteria.\n\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:01,248 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29955, Requested 2356. Please try again in 4.622s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:01,250 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '0.\narray([-0.61274879, 0.\narray([-0.58509755, 0.\n, 3.12039086, 3.22470745]),\n, 3.09818066, 3.19766659]),\n, 3.05891014, 3.1747754 ]),\n, 3.03697755, 3.14715043]),\n, 3.02056866, 3.11785887]),\n, 2.99732931, 3.0900815 ]),\n, 2.97080741, 3.06291264]),\n, 2.97634178, 3.02961721]),\n, 2.97513264, 3.00012166]),\n, 2.96319451, 2.97216583]),\narray([-6.00820243e-01, -3.14038921e-06, 2.91819194e+00, 2.94447850e+00]),\narray([-0.54776078, 0.\n, 2.92305106, 2.91616177]),\narray([-0.49669547, 0.\narray([-0.46034651, 0.\narray([-0.43924183, 0.\narray([-0.42114809, 0.\narray([-0.37710231, 0.\narray([-0.36078815, 0.\narray([-0.32730807, 0.\narray([-0.29040147, 0.\narray([-0.26100188, 0.\narray([-0.23403905, 0.\narray([-0.19633863, 0.\narray([-0.17791327, 0.\narray([-0.12625897, 0.\narray([-0.09535538, 0.\narray([-0.05649025, 0.\n, 2.92482248, 2.88916594]),\n, 2.91500936, 2.8615579 ]),\n, 2.89357789, 2.8326846 ]),\n, 2.86936609, 2.80318528]),\n, 2.86234066, 2.77473542]),\n, 2.83524682, 2.74417042]),\n, 2.81919184, 2.7140471 ]),\n, 2.80460709, 2.68351837]),\n, 2.78395265, 2.6519696 ]),\n, 2.76072855, 2.61970054]),\n, 2.74382518, 2.58723019]),\n, 2.71294983, 2.55340083]),\n, 2.70333197, 2.51992837]),\n, 2.67864753, 2.48510602]),\n, 2.65815739, 2.44967008]),\n\narray([-0.01584183, 0.\narray([0.\n, 0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 2.63763392, 2.41346342]),\n, 2.5995733 , 2.37634385]),\n, 2.90224674, 2.23453556]),\n, 2.90064745, 2.1756571 ]),\n, 2.88959628, 2.11967691]),\n, 2.8984936 , 2.05314704]),\n, 2.89326238, 1.99161195]),\n, 2.89341202, 1.92595881]),\n, 2.89113194, 1.85983192]),\n, 2.88973273, 1.79155147]),\n, 2.8825456 , 1.72445091]),\n, 2.88019419, 1.65301627]),\n, 2.88195891, 1.57737666]),\n, 2.88257639, 1.50019671]),\n, 2.87738246, 1.42399342]),\n, 2.87838348, 1.34196882]),\n, 2.878'}
11:04:01,448 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,450 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:04:01,622 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,623 openai._base_client INFO Retrying request to /chat/completions in 4.744000 seconds
11:04:01,624 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,625 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,626 openai._base_client INFO Retrying request to /chat/completions in 4.748000 seconds
11:04:01,626 openai._base_client INFO Retrying request to /chat/completions in 3.436000 seconds
11:04:01,655 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,656 openai._base_client INFO Retrying request to /chat/completions in 4.870000 seconds
11:04:01,670 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,671 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:04:01,683 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,683 openai._base_client INFO Retrying request to /chat/completions in 4.896000 seconds
11:04:01,692 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,694 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 方程，其中每个方程其实都会一定程度上受到其他方程影响，导致决策边界\n无法直接通过方程系数进行计算。\n尽管x=b分类边界的准确率不足100%，但其仍然不失为一个不错的分类规则，即分类条\n件为petal length (cm) <= 4.879，当分类条件满足时，鸢尾花属于第二类、不满足时鸢\n尾花属于第三类，根据此分类条件进行的分类准确率为93%。我们可以将围绕鸢尾花子数\n据集进行二、三类的分类过程进行如下方式表示：\n1\n至此，我们就根据两个简单的分类规则，对鸢尾花数据集进行了有效划分，此时整体准确\n率为：\nIn [89]:\nOut[89]:\n1-(y != y_pred).sum() / 150\n0.9533333333333334\n决策树简单构建\n而上述整个过程，我们是通过带正则化项的逻辑回归模型挖掘出的两个分类规则，并\n且这两个分类规则呈现递进的关系，也就是一个分类规则是在另一个分类规则的分类结果\n下继续进行分类，最终这两个分类规则和对应划分出来的数据集呈现出树状，而带有不同\n层次分类规则的模型，其实就是决策树模型，也就是说通过上面一系列的操作，我们就已\n经成功构建了一个决策树模型。\n决策树的分类过程\n对于上述已经构建好的一个决策树来说，当对新数据进行判别时，任意进来一条数据\n我们都可以自上而下进行分类，先根据petal length (cm) <= 2.5判断是否属于第一类，\n如果不满足条件则不属于第一类，此时进一步考虑petal length (cm) <= 4.879是否满足\n条件，并据此判断是属于第二类还是第三类。\n当然，目前主流的决策树并不是依据逻辑回归来寻找分类规则，但上述构建决策树模\n型的一般过程和核心思想和目前主流的决策树模型并无二致，因此我们可以围绕上述过程\n进行进一步总结：\n决策树模型本质\n当决策树模型构建好了之后，实际上一个决策树就是一系列分类规则的叠加，换而言\n之，决策树模型的构建从本质上来看就是在挖掘有效的分类规则，然后以树的形式来进行\n呈现。\n决策树的树生长过程\n\n在整个树的构建过程中，我们实际上是分层来对数据集进行划分的，每当定下一个分\n类规则后，我们就可以根据是否满足分类规则来对数据集进行划分，而后续的分类规则的\n挖掘则进一步根据上一层划分出来的子数据集的情况来定，逐层划分数据集、逐数据集寻\n找分类规则再划分数据集，实际上就就是树模型的生长过程，并且不难看出，这个过程实\n际上也是一个迭代计算过程（上一层的数据集决定有效规律的挖掘、而有效规律的挖\n掘）。而停止生长的条件，我们也可以根据“继续迭代对结果没有显著影响”这个一般思路\n来构建。\n树模型的基本结构\n当然，在已经构建了决策树之后，我们也能够对一个树模型的内部结构来进行说明。\n对上述决策树来说，我们可以将其看成是点（数据集）和线构成的一个图结构（准确来说\n应该是一种有向无环图），而对于任何一个图结构，我们都能够通过点和线来\n######################\nOutput:', 'kwargs': {}}
11:04:01,695 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 30000, Requested 2451. Please try again in 4.902s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:01,697 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '方程，其中每个方程其实都会一定程度上受到其他方程影响，导致决策边界\n无法直接通过方程系数进行计算。\n尽管x=b分类边界的准确率不足100%，但其仍然不失为一个不错的分类规则，即分类条\n件为petal length (cm) <= 4.879，当分类条件满足时，鸢尾花属于第二类、不满足时鸢\n尾花属于第三类，根据此分类条件进行的分类准确率为93%。我们可以将围绕鸢尾花子数\n据集进行二、三类的分类过程进行如下方式表示：\n1\n至此，我们就根据两个简单的分类规则，对鸢尾花数据集进行了有效划分，此时整体准确\n率为：\nIn [89]:\nOut[89]:\n1-(y != y_pred).sum() / 150\n0.9533333333333334\n决策树简单构建\n而上述整个过程，我们是通过带正则化项的逻辑回归模型挖掘出的两个分类规则，并\n且这两个分类规则呈现递进的关系，也就是一个分类规则是在另一个分类规则的分类结果\n下继续进行分类，最终这两个分类规则和对应划分出来的数据集呈现出树状，而带有不同\n层次分类规则的模型，其实就是决策树模型，也就是说通过上面一系列的操作，我们就已\n经成功构建了一个决策树模型。\n决策树的分类过程\n对于上述已经构建好的一个决策树来说，当对新数据进行判别时，任意进来一条数据\n我们都可以自上而下进行分类，先根据petal length (cm) <= 2.5判断是否属于第一类，\n如果不满足条件则不属于第一类，此时进一步考虑petal length (cm) <= 4.879是否满足\n条件，并据此判断是属于第二类还是第三类。\n当然，目前主流的决策树并不是依据逻辑回归来寻找分类规则，但上述构建决策树模\n型的一般过程和核心思想和目前主流的决策树模型并无二致，因此我们可以围绕上述过程\n进行进一步总结：\n决策树模型本质\n当决策树模型构建好了之后，实际上一个决策树就是一系列分类规则的叠加，换而言\n之，决策树模型的构建从本质上来看就是在挖掘有效的分类规则，然后以树的形式来进行\n呈现。\n决策树的树生长过程\n\n在整个树的构建过程中，我们实际上是分层来对数据集进行划分的，每当定下一个分\n类规则后，我们就可以根据是否满足分类规则来对数据集进行划分，而后续的分类规则的\n挖掘则进一步根据上一层划分出来的子数据集的情况来定，逐层划分数据集、逐数据集寻\n找分类规则再划分数据集，实际上就就是树模型的生长过程，并且不难看出，这个过程实\n际上也是一个迭代计算过程（上一层的数据集决定有效规律的挖掘、而有效规律的挖\n掘）。而停止生长的条件，我们也可以根据“继续迭代对结果没有显著影响”这个一般思路\n来构建。\n树模型的基本结构\n当然，在已经构建了决策树之后，我们也能够对一个树模型的内部结构来进行说明。\n对上述决策树来说，我们可以将其看成是点（数据集）和线构成的一个图结构（准确来说\n应该是一种有向无环图），而对于任何一个图结构，我们都能够通过点和线来'}
11:04:01,798 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,800 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: ˜T|\nRα(T) = R(T) + α| ˜T|\n其中Rα(T)就是加入风险结构项后的损失函数，而α则是风险结构项的系数。由此可\n知， 取值越大、对模型的结构风险惩罚力度就越大、模型结构就越简单、过拟合就能够\n被更好的抑制，反之亦反。\nα\n控制树结构的参数类\n接下来就是关于控制树模型结构的相关参数，同时这也是最多的一类参数。这类参数\n可以进一步细分成两类，其一是限制模型整体结构，主要包括限制树深度的max_depth参\n数和限制叶节点数量的max_leaf_nodes参数。此外第二类就是限制树生长的参数，包括\n从节点样本数量限制树生长的参数，包括min_samples_split、min_samples_leaf两个参\n数，当然也有从损失值降低角度出发限制树生长的参数，包括min_impurity_split和\nmin_impurity_decrease参数。通过这些参数的共同作用，可以从各角度有效限制树的生\n长。\n注意，所谓树的最大深度，指的是树的最多生长几层，或者除了根节点外总\n共有几层，并不是树的总共的层数。\n此处需要重点说明的是，对于树模型来说，叶节点太多、单独叶节点所包含的样本数\n量太少、内部节点再划分降低的基尼系数较少，都是可能是过拟合的表现，在建模时尤其\n需要注意。\n并且需要知道的是，sklearn中在计算父节点和子节点的基尼系数（或信息熵）的差\n值时，会在计算结果的前面乘以一个父节点占根节点数据量比例的系数作为最终\nimpurity_decrease的结果：\n1\n而这会导致样本比较少的某节点，哪怕再划分时子节点纯度提升更高，但由于当前节点样\n本较少，因此impurity_decrease数值较低。这其实也是一种为了防止过拟合而采取的措\n施。\n控制迭代随机过程的参数类\n最后，还有一类参数值得注意，那就是关于控制建模过程中随机性的一些参数，主要\n包含两个，其一是splitter参数，当该参数取值为random时其实是随机挑选分类规则对当\n前数据集进行划分，其二是max_features，该参数可以任意设置最多带入几个特征进行备\n选规律挖掘，只要该参数的设置不是带入全部特征进行建模，就相当于是给备选特征随机\n划个范围，也相当于是给树模型的训练增加了一定的随机性。当然，这两个参数的主要作\n\n用有两个方面，其一是可以提升模型训练速度，试想一下，如果我们只从个别特征中挑选\n最佳划分规则，或者随机生成一个划分规则、不进行比较就直接使用，其实都能够极大节\n省计算量，只不过这也是一种用精度换效率的方式，如此操作肯定会带来模型结果精度的\n下降；不过随机性其实也是一把双刃剑，在集成学习中，为了让各基础分类器“和而不\n同”，就必须让每个基分类器保证一定的随机性，而决策树就是最常作为基分类器参与到\n集成学习中的模型，因此树模型中的这些控制其随机性的参数，也会在集成学习中发挥作\n用。\n更多关于决策树的使用及各类参数的使用及调参方法，我们将在后续内容中进行详细\n介绍。\nLesson 8.3 ID3、C4.5决策树的建模\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:01,801 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 30000, Requested 2511. Please try again in 5.022s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:01,804 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '˜T|\nRα(T) = R(T) + α| ˜T|\n其中Rα(T)就是加入风险结构项后的损失函数，而α则是风险结构项的系数。由此可\n知， 取值越大、对模型的结构风险惩罚力度就越大、模型结构就越简单、过拟合就能够\n被更好的抑制，反之亦反。\nα\n控制树结构的参数类\n接下来就是关于控制树模型结构的相关参数，同时这也是最多的一类参数。这类参数\n可以进一步细分成两类，其一是限制模型整体结构，主要包括限制树深度的max_depth参\n数和限制叶节点数量的max_leaf_nodes参数。此外第二类就是限制树生长的参数，包括\n从节点样本数量限制树生长的参数，包括min_samples_split、min_samples_leaf两个参\n数，当然也有从损失值降低角度出发限制树生长的参数，包括min_impurity_split和\nmin_impurity_decrease参数。通过这些参数的共同作用，可以从各角度有效限制树的生\n长。\n注意，所谓树的最大深度，指的是树的最多生长几层，或者除了根节点外总\n共有几层，并不是树的总共的层数。\n此处需要重点说明的是，对于树模型来说，叶节点太多、单独叶节点所包含的样本数\n量太少、内部节点再划分降低的基尼系数较少，都是可能是过拟合的表现，在建模时尤其\n需要注意。\n并且需要知道的是，sklearn中在计算父节点和子节点的基尼系数（或信息熵）的差\n值时，会在计算结果的前面乘以一个父节点占根节点数据量比例的系数作为最终\nimpurity_decrease的结果：\n1\n而这会导致样本比较少的某节点，哪怕再划分时子节点纯度提升更高，但由于当前节点样\n本较少，因此impurity_decrease数值较低。这其实也是一种为了防止过拟合而采取的措\n施。\n控制迭代随机过程的参数类\n最后，还有一类参数值得注意，那就是关于控制建模过程中随机性的一些参数，主要\n包含两个，其一是splitter参数，当该参数取值为random时其实是随机挑选分类规则对当\n前数据集进行划分，其二是max_features，该参数可以任意设置最多带入几个特征进行备\n选规律挖掘，只要该参数的设置不是带入全部特征进行建模，就相当于是给备选特征随机\n划个范围，也相当于是给树模型的训练增加了一定的随机性。当然，这两个参数的主要作\n\n用有两个方面，其一是可以提升模型训练速度，试想一下，如果我们只从个别特征中挑选\n最佳划分规则，或者随机生成一个划分规则、不进行比较就直接使用，其实都能够极大节\n省计算量，只不过这也是一种用精度换效率的方式，如此操作肯定会带来模型结果精度的\n下降；不过随机性其实也是一把双刃剑，在集成学习中，为了让各基础分类器“和而不\n同”，就必须让每个基分类器保证一定的随机性，而决策树就是最常作为基分类器参与到\n集成学习中的模型，因此树模型中的这些控制其随机性的参数，也会在集成学习中发挥作\n用。\n更多关于决策树的使用及各类参数的使用及调参方法，我们将在后续内容中进行详细\n介绍。\nLesson 8.3 ID3、C4.5决策树的建模'}
11:04:01,835 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,836 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:04:01,993 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:02,152 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,152 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:04:02,172 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,173 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:04:02,187 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,188 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:04:02,198 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,200 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:04:02,205 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,208 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Lesson 8.1 决策树的核心思想与建模流程\n从本节课开始，我们将介绍经典机器学习领域中最重要的一类有监督学习算法——树\n模型（决策树）。\n可此前的聚类算法类似，树模型也同样不是一个模型，而是一类模型的概称。树模型\n不仅运算效率高、模型判别能力强、而且原理简单过程清晰、可解释性强，是机器学习领\n域内为数不多的“白箱模型”。并且就树模型本身的功能来说，除了能够同时进行分类和回\n归预测外，还能够产出包括特征重要性、连续变量分箱指标等重要附加结论，而在集成学\n习中，最为常用的基础分类器也正是树模型。正是这些优势，使得树模型成为目前机器学\n习领域最为重要的模型之一。\n一、借助逻辑回归构建决策树\n那到底什么是树模型？接下来我们简单介绍树模型建模的基本思想 。\n尽管树模型作为经典模型，发展至今已是算法数量众多、流派众多，但大多数树模型\n的基本思想其实是相通的，我们可以用一句话来解释树模型的模型形态和建模目标，那就\n是：挖掘有效分类规则并以树状形式呈现。接下来我们就以一个简单实例进行说明，我们\n借助此前所学的基本建模知识，尝试复现决策树的基本分类思想。\nIn [1]:\n# 科学计算模块\nimport numpy as np\nimport pandas as pd\n# 绘图模块\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n# 自定义模块\nfrom ML_basic_function import *\n# Scikit-Learn相关模块\n# 评估器类\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\n# 实用函数\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n# 数据准备\nfrom sklearn.datasets import load_iris\n在Lesson 6.5节中，我们曾围绕鸢尾花数据集构建了多分类逻辑回归模型并且采用网\n格搜索对其进行最优超参数搜索，其基本过程如下：\nIn [2]:\n# 数据准备\nX, y = load_iris(return_X_y=True)\n\nIn [3]:\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=24)\n# 模型训练\n# 实例化模型\nclf = LogisticRegression(max_iter=int(1e6), solver=\'saga\')\n# 构建参数空间\nparam_grid_simple = {\'penalty\': [\'l1\', \'l2\'],\n\'C\': [1, 0.5, 0.1, 0.05, 0.01]}\n# 构建网格搜索评估器\nsearch = GridSearchCV(estimator=clf,\nparam_grid=param_grid_simple)\n# 模型训练\nsearch.fit(X_train, y_train)\nOut[3]:\nGridSearchCV(estimator=LogisticRegression(max_iter=1000000, solver=\'saga\'),\nparam_grid={\'C\': [1, 0.5, 0.1, 0.05, 0.01],\n\'penalty\': [\'l1\', \'l2\']})\nIn [4]:\nOut[4]:\nIn [5]:\nOut[5]:\nsearch.best_params_\n{\'C\': 1, \'penalty\': \'l1\'}\nsearch.best_estimator_.coef_\narray([[ 0.\n, 0.\n[ 0.\n, 0.\n, -3.47337669, 0.\n, 0.\n, 0.\n],\n],\n[-0.55511761, -0.34237661, 3.03227709, 4.12148646]])\nIn [6]:\nOut[6]:\nsearch.best_estimator_.intercept_\narray([ 11.85884734, 2.65291107, -14.51175841])\n我们发现，在参数组取值为{\'C\': 1, \'penalty\': \'l1\'}的情况下，三个逻辑回归方程中，\n第一个方程只包含一个系数，也就是说明第一个方程实际上只用\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>LOGISTIC REGRESSION<|>ORGANIZATION<|>A machine learning model used for classification tasks, which was applied to the iris dataset in the text)\n##\n("entity"<|>GRIDSEARCHCV<|>ORGANIZATION<|>A tool from Scikit-Learn used for hyperparameter optimization, applied to Logistic Regression in the text)\n##\n("entity"<|>IRIS DATASET<|>ORGANIZATION<|>A well-known dataset used for machine learning tasks, specifically for multi-class classification in the text)\n##\n("relationship"<|>LOGISTIC REGRESSION<|>IRIS DATASET<|>Logistic Regression was applied to the Iris dataset for multi-class classification<|>9)\n##\n("relationship"<|>GRIDSEARCHCV<|>LOGISTIC REGRESSION<|>GridSearchCV was used to find the best hyperparameters for Logistic Regression<|>8)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:02,209 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 30000, Requested 2702. Please try again in 5.404s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:02,212 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Lesson 8.1 决策树的核心思想与建模流程\n从本节课开始，我们将介绍经典机器学习领域中最重要的一类有监督学习算法——树\n模型（决策树）。\n可此前的聚类算法类似，树模型也同样不是一个模型，而是一类模型的概称。树模型\n不仅运算效率高、模型判别能力强、而且原理简单过程清晰、可解释性强，是机器学习领\n域内为数不多的“白箱模型”。并且就树模型本身的功能来说，除了能够同时进行分类和回\n归预测外，还能够产出包括特征重要性、连续变量分箱指标等重要附加结论，而在集成学\n习中，最为常用的基础分类器也正是树模型。正是这些优势，使得树模型成为目前机器学\n习领域最为重要的模型之一。\n一、借助逻辑回归构建决策树\n那到底什么是树模型？接下来我们简单介绍树模型建模的基本思想 。\n尽管树模型作为经典模型，发展至今已是算法数量众多、流派众多，但大多数树模型\n的基本思想其实是相通的，我们可以用一句话来解释树模型的模型形态和建模目标，那就\n是：挖掘有效分类规则并以树状形式呈现。接下来我们就以一个简单实例进行说明，我们\n借助此前所学的基本建模知识，尝试复现决策树的基本分类思想。\nIn [1]:\n# 科学计算模块\nimport numpy as np\nimport pandas as pd\n# 绘图模块\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n# 自定义模块\nfrom ML_basic_function import *\n# Scikit-Learn相关模块\n# 评估器类\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\n# 实用函数\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n# 数据准备\nfrom sklearn.datasets import load_iris\n在Lesson 6.5节中，我们曾围绕鸢尾花数据集构建了多分类逻辑回归模型并且采用网\n格搜索对其进行最优超参数搜索，其基本过程如下：\nIn [2]:\n# 数据准备\nX, y = load_iris(return_X_y=True)\n\nIn [3]:\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=24)\n# 模型训练\n# 实例化模型\nclf = LogisticRegression(max_iter=int(1e6), solver='saga')\n# 构建参数空间\nparam_grid_simple = {'penalty': ['l1', 'l2'],\n'C': [1, 0.5, 0.1, 0.05, 0.01]}\n# 构建网格搜索评估器\nsearch = GridSearchCV(estimator=clf,\nparam_grid=param_grid_simple)\n# 模型训练\nsearch.fit(X_train, y_train)\nOut[3]:\nGridSearchCV(estimator=LogisticRegression(max_iter=1000000, solver='saga'),\nparam_grid={'C': [1, 0.5, 0.1, 0.05, 0.01],\n'penalty': ['l1', 'l2']})\nIn [4]:\nOut[4]:\nIn [5]:\nOut[5]:\nsearch.best_params_\n{'C': 1, 'penalty': 'l1'}\nsearch.best_estimator_.coef_\narray([[ 0.\n, 0.\n[ 0.\n, 0.\n, -3.47337669, 0.\n, 0.\n, 0.\n],\n],\n[-0.55511761, -0.34237661, 3.03227709, 4.12148646]])\nIn [6]:\nOut[6]:\nsearch.best_estimator_.intercept_\narray([ 11.85884734, 2.65291107, -14.51175841])\n我们发现，在参数组取值为{'C': 1, 'penalty': 'l1'}的情况下，三个逻辑回归方程中，\n第一个方程只包含一个系数，也就是说明第一个方程实际上只用"}
11:04:02,220 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,221 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:04:02,221 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,222 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:04:02,232 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,233 openai._base_client INFO Retrying request to /chat/completions in 5.684000 seconds
11:04:02,252 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,253 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:04:02,290 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,291 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:04:02,338 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,339 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:04:02,370 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,371 openai._base_client INFO Retrying request to /chat/completions in 5.066000 seconds
11:04:02,521 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,523 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:04:02,712 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,714 openai._base_client INFO Retrying request to /chat/completions in 6.112000 seconds
11:04:05,399 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:05,401 openai._base_client INFO Retrying request to /chat/completions in 3.436000 seconds
11:04:06,725 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:06,727 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:06,728 openai._base_client INFO Retrying request to /chat/completions in 4.748000 seconds
11:04:06,729 openai._base_client INFO Retrying request to /chat/completions in 4.744000 seconds
11:04:06,872 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:06,874 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:06,877 openai._base_client INFO Retrying request to /chat/completions in 4.562000 seconds
11:04:06,878 openai._base_client INFO Retrying request to /chat/completions in 4.356000 seconds
11:04:06,899 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:06,902 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Out[6]:\nsearch.best_estimator_.intercept_\narray([ 11.85884734, 2.65291107, -14.51175841])\n我们发现，在参数组取值为{\'C\': 1, \'penalty\': \'l1\'}的情况下，三个逻辑回归方程中，\n第一个方程只包含一个系数，也就是说明第一个方程实际上只用到了原数据集的一个特\n征，第二个方程自变量系数均为0、基本属于无用方程，而只有第三个方程自变量系数都\n不是0、看起来比较正常“正常”。我们知道，对于多分类问题，逻辑回归所构建的模型方程\n实际上是每个方程对应预测一个类别，而由于总共只有三个类别，因此是允许存在一个类\n别的预测方程失效的，只要剩下的两个类别能够各自完成对应类别的预测，则剩下的样本\n就属于第三类。此处我们需要重点关注的是第一个方程，该方程只有一个非零系数，其背\n后含义是模型只借助特征矩阵中的第三个特征，就很好的将第一类鸢尾花和其他鸢尾花区\n分开了。\nIn [7]:\nIn [8]:\n我们进一步观察数据和第三个特征对于第一个类别的分类结果：\niris = load_iris(as_frame=True)\niris.data\n\nOut[8]:\n0\n1\n2\n3\n4\n...\n145\n146\n147\n148\n149\nsepal length (cm) sepal width (cm) petal length (cm) petal width (cm)\n5.1\n3.5\n4.9\n4.7\n4.6\n5.0\n...\n6.7\n6.3\n6.5\n6.2\n5.9\n150 rows × 4 columns\nIn [9]:\nOut[9]:\nt = np.array(iris.target)\nt[50:]\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\nIn [10]:\n# 将2、3类划归为一类\nt[50:] = 1\nt\nOut[10]:\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>IRIS DATASET<|>ORGANIZATION<|>A dataset used for a machine learning model to classify iris flowers into three species based on sepal length, sepal width, petal length, and petal width)\n##\n("entity"<|>LOGISTIC REGRESSION MODEL<|>ORGANIZATION<|>A model used to classify iris flowers into species based on features such as sepal length, sepal width, petal length, and petal width. It includes three equations for the classification)\n##\n("entity"<|>IRIS FLOWER SPECIES<|>EVENT<|>The classification target of the logistic regression model, aiming to distinguish among three different species of iris flowers)\n##\n("relationship"<|>LOGISTIC REGRESSION MODEL<|>IRIS DATASET<|>The logistic regression model is trained using the Iris dataset to classify iris flowers into species<|>9)\n##\n("relationship"<|>IRIS FLOWER SPECIES<|>IRIS DATASET<|>The Iris dataset contains data points for different iris flower species used for classification<|>8)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:06,902 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 30000, Requested 2444. Please try again in 4.888s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:06,907 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Out[6]:\nsearch.best_estimator_.intercept_\narray([ 11.85884734, 2.65291107, -14.51175841])\n我们发现，在参数组取值为{'C': 1, 'penalty': 'l1'}的情况下，三个逻辑回归方程中，\n第一个方程只包含一个系数，也就是说明第一个方程实际上只用到了原数据集的一个特\n征，第二个方程自变量系数均为0、基本属于无用方程，而只有第三个方程自变量系数都\n不是0、看起来比较正常“正常”。我们知道，对于多分类问题，逻辑回归所构建的模型方程\n实际上是每个方程对应预测一个类别，而由于总共只有三个类别，因此是允许存在一个类\n别的预测方程失效的，只要剩下的两个类别能够各自完成对应类别的预测，则剩下的样本\n就属于第三类。此处我们需要重点关注的是第一个方程，该方程只有一个非零系数，其背\n后含义是模型只借助特征矩阵中的第三个特征，就很好的将第一类鸢尾花和其他鸢尾花区\n分开了。\nIn [7]:\nIn [8]:\n我们进一步观察数据和第三个特征对于第一个类别的分类结果：\niris = load_iris(as_frame=True)\niris.data\n\nOut[8]:\n0\n1\n2\n3\n4\n...\n145\n146\n147\n148\n149\nsepal length (cm) sepal width (cm) petal length (cm) petal width (cm)\n5.1\n3.5\n4.9\n4.7\n4.6\n5.0\n...\n6.7\n6.3\n6.5\n6.2\n5.9\n150 rows × 4 columns\nIn [9]:\nOut[9]:\nt = np.array(iris.target)\nt[50:]\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\nIn [10]:\n# 将2、3类划归为一类\nt[50:] = 1\nt\nOut[10]:\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,"}
11:04:06,928 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:06,929 openai._base_client INFO Retrying request to /chat/completions in 4.896000 seconds
11:04:07,486 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:07,490 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 对分类更加有效。因此如果我们可以将每一轮迭代过程中父类的基尼系数看成是\n损失函数值，树的迭代生长过程就是为了能够更快速的降低父类的基尼系数值。\n其次就是迭代计算的收敛条件。对于此前我们所介绍的收敛条件其实也同样适用于决\n策树模型，例如当两轮迭代损失函数的差值小于某个值、或者直接限制最大迭代次数，其\n实都是可以用于决策树模型的。此时所谓两轮迭代的损失值小于某个值就停止迭代，其实\n就等价于如果进一步的划分数据集、但基尼系数的减少少于某个值就暂时不做划分；而最\n大迭代次数其实就相当于树模型的最高生长层数，在实际建模过程中，我们也可以通过约\n束树最多生长几层来作为迭代收敛条件。当然，对于树模型来说，还有可能出现类似上述\n备选规则都用完了的情况，此时也会停止迭代。\n2.CART树的剪枝\n和逻辑回归不同，决策树在不进行特征衍生时就是一个分类效力更强的模型，因此其\n本身就是一个更容易过拟合的模型。并且通过观察我们不难发现，决策树生长的层数越多\n就表示树模型越复杂，此时模型结构风险就越高、模型越容易过拟合。因此，很多时候如\n果我们不对树的生长进行任何约束，即如果设置的收敛条件较为严格（例如要求最终基尼\n系数全为0），并且最大迭代次数不进行限制，则很有可能容易过拟合。因此在决策树的\n建模流程当中，有非常重要的一个环节，就是需要讨论限制决策树模型过拟合倾向的方\n法。\n当然，不同决策树算法的剪枝策略也各有不同，总的来说树模型的剪枝分为两种，其\n一在模型生长前就限制模型生长，这种方法也被称为预剪枝或者盆栽法；而另外一种方法\n则是先让树模型尽可能的生长，然后再进行剪枝，这种方法也被称为后剪枝或者修建法。\n从算法的原生原理来讲，目前主流的C4.5和CART树都采用的是后剪枝的方法，其中C4.5\n\n是通过计算叶节点的期望错误率（一种区间估计的方法）来进行剪枝，而CART树则是通\n过类似正则化的方法在损失函数（基尼系数计算函数）中加入结构复杂度的惩罚因子，来\n进行剪枝。\n不过，无论采用何种方式来进行剪枝，最终的结果都是通过控制树的结构复杂度来抑\n制过拟合倾向，而树模型的结构复杂度其实完全可以用树的层数、每一层分叉的节点数来\n表示，即内部节点和叶节点的数量来表示，因此我们也完全可以不采用这些树模型原生原\n理的方式来进行剪枝，而是直接将这些决定树模型的复杂度的因素视作超参数，然后通过\n网格搜索的方式来直接确定泛化能力最强的树模型结构。当然这也是sklearn中进行决策\n树剪枝的一般策略。\n在sklearn 0.22版本之前，甚至没有支持CART树实现原生原理剪枝方式的\n参数。\n二、CART分类树的Scikit-Learn快速实现方法与评\n估器参数详解\n1.CART分类\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>CART树<|>ORGANIZATION<|>CART树是一种决策树算法，用于分类和回归任务，通过计算基尼系数进行分割，并采用后剪枝方法来防止过拟合)\n##\n("entity"<|>C4.5<|>ORGANIZATION<|>C4.5是一种决策树算法，通过计算信息增益比来选择特征，并采用后剪枝)\n##\n("entity"<|>SKLEARN<|>ORGANIZATION<|>Sklearn是一个Python机器学习库，支持多种机器学习算法的实现，包括决策树)\n##\n("relationship"<|>CART树<|>SKLEARN<|>Sklearn提供了CART树算法的实现，包括剪枝策略<|>8)\n##\n("relationship"<|>C4.5<|>CART树<|>C4.5和CART树都采用后剪枝方法，但通过不同的策略来防止过拟合<|>5)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:07,490 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29744, Requested 2652. Please try again in 4.792s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:07,492 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '对分类更加有效。因此如果我们可以将每一轮迭代过程中父类的基尼系数看成是\n损失函数值，树的迭代生长过程就是为了能够更快速的降低父类的基尼系数值。\n其次就是迭代计算的收敛条件。对于此前我们所介绍的收敛条件其实也同样适用于决\n策树模型，例如当两轮迭代损失函数的差值小于某个值、或者直接限制最大迭代次数，其\n实都是可以用于决策树模型的。此时所谓两轮迭代的损失值小于某个值就停止迭代，其实\n就等价于如果进一步的划分数据集、但基尼系数的减少少于某个值就暂时不做划分；而最\n大迭代次数其实就相当于树模型的最高生长层数，在实际建模过程中，我们也可以通过约\n束树最多生长几层来作为迭代收敛条件。当然，对于树模型来说，还有可能出现类似上述\n备选规则都用完了的情况，此时也会停止迭代。\n2.CART树的剪枝\n和逻辑回归不同，决策树在不进行特征衍生时就是一个分类效力更强的模型，因此其\n本身就是一个更容易过拟合的模型。并且通过观察我们不难发现，决策树生长的层数越多\n就表示树模型越复杂，此时模型结构风险就越高、模型越容易过拟合。因此，很多时候如\n果我们不对树的生长进行任何约束，即如果设置的收敛条件较为严格（例如要求最终基尼\n系数全为0），并且最大迭代次数不进行限制，则很有可能容易过拟合。因此在决策树的\n建模流程当中，有非常重要的一个环节，就是需要讨论限制决策树模型过拟合倾向的方\n法。\n当然，不同决策树算法的剪枝策略也各有不同，总的来说树模型的剪枝分为两种，其\n一在模型生长前就限制模型生长，这种方法也被称为预剪枝或者盆栽法；而另外一种方法\n则是先让树模型尽可能的生长，然后再进行剪枝，这种方法也被称为后剪枝或者修建法。\n从算法的原生原理来讲，目前主流的C4.5和CART树都采用的是后剪枝的方法，其中C4.5\n\n是通过计算叶节点的期望错误率（一种区间估计的方法）来进行剪枝，而CART树则是通\n过类似正则化的方法在损失函数（基尼系数计算函数）中加入结构复杂度的惩罚因子，来\n进行剪枝。\n不过，无论采用何种方式来进行剪枝，最终的结果都是通过控制树的结构复杂度来抑\n制过拟合倾向，而树模型的结构复杂度其实完全可以用树的层数、每一层分叉的节点数来\n表示，即内部节点和叶节点的数量来表示，因此我们也完全可以不采用这些树模型原生原\n理的方式来进行剪枝，而是直接将这些决定树模型的复杂度的因素视作超参数，然后通过\n网格搜索的方式来直接确定泛化能力最强的树模型结构。当然这也是sklearn中进行决策\n树剪枝的一般策略。\n在sklearn 0.22版本之前，甚至没有支持CART树实现原生原理剪枝方式的\n参数。\n二、CART分类树的Scikit-Learn快速实现方法与评\n估器参数详解\n1.CART分类'}
11:04:07,788 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:07,789 openai._base_client INFO Retrying request to /chat/completions in 4.248000 seconds
11:04:07,913 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:07,916 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 的原理时，我们先从简单入手，先考虑自变量都是离散变量的分类预测问题，再\n逐步拓展连续变量的处理方法和回归类问题的预测方法。\n1.CART树的基本生长过程\n首先我们来看在特征都为分类变量时、围绕分类问题构建CART的基本过程。\n1.1 规则评估指标选取与设置\n划分规则评估指标概念\n在引言部分中我们曾简单构建了一个决策树，我们曾强调，决策树的建模过程实际上\n就是挖掘有效分类规律的过程，而这里的分类规律是否有效，其实是需要有一个评估标准\n的。此前我们是在逻辑回归的模型结论的基础上寻找分类规律，可以看成是根据分类结果\n的准确率来寻找分类规则，此时准确率就是评估分类条件好坏的评估指标，例如在决策树\n开始生长的第一层，我们选取petal length (cm) <= 2.5作为分类条件将原始数据集一分\n为二，分出来的两个数据集其中一个100%是一类数据，另一个则全是二、三类数据，此\n时如果我们根据准确率来判断该分类规则是否能够很好的区分一类和二、三类数据的话，\n那此时的准确率就是100%，此时的分类误差就是0。\n1\n划分规则评估指标构建的核心思路\n当然，这种定义分类评估指标的方法并不通用并且在多分类问题时容易引发混乱，例\n如如果是四分类问题，1条件能够100%区分A类和BCD类，2条件能够100%区分AB类和\nCD类，此时如何还按照准确率来进行判别分类条件好坏的判别一句，则选择哪个条件就\n成了问题。因此一般来说树模型挑选分类规则的评估指标并不是看每个类别划分后的准确\n率，而是父节点划分子节点后子节点数据集标签的纯度。\n注意，此处纯度是一个非常重要的概念，一般来说如果一个数据集标签都比较倾向于\n取得同一个值（不管是都取0还是都取1），则我们就说这个数据集的标签纯度高，反之则\n说这个这个数据集标签纯度不高。而决策树的划分规则的评估标准，其实都是根据纯度来\n进行构建的。\n其实，决策树生长的方向也就是令每个划分出来的子集纯度越来越高的方\n向。\n\n单独一个数据集的标签纯度衡量指标\n首先我们先来讨论对于一个单独的数据集来说，可以通过哪些指标来衡量该数据集标\n签的纯度。一般来说，用于衡量数据集标签纯度的数值指标一般有三种，分别是分类误\n差、信息熵和基尼系数，对于每个单独数据集来说，其基本计算公式如下：\n(1)分类误差（Classification error）：\nClassification error(t) = 1 − max[p(i|t)]\n1≤i≤c\n其中i表示第i类，当前数据集总共有c类， 代表第i类数据占当前数据集中总数据\n的比例。而所谓的分类误差，其实就是用1减去多数类的占比。例如某个包含10条数据的\n数据集，有6条0类数据、4条1类数据，此时该数据集分类误差就是1-6/10 = 0.4。分类误\n差在[0, 0.5]范围内取值，分类误差越小，说明数据集标签纯度越高。\np(i|t)\n此外，由于决策树中每一个数据集实际上就代表一系列分类规则，因此分类\n误差的另一种理解方法是，如果需要根据少数服从多数原\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>CART树<|>ORGANIZATION<|>CART树是一种决策树，用于分类预测问题，包括处理离散和连续变量以及回归问题)\n##\n("entity"<|>分类误差<|>EVENT<|>分类误差是衡量数据集标签纯度的一种指标，用于评估分类规则的有效性)\n##\n("entity"<|>信息熵<|>EVENT<|>信息熵是衡量数据集标签纯度的一种指标，用于评估分类规则的有效性，反映数据集的混乱程度)\n##\n("entity"<|>基尼系数<|>EVENT<|>基尼系数是衡量数据集标签纯度的一种指标，用于评估分类规则的有效性，反映数据集的不平等程度)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:07,916 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29222, Requested 2675. Please try again in 3.794s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:07,919 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '的原理时，我们先从简单入手，先考虑自变量都是离散变量的分类预测问题，再\n逐步拓展连续变量的处理方法和回归类问题的预测方法。\n1.CART树的基本生长过程\n首先我们来看在特征都为分类变量时、围绕分类问题构建CART的基本过程。\n1.1 规则评估指标选取与设置\n划分规则评估指标概念\n在引言部分中我们曾简单构建了一个决策树，我们曾强调，决策树的建模过程实际上\n就是挖掘有效分类规律的过程，而这里的分类规律是否有效，其实是需要有一个评估标准\n的。此前我们是在逻辑回归的模型结论的基础上寻找分类规律，可以看成是根据分类结果\n的准确率来寻找分类规则，此时准确率就是评估分类条件好坏的评估指标，例如在决策树\n开始生长的第一层，我们选取petal length (cm) <= 2.5作为分类条件将原始数据集一分\n为二，分出来的两个数据集其中一个100%是一类数据，另一个则全是二、三类数据，此\n时如果我们根据准确率来判断该分类规则是否能够很好的区分一类和二、三类数据的话，\n那此时的准确率就是100%，此时的分类误差就是0。\n1\n划分规则评估指标构建的核心思路\n当然，这种定义分类评估指标的方法并不通用并且在多分类问题时容易引发混乱，例\n如如果是四分类问题，1条件能够100%区分A类和BCD类，2条件能够100%区分AB类和\nCD类，此时如何还按照准确率来进行判别分类条件好坏的判别一句，则选择哪个条件就\n成了问题。因此一般来说树模型挑选分类规则的评估指标并不是看每个类别划分后的准确\n率，而是父节点划分子节点后子节点数据集标签的纯度。\n注意，此处纯度是一个非常重要的概念，一般来说如果一个数据集标签都比较倾向于\n取得同一个值（不管是都取0还是都取1），则我们就说这个数据集的标签纯度高，反之则\n说这个这个数据集标签纯度不高。而决策树的划分规则的评估标准，其实都是根据纯度来\n进行构建的。\n其实，决策树生长的方向也就是令每个划分出来的子集纯度越来越高的方\n向。\n\n单独一个数据集的标签纯度衡量指标\n首先我们先来讨论对于一个单独的数据集来说，可以通过哪些指标来衡量该数据集标\n签的纯度。一般来说，用于衡量数据集标签纯度的数值指标一般有三种，分别是分类误\n差、信息熵和基尼系数，对于每个单独数据集来说，其基本计算公式如下：\n(1)分类误差（Classification error）：\nClassification error(t) = 1 − max[p(i|t)]\n1≤i≤c\n其中i表示第i类，当前数据集总共有c类， 代表第i类数据占当前数据集中总数据\n的比例。而所谓的分类误差，其实就是用1减去多数类的占比。例如某个包含10条数据的\n数据集，有6条0类数据、4条1类数据，此时该数据集分类误差就是1-6/10 = 0.4。分类误\n差在[0, 0.5]范围内取值，分类误差越小，说明数据集标签纯度越高。\np(i|t)\n此外，由于决策树中每一个数据集实际上就代表一系列分类规则，因此分类\n误差的另一种理解方法是，如果需要根据少数服从多数原'}
11:04:07,930 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:07,931 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 结构。当然这也是sklearn中进行决策\n树剪枝的一般策略。\n在sklearn 0.22版本之前，甚至没有支持CART树实现原生原理剪枝方式的\n参数。\n二、CART分类树的Scikit-Learn快速实现方法与评\n估器参数详解\n1.CART分类树的sklearn快速实现\nIn [19]:\n接下来我们尝试在Scikit-Learn中构建分类树模型。在sklearn中，回归树和分类树是\n两个不同的评估器，都在sklearn.tree模块内，我们可以通过如下方式进行导入：\nfrom sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n然后尝试围绕上述简单例子进行快速建模试验：\nIn [38]:\n# 准备数据集\nX = np.array([[1, 1], [2, 2], [2, 1], [1, 2], [1, 1], [1, 2], [1, 2], [2, 1]])\ny = np.array([0, 0, 0, 1, 0, 1, 1, 0])\nIn [39]:\nIn [40]:\nOut[40]:\n# 调用决策树评估器并进行训练\nclf = DecisionTreeClassifier().fit(X, y)\nclf.score(X, y)\n1.0\n当然，对于树模型来说，我们不仅需要查看模型最终结果的评估指标，很多时候我们还希\n望能够观察到树模型分类过程的树状图，即类似于此前我们手动绘制的树状图。根据\nsklearn说明文档中的介绍，此处我们可以借助sklearn.tree模块下的plot_tree函数直接输\n入训练好的评估器即可进行绘制：\nplot_tree绘制树状图\nIn [41]:\n# 首先导入tree模块\nfrom sklearn import tree\n\nIn [42]:\n# 然后调用plot_tree函数进行绘制\nplt.figure(figsize=(6, 2), dpi=150)\ntree.plot_tree(clf)\nOut[42]:\n[Text(279.0, 188.75, \'X[1] <= 1.5\\ngini = 0.469\\nsamples = 8\\nvalue = [5, 3]\'),\nText(139.5, 113.25, \'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]\'),\nText(418.5, 113.25, \'X[0] <= 1.5\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3]\'),\nText(279.0, 37.75, \'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]\'),\nText(558.0, 37.75, \'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]\')]\n由于plot_tree是sklearn中已经集成好的函数，因此调用过程非常简单，我们只需要\n输入训练好的分类树评估器即可。同时根据输出的结果可知，sklearn中分类树的建模过\n程和此前我们手动哦实现的过程是一样的，先根据第一个特征的不同取值进行数据集划\n分，然后在根据第二个特征的不同取值进行数据集划分，最终形成一个三个叶节点、两层\n的决策树模型。\n当然，sklearn中的评估器使用过程基本一致，决策树模型评估器的简单使用也非常\n类似于逻辑回归评估器。此外，由于sklearn中优秀的参数默认值设置，使得很多时候我\n们直接使用其默认值就能完成不错的建模结果。接下来我们详细讨论决策树评估器中的相\n关参数，借此讨论关于sklearn中的决策树剪枝方法。\nIn [25]:\n2.CART分类树评估器的参数详解\n实际上DecisionTreeClassifier评估器参数众多，并且大多和决策树的模型结构相关：\nDecisionTreeClassifier?\n\nInit signature:\nDecisionTreeClassifier(\n*,\ncriterion=\'gini\',\nsplitter=\'best\',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_imp\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>DECISIONTREECLASSIFIER<|>ORGANIZATION<|>A classifier in sklearn.tree module for creating a decision tree for classification tasks)\n##\n("entity"<|>DECISIONTREEREGRESSOR<|>ORGANIZATION<|>A regressor in sklearn.tree module for creating a decision tree for regression tasks)\n##\n("entity"<|>SKLEARN.TREE<|>ORGANIZATION<|>Module in Scikit-Learn containing tools for decision tree models)\n##\n("entity"<|>PLOT_TREE<|>ORGANIZATION<|>Function in sklearn.tree module for visualizing decision trees)\n##\n("relationship"<|>DECISIONTREECLASSIFIER<|>SKLEARN.TREE<|>DecisionTreeClassifier is a part of the sklearn.tree module<|>9)\n##\n("relationship"<|>DECISIONTREEREGRESSOR<|>SKLEARN.TREE<|>DecisionTreeRegressor is a part of the sklearn.tree module<|>9)\n##\n("relationship"<|>PLOT_TREE<|>SKLEARN.TREE<|>plot_tree function is used for visualizing decision trees from the sklearn.tree module<|>9)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:07,931 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29517, Requested 2686. Please try again in 4.406s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:07,933 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "结构。当然这也是sklearn中进行决策\n树剪枝的一般策略。\n在sklearn 0.22版本之前，甚至没有支持CART树实现原生原理剪枝方式的\n参数。\n二、CART分类树的Scikit-Learn快速实现方法与评\n估器参数详解\n1.CART分类树的sklearn快速实现\nIn [19]:\n接下来我们尝试在Scikit-Learn中构建分类树模型。在sklearn中，回归树和分类树是\n两个不同的评估器，都在sklearn.tree模块内，我们可以通过如下方式进行导入：\nfrom sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n然后尝试围绕上述简单例子进行快速建模试验：\nIn [38]:\n# 准备数据集\nX = np.array([[1, 1], [2, 2], [2, 1], [1, 2], [1, 1], [1, 2], [1, 2], [2, 1]])\ny = np.array([0, 0, 0, 1, 0, 1, 1, 0])\nIn [39]:\nIn [40]:\nOut[40]:\n# 调用决策树评估器并进行训练\nclf = DecisionTreeClassifier().fit(X, y)\nclf.score(X, y)\n1.0\n当然，对于树模型来说，我们不仅需要查看模型最终结果的评估指标，很多时候我们还希\n望能够观察到树模型分类过程的树状图，即类似于此前我们手动绘制的树状图。根据\nsklearn说明文档中的介绍，此处我们可以借助sklearn.tree模块下的plot_tree函数直接输\n入训练好的评估器即可进行绘制：\nplot_tree绘制树状图\nIn [41]:\n# 首先导入tree模块\nfrom sklearn import tree\n\nIn [42]:\n# 然后调用plot_tree函数进行绘制\nplt.figure(figsize=(6, 2), dpi=150)\ntree.plot_tree(clf)\nOut[42]:\n[Text(279.0, 188.75, 'X[1] <= 1.5\\ngini = 0.469\\nsamples = 8\\nvalue = [5, 3]'),\nText(139.5, 113.25, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\nText(418.5, 113.25, 'X[0] <= 1.5\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\nText(279.0, 37.75, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\nText(558.0, 37.75, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]')]\n由于plot_tree是sklearn中已经集成好的函数，因此调用过程非常简单，我们只需要\n输入训练好的分类树评估器即可。同时根据输出的结果可知，sklearn中分类树的建模过\n程和此前我们手动哦实现的过程是一样的，先根据第一个特征的不同取值进行数据集划\n分，然后在根据第二个特征的不同取值进行数据集划分，最终形成一个三个叶节点、两层\n的决策树模型。\n当然，sklearn中的评估器使用过程基本一致，决策树模型评估器的简单使用也非常\n类似于逻辑回归评估器。此外，由于sklearn中优秀的参数默认值设置，使得很多时候我\n们直接使用其默认值就能完成不错的建模结果。接下来我们详细讨论决策树评估器中的相\n关参数，借此讨论关于sklearn中的决策树剪枝方法。\nIn [25]:\n2.CART分类树评估器的参数详解\n实际上DecisionTreeClassifier评估器参数众多，并且大多和决策树的模型结构相关：\nDecisionTreeClassifier?\n\nInit signature:\nDecisionTreeClassifier(\n*,\ncriterion='gini',\nsplitter='best',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_imp"}
11:04:07,934 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:07,934 openai._base_client INFO Retrying request to /chat/completions in 4.408000 seconds
11:04:07,938 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:07,938 openai._base_client INFO Retrying request to /chat/completions in 4.470000 seconds
11:04:07,962 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:08,108 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:08,109 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:04:08,261 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:08,261 openai._base_client INFO Retrying request to /chat/completions in 5.462000 seconds
11:04:08,289 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:08,289 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:04:08,440 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:08,441 openai._base_client INFO Retrying request to /chat/completions in 5.684000 seconds
11:04:08,469 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:08,473 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 解\n实际上DecisionTreeClassifier评估器参数众多，并且大多和决策树的模型结构相关：\nDecisionTreeClassifier?\n\nInit signature:\nDecisionTreeClassifier(\n*,\ncriterion=\'gini\',\nsplitter=\'best\',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_impurity_decrease=0.0,\nmin_impurity_split=None,\nclass_weight=None,\npresort=\'deprecated\',\nccp_alpha=0.0,\n)\nDocstring:\nA decision tree classifier.\nRead more in the :ref:`User Guide <tree>`.\nParameters\n---------\ncriterion : {"gini", "entropy"}, default="gini"\nThe function to measure the quality of a split. Supported criteria are\n"gini" for the Gini impurity and "entropy" for the information gain.\nsplitter : {"best", "random"}, default="best"\nThe strategy used to choose the split at each node. Supported\nstrategies are "best" to choose the best split and "random" to choose\nthe best random split.\nmax_depth : int, default=None\nThe maximum depth of the tree. If None, then nodes are expanded until\nall leaves are pure or until all leaves contain less than\nmin_samples_split samples.\nmin_samples_split : int or float, default=2\nThe minimum number of samples required to split an internal node:\n- If int, then consider `min_samples_split` as the minimum number.\n- If float, then `min_samples_split` is a fraction and\n`ceil(min_samples_split * n_samples)` are the minimum\nnumber of samples for each split.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_samples_leaf : int or float, default=1\nThe minimum number of samples required to be at a leaf node.\nA split point at any depth will only be considered if it leaves at\nleast ``min_samples_leaf`` training samples in each of the left and\nright branches. This may have the effect of smoothing the model,\nespecially in regression.\n- If int, then consider `min_samples_leaf` as the minimum number.\n- If float, then `min_samples_leaf` is a fraction and\n`ceil(min_samples_leaf * n_samples)` are the minimum\n\nnumber of samples for each node.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_weight_fraction_leaf : float, default=0.0\nThe minimum weighted fraction of the sum total of weights (of all\nthe input samples) required to be at a leaf node. Samples have\nequal weight when sample_weight is not provided.\nmax_features : int, float or {"auto", "sqrt", "log2"}, default=None\nThe number of features to consider when looking for the best split:\n- If int, then consider `max_features` features at each split.\n- If float, then `max_features` is a fraction and\n`int(max_features * n_features)` features are considered at each\nsplit.\n- If "auto", then `max_features=sqrt(n_features)`.\n- If "sqrt", then `max_features=sqrt(n_features)`.\n- If "log2", then `max_features=log2(n_features)`.\n- If None, then `max_features=n_features`.\nNote: the search for a split does not stop until at least one\nvalid partition of the node samples is found, even if it requires to\neffectively inspect more than ``max_features`` features.\nrandom_state : int, RandomState instance, default=None\nControls the randomness of the estimator. The features are always\nrandomly permuted at each split, even if ``splitter`` is set to\n``"best"``. When ``max_features < n_features``, the algorithm will\nselect ``max_features`` at random at each split before finding the best\nsplit among them. But the best found split may vary across different\nruns, even if ``max_features=n_features``. That is the case, if the\nimprovement of the criterion is identical for several splits and one\nsplit has to be selected at random. To obtain a deterministic behaviour\nduring fitting, ``random_state`` has to be fixed to an integer.\nSee :term:`Glossary <random_state>` for details.\nmax_leaf_nodes : int, default=None\nGrow a tree with ``max_leaf_nodes`` in best-first fashion.\nBest nodes are defined as relative reduction in impurity.\nIf None then unlimited number of leaf nodes.\nmin_impurity_decrease : float, default=0.0\nA node will be split if this split induces a decrease of the impurity\ngreater than or equal to this value.\nThe weighted impurity decrease equation is the following::\nN_t / N * (impurity - N_t_R / N_t * right_impurity\n- N_t_L / N_t * left_impurity)\nwhere ``N`` is the total number of samples, ``N_t`` is the number of\nsamples at the current node, ``N_t_L`` is the number of samples in the\nleft child, and ``N_t_R`` is the number of samples in the right child.\n``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\n\nmin_impurity_split : float, default=0\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:08,473 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 30000, Requested 2890. Please try again in 5.78s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:08,476 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '解\n实际上DecisionTreeClassifier评估器参数众多，并且大多和决策树的模型结构相关：\nDecisionTreeClassifier?\n\nInit signature:\nDecisionTreeClassifier(\n*,\ncriterion=\'gini\',\nsplitter=\'best\',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_impurity_decrease=0.0,\nmin_impurity_split=None,\nclass_weight=None,\npresort=\'deprecated\',\nccp_alpha=0.0,\n)\nDocstring:\nA decision tree classifier.\nRead more in the :ref:`User Guide <tree>`.\nParameters\n---------\ncriterion : {"gini", "entropy"}, default="gini"\nThe function to measure the quality of a split. Supported criteria are\n"gini" for the Gini impurity and "entropy" for the information gain.\nsplitter : {"best", "random"}, default="best"\nThe strategy used to choose the split at each node. Supported\nstrategies are "best" to choose the best split and "random" to choose\nthe best random split.\nmax_depth : int, default=None\nThe maximum depth of the tree. If None, then nodes are expanded until\nall leaves are pure or until all leaves contain less than\nmin_samples_split samples.\nmin_samples_split : int or float, default=2\nThe minimum number of samples required to split an internal node:\n- If int, then consider `min_samples_split` as the minimum number.\n- If float, then `min_samples_split` is a fraction and\n`ceil(min_samples_split * n_samples)` are the minimum\nnumber of samples for each split.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_samples_leaf : int or float, default=1\nThe minimum number of samples required to be at a leaf node.\nA split point at any depth will only be considered if it leaves at\nleast ``min_samples_leaf`` training samples in each of the left and\nright branches. This may have the effect of smoothing the model,\nespecially in regression.\n- If int, then consider `min_samples_leaf` as the minimum number.\n- If float, then `min_samples_leaf` is a fraction and\n`ceil(min_samples_leaf * n_samples)` are the minimum\n\nnumber of samples for each node.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_weight_fraction_leaf : float, default=0.0\nThe minimum weighted fraction of the sum total of weights (of all\nthe input samples) required to be at a leaf node. Samples have\nequal weight when sample_weight is not provided.\nmax_features : int, float or {"auto", "sqrt", "log2"}, default=None\nThe number of features to consider when looking for the best split:\n- If int, then consider `max_features` features at each split.\n- If float, then `max_features` is a fraction and\n`int(max_features * n_features)` features are considered at each\nsplit.\n- If "auto", then `max_features=sqrt(n_features)`.\n- If "sqrt", then `max_features=sqrt(n_features)`.\n- If "log2", then `max_features=log2(n_features)`.\n- If None, then `max_features=n_features`.\nNote: the search for a split does not stop until at least one\nvalid partition of the node samples is found, even if it requires to\neffectively inspect more than ``max_features`` features.\nrandom_state : int, RandomState instance, default=None\nControls the randomness of the estimator. The features are always\nrandomly permuted at each split, even if ``splitter`` is set to\n``"best"``. When ``max_features < n_features``, the algorithm will\nselect ``max_features`` at random at each split before finding the best\nsplit among them. But the best found split may vary across different\nruns, even if ``max_features=n_features``. That is the case, if the\nimprovement of the criterion is identical for several splits and one\nsplit has to be selected at random. To obtain a deterministic behaviour\nduring fitting, ``random_state`` has to be fixed to an integer.\nSee :term:`Glossary <random_state>` for details.\nmax_leaf_nodes : int, default=None\nGrow a tree with ``max_leaf_nodes`` in best-first fashion.\nBest nodes are defined as relative reduction in impurity.\nIf None then unlimited number of leaf nodes.\nmin_impurity_decrease : float, default=0.0\nA node will be split if this split induces a decrease of the impurity\ngreater than or equal to this value.\nThe weighted impurity decrease equation is the following::\nN_t / N * (impurity - N_t_R / N_t * right_impurity\n- N_t_L / N_t * left_impurity)\nwhere ``N`` is the total number of samples, ``N_t`` is the number of\nsamples at the current node, ``N_t_L`` is the number of samples in the\nleft child, and ``N_t_R`` is the number of samples in the right child.\n``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\n\nmin_impurity_split : float, default=0\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity'}
11:04:08,525 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:08,526 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:04:08,843 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:08,844 openai._base_client INFO Retrying request to /chat/completions in 5.836000 seconds
11:04:09,180 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:09,182 openai._base_client INFO Retrying request to /chat/completions in 5.018000 seconds
11:04:10,537 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:10,539 openai._base_client INFO Retrying request to /chat/completions in 1.724000 seconds
11:04:11,582 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:11,584 openai._base_client INFO Retrying request to /chat/completions in 1.988000 seconds
11:04:11,786 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:11,787 openai._base_client INFO Retrying request to /chat/completions in 1.938000 seconds
11:04:11,815 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:11,816 openai._base_client INFO Retrying request to /chat/completions in 1.636000 seconds
11:04:11,928 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:11,929 openai._base_client INFO Retrying request to /chat/completions in 1.518000 seconds
11:04:12,166 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:12,167 openai._base_client INFO Retrying request to /chat/completions in 1.432000 seconds
11:04:12,453 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:12,454 openai._base_client INFO Retrying request to /chat/completions in 0.700000 seconds
11:04:12,733 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:12,734 openai._base_client INFO Retrying request to /chat/completions in 0.760000 seconds
11:04:12,760 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:12,763 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: ，因此树模型中的这些控制其随机性的参数，也会在集成学习中发挥作\n用。\n更多关于决策树的使用及各类参数的使用及调参方法，我们将在后续内容中进行详细\n介绍。\nLesson 8.3 ID3、C4.5决策树的建模流程\nID3和C4.5作为的经典决策树算法，尽管无法通过sklearn来进行建模，但其基本原理\n仍然值得讨论与学习。接下来我们详细介绍关于ID3和C4.5这两种决策树模型的建模基本\n思路和原理。ID3和C4.5的基本建模流程和CART树是类似的，也是根据纯度评估指标选取\n最佳的数据集划分方式，只是不过ID3和C4.5是以信息熵为评估指标，而数据集的离散特\n征划分方式也是一次展开一列，而不是寻找切点进行切分。我们先从ID3的基本原理开始\n介绍，随后讨论C4.5在ID3基础上的改善措施。\nIn [9]:\nimport numpy as np\nfrom ML_basic_function import *\n一、ID3决策树的基本建模流程\nID3是一个只能围绕离散型变量进行分类问题建模的决策树模型，即ID3无法处理连续\n型特征、也无法处理回归问题，如果带入训练数据有连续型变量，则首先需要对其进行离\n散化处理，也就是连续变量分箱。例如如下个人消费数据，各特征都是离散型变量，能够\n看出，其中age和income两列就是连续型变量分箱之后的结果，例如age列就是以30、\n40为界进行连续变量分箱。当然，除了如下表示外，我们还可以将分箱之后的结果直接赋\n予一个离散的值，如1、2、3等。\n1\n更多关于连续变量的离散化的方法将在特征工程部分进行介绍。\nID3的生长过程其实和CART树基本一致，其目标都是尽可能降低数据集的不纯度，其\n生长的过程也就是数据集不断划分的过程。只不过ID3的数据集划分过程（规律提取过\n程）和CART树有所不同，CART树是在所有特征中寻找切分点、然后再从中挑选出能够最\n大程度降低数据集不纯度的节分方式，换而言之就是CART树是按照某切分点来展开，而\nID3则是按照列来展开，即根据某列的不同取值来对数据集进行划分。例如根据上述数据\n集中的age列的不同取值来对原始数据集进行划分，则划分结果如下：\n1\n\n同样，我们可以计算在以age的不同取值为划分规则、对数据集进行划分后数据集整体不\n纯度下降结果，ID3中采用信息熵作为评估指标，具体计算过程如下：\n首先计算父节点的信息熵\nIn [10]:\n# 父节点A的信息熵\nent_A = -5/14 * np.log2(5/14) - 9/14 * np.log2(9/14)\nent_A\nOut[10]:\n0.9402859586706311\n然后计算每个子节点的信息熵\nIn [16]:\n# 子节点B的信息熵\nent_B1 = entropy(2/5)\nent_B2 = entropy(2/5)\nent_B3 = 0\nent_B1, ent_B2, ent_B3\nOut[16]:\n(0.9709505944546686, 0.9709505944546686, 0)\n同样，子节点整体信息熵就是每个子节点的信息熵加权求和计算得出，其权重就是各子节\n点数据集数量占父节点总数据量的比例：\nIn [20]:\nOut[20]:\nent_B = ent_B1 * 5/14 + ent_B2 * 5/14 + ent_B\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>ID3<|>ORGANIZATION<|>ID3 is a decision tree model that focuses on classification problems around discrete variables and cannot handle continuous features or regression problems without discretizing continuous variables first)\n##\n("entity"<|>C4.5<|>ORGANIZATION<|>C4.5 improves upon ID3 by handling the limitations of ID3, both are classic decision tree algorithms)\n##\n("entity"<|>CART<|>ORGANIZATION<|>CART tree is a type of decision tree that looks for splitting points among all features to reduce dataset impurity, unlike ID3 which expands by columns)\n##\n("relationship"<|>ID3<|>C4.5<|>C4.5 is developed as an improvement over ID3, addressing its limitations<|>8)\n##\n("relationship"<|>ID3<|>CART<|>ID3\'s process of growing and dataset splitting is fundamentally similar to that of CART, but differs in the method of expansion<|>7)\n##\n("relationship"<|>C4.5<|>CART<|>C4.5 and CART share similarities in their basic modeling approach but differ in their specific methodologies and metrics used for dataset splitting<|>6)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:12,763 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 27988, Requested 2722. Please try again in 1.42s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:12,766 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '，因此树模型中的这些控制其随机性的参数，也会在集成学习中发挥作\n用。\n更多关于决策树的使用及各类参数的使用及调参方法，我们将在后续内容中进行详细\n介绍。\nLesson 8.3 ID3、C4.5决策树的建模流程\nID3和C4.5作为的经典决策树算法，尽管无法通过sklearn来进行建模，但其基本原理\n仍然值得讨论与学习。接下来我们详细介绍关于ID3和C4.5这两种决策树模型的建模基本\n思路和原理。ID3和C4.5的基本建模流程和CART树是类似的，也是根据纯度评估指标选取\n最佳的数据集划分方式，只是不过ID3和C4.5是以信息熵为评估指标，而数据集的离散特\n征划分方式也是一次展开一列，而不是寻找切点进行切分。我们先从ID3的基本原理开始\n介绍，随后讨论C4.5在ID3基础上的改善措施。\nIn [9]:\nimport numpy as np\nfrom ML_basic_function import *\n一、ID3决策树的基本建模流程\nID3是一个只能围绕离散型变量进行分类问题建模的决策树模型，即ID3无法处理连续\n型特征、也无法处理回归问题，如果带入训练数据有连续型变量，则首先需要对其进行离\n散化处理，也就是连续变量分箱。例如如下个人消费数据，各特征都是离散型变量，能够\n看出，其中age和income两列就是连续型变量分箱之后的结果，例如age列就是以30、\n40为界进行连续变量分箱。当然，除了如下表示外，我们还可以将分箱之后的结果直接赋\n予一个离散的值，如1、2、3等。\n1\n更多关于连续变量的离散化的方法将在特征工程部分进行介绍。\nID3的生长过程其实和CART树基本一致，其目标都是尽可能降低数据集的不纯度，其\n生长的过程也就是数据集不断划分的过程。只不过ID3的数据集划分过程（规律提取过\n程）和CART树有所不同，CART树是在所有特征中寻找切分点、然后再从中挑选出能够最\n大程度降低数据集不纯度的节分方式，换而言之就是CART树是按照某切分点来展开，而\nID3则是按照列来展开，即根据某列的不同取值来对数据集进行划分。例如根据上述数据\n集中的age列的不同取值来对原始数据集进行划分，则划分结果如下：\n1\n\n同样，我们可以计算在以age的不同取值为划分规则、对数据集进行划分后数据集整体不\n纯度下降结果，ID3中采用信息熵作为评估指标，具体计算过程如下：\n首先计算父节点的信息熵\nIn [10]:\n# 父节点A的信息熵\nent_A = -5/14 * np.log2(5/14) - 9/14 * np.log2(9/14)\nent_A\nOut[10]:\n0.9402859586706311\n然后计算每个子节点的信息熵\nIn [16]:\n# 子节点B的信息熵\nent_B1 = entropy(2/5)\nent_B2 = entropy(2/5)\nent_B3 = 0\nent_B1, ent_B2, ent_B3\nOut[16]:\n(0.9709505944546686, 0.9709505944546686, 0)\n同样，子节点整体信息熵就是每个子节点的信息熵加权求和计算得出，其权重就是各子节\n点数据集数量占父节点总数据量的比例：\nIn [20]:\nOut[20]:\nent_B = ent_B1 * 5/14 + ent_B2 * 5/14 + ent_B'}
11:04:13,513 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:13,513 openai._base_client INFO Retrying request to /chat/completions in 3.084000 seconds
11:04:13,790 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:13,791 openai._base_client INFO Retrying request to /chat/completions in 3.092000 seconds
11:04:13,802 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:13,803 openai._base_client INFO Retrying request to /chat/completions in 3.088000 seconds
11:04:13,937 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:13,938 openai._base_client INFO Retrying request to /chat/completions in 3.080000 seconds
11:04:14,246 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,248 openai._base_client INFO Retrying request to /chat/completions in 3.256000 seconds
11:04:14,249 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,252 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 中，需要先计算GR，然后选择GR计算结果较大的列来\n执行这一次展开。例如对于上述例子来看，以age列展开后Information Gain结果为：\nIn [37]:\nOut[37]:\nIG = ent_A - ent_B\nIG\n0.24674981977443922\n1\nP(vi)\n而IV值为：\nIn [36]:\nOut[36]:\nIV = - (5/14 * np.log2(5/14) + 5/14 * np.log2(5/14)+ 4/14 * np.log2(4/14))\nIV\n1.5774062828523454\n因此计算得到GR值为：\nIn [38]:\nGR = IG / IV\nGR\n\nOut[38]:\n0.1564275624211752\n然后据此进一步计算其他各列展开后的GR值，并选择GR较大者进行数据集划分。\nC4.5的连续变量处理方法\nC4.5允许带入连续变量进行建模，并且围绕连续变量的规则提取方式和此前介绍的\nCART树一致。即在连续变量中寻找相邻的取值的中间点作为备选切分点，通过计算切分\n后的GR值来挑选最终数据集划分方式。当然，基于连续变量的备选切分方式也要和离散\n变量的切分方式进行横向比较，到底是一次展开一个离散列还是按照连续变量的某个切点\n展开，要根据最终GR的计算结果来决定。\n例如，如果将上述数据集的age列换成连续变量，则我们需要计算的GR情况就变成了\nGR(income)、GR(student)、GR(credit_rating)、GR(age<=26.5)、GR(age<=27.5)...\n1\n当然，由于C4.5的离散变量和连续变量提取规则方式不同，离散变量是一\n次消耗一列来进行展开（有可能多分叉），而连续变量则一次消耗一个切分\n点，因此和CART树一样、同一个连续变量可以多次指导数据集进行划分。\n在sklearn的树模型介绍文档中，有一段关于sklearn的决策树不支持离散变\n量建模的说明，其意为不支持按照类似ID3或C4.5的方式直接将离散变量按\n列来进行展开，而是根据sklearn中集成的CART树自身的建模规则，使得\nsklearn中的决策树实际上在处理特征时都是按照C4.5中连续变量的处理方\n式在进行处理，并非指的是带入离散变量就无法建模。\nLesson 8.4 CART回归树的建模流程与\nsklearn参数详解\n接下来，我们继续讨论关于CART回归树的相关内容。\n根据此前介绍，CART树能同时解决分类问题和回归问题，但由于两类问题的性质还\n是存在一定的差异，因此CART树在处理不同类型问题时相应建模流程也略有不同，当然\n对应的sklearn中的评估器也是不同的。并且值得一提的是，尽管回归树单独来看是解决\n回归类问题的模型，但实际上回归树其实是构建梯度提升树（GBDT，一种集成算法）的\n基础分类器，并且无论是解决回归类问题还是分类问题，CART回归树都是唯一的基础分\n类器，因此哪怕单独利用回归树解决问题的场景并不多见，但对于CART回归树的相关方\n法仍然需要重点掌握，从而为后续集成算法的学习奠定基础。\n本节我们将在CART分类树的基础之上详细讨论CART树在处理回归问题时的基本流\n程，并详细介绍关于CART回归树在sklearn中评估器的的相关参数与使用方法。\nIn [2]:\n# 科学计算模块\nimport numpy\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>C4.5<|>ORGANIZATION<|>C4.5 is a decision tree algorithm that allows for modeling with continuous variables, comparing GR values for dataset division based on rules for continuous and discrete variables)\n##\n("entity"<|>CART<|>ORGANIZATION<|>CART (Classification And Regression Trees) is a decision tree technique that can handle both classification and regression problems and is used as a basis for ensemble methods like GBDT)\n##\n("entity"<|>SKLEARN<|>ORGANIZATION<|>Sklearn is a machine learning library for Python, known for its decision tree implementation which does not support discrete variable modeling in the manner of ID3 or C4.5 but treats features in a continuous variable fashion)\n##\n("entity"<|>GBDT<|>ORGANIZATION<|>Gradient Boosting Decision Tree, an ensemble algorithm for which CART regression trees serve as the base classifier)\n##\n("relationship"<|>C4.5<|>CART<|>C4.5 and CART are both decision tree algorithms with different approaches to handling variables and dataset division<|>5)\n##\n("relationship"<|>CART<|>GBDT<|>CART regression trees are used as the base classifier in GBDT ensemble algorithms<|>8)\n##\n("relationship"<|>SKLEARN<|>CART<|>Sklearn implements CART tree modeling rules, focusing on continuous variable treatment<|>7)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:14,252 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28946, Requested 2783. Please try again in 3.458s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:14,256 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '中，需要先计算GR，然后选择GR计算结果较大的列来\n执行这一次展开。例如对于上述例子来看，以age列展开后Information Gain结果为：\nIn [37]:\nOut[37]:\nIG = ent_A - ent_B\nIG\n0.24674981977443922\n1\nP(vi)\n而IV值为：\nIn [36]:\nOut[36]:\nIV = - (5/14 * np.log2(5/14) + 5/14 * np.log2(5/14)+ 4/14 * np.log2(4/14))\nIV\n1.5774062828523454\n因此计算得到GR值为：\nIn [38]:\nGR = IG / IV\nGR\n\nOut[38]:\n0.1564275624211752\n然后据此进一步计算其他各列展开后的GR值，并选择GR较大者进行数据集划分。\nC4.5的连续变量处理方法\nC4.5允许带入连续变量进行建模，并且围绕连续变量的规则提取方式和此前介绍的\nCART树一致。即在连续变量中寻找相邻的取值的中间点作为备选切分点，通过计算切分\n后的GR值来挑选最终数据集划分方式。当然，基于连续变量的备选切分方式也要和离散\n变量的切分方式进行横向比较，到底是一次展开一个离散列还是按照连续变量的某个切点\n展开，要根据最终GR的计算结果来决定。\n例如，如果将上述数据集的age列换成连续变量，则我们需要计算的GR情况就变成了\nGR(income)、GR(student)、GR(credit_rating)、GR(age<=26.5)、GR(age<=27.5)...\n1\n当然，由于C4.5的离散变量和连续变量提取规则方式不同，离散变量是一\n次消耗一列来进行展开（有可能多分叉），而连续变量则一次消耗一个切分\n点，因此和CART树一样、同一个连续变量可以多次指导数据集进行划分。\n在sklearn的树模型介绍文档中，有一段关于sklearn的决策树不支持离散变\n量建模的说明，其意为不支持按照类似ID3或C4.5的方式直接将离散变量按\n列来进行展开，而是根据sklearn中集成的CART树自身的建模规则，使得\nsklearn中的决策树实际上在处理特征时都是按照C4.5中连续变量的处理方\n式在进行处理，并非指的是带入离散变量就无法建模。\nLesson 8.4 CART回归树的建模流程与\nsklearn参数详解\n接下来，我们继续讨论关于CART回归树的相关内容。\n根据此前介绍，CART树能同时解决分类问题和回归问题，但由于两类问题的性质还\n是存在一定的差异，因此CART树在处理不同类型问题时相应建模流程也略有不同，当然\n对应的sklearn中的评估器也是不同的。并且值得一提的是，尽管回归树单独来看是解决\n回归类问题的模型，但实际上回归树其实是构建梯度提升树（GBDT，一种集成算法）的\n基础分类器，并且无论是解决回归类问题还是分类问题，CART回归树都是唯一的基础分\n类器，因此哪怕单独利用回归树解决问题的场景并不多见，但对于CART回归树的相关方\n法仍然需要重点掌握，从而为后续集成算法的学习奠定基础。\n本节我们将在CART分类树的基础之上详细讨论CART树在处理回归问题时的基本流\n程，并详细介绍关于CART回归树在sklearn中评估器的的相关参数与使用方法。\nIn [2]:\n# 科学计算模块\nimport numpy'}
11:04:14,275 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,278 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: matplotlib.lines.Line2D at 0x7fbeaafe80d0>,\n<matplotlib.lines.Line2D at 0x7fbeaafe8100>]\n多个数据集的平均指标\n在很多时候，我们不仅需要衡量单独数据集标签的纯度，我们还需要衡量多个数据集\n作为一个整体时的标签的纯度，例如一个父节点在划分成两个子节点时两个子节点整体的\n评估指标。此处我们举例说明：我们简化一组后续建模会用到的客户数据，简化后的数据\n集A共有两个特征、一个标签，并且标签只有0-1两个类别，数据集特征分别是收入\n（income）和信用评级（credit_rating），同样也都用有两个分类水平的离散变量表\n示。\n1\n此时我们首先可以计算该数据集整体的基尼系数：\nIn [10]:\np = 3/8\ngini_A = 1 - np.power([p, 1-p], 2).sum()\ngini_A\nOut[10]:\n0.46875\n然后我们随意设置一个分类条件。例如我们设置分类条件为income <= 1.5，则可以将上\n述数据集进一步划分成两个子数据集B1、B2:\n\n1\nIn [11]:\np = 2/5\ngini_B1 = 1 - np.power([p, 1-p], 2).sum()\ngini_B1\nOut[11]:\n0.48\nIn [12]:\n而B2数据集只包含一个标签，因此B2的基尼系数为0\ngini_B2 = 0\n而此时如果要计算B1、B2整体的基尼系数，则需要在gini_B1、gini_B2的基础上进行各自\n数据集样本数量占整体数据集比例的加权求和，即根据如下方式进行计算：\nGini(B) =\n其中 为子数据集 数据个数占父类数据集A中数据个数的比例。因此上述 、 整\n体基尼系数为：\n|Bi|\n|A|\nBi\nB1 B2\nIn [13]:\nOut[13]:\ngini_B = gini_B1 * 5/8 + gini_B2 * 3/8\ngini_B\n0.3\n至此，我们就构建了一个用于描述数据集划分完后两个子集的整体纯度的方法，而我们知\n道，子集整体纯度越高，其实也就说明对应分类规则越有效。接下来我们将详细讨论如何\n构建分类规则以及如何对这些分类规则进行评估。\n1.2 决策树备选规则创建方法\n正如此前所说，决策树模型的建模过程实际上就是在挑选有效分类规则的过程，而要\n挑选有效分类规则，首先就必须明确如何创建哪些备选规则，其实对于很多树模型，特征\n是离散型变量还是连续性变量会直接影响备选规则的创建，但对于CART树以及slearn中\n集成的方法来说，是将两种情况合二为一来进行看待，也就是根据如下方式来进行备选规\n则的创建：\n对于任何特征矩阵，首先需要逐列对其进行数值排序，例如上述数据集A，我们可以\n单独提取income和credit_rating两列来进行降序排序，排序结果如下：\n1\n|B1|\n|A|\nGini(B1) +\n|B2|\n|A|\nGini(B2)\n1\n据此，我们通过寻找这些特征不同取值之间的中间点作为切点，来构造备选规则。例\n如income有两个取值1、2，因此只有一个切点就是1.5，那么我们就能创造一个income\n<= 1.5的规则来对数据集进行划分，如此我们就能把income取值为1的数据划归一个子\n\n集、income取值为2的数据集划归另一个子集，实际上上面在介绍多数据集基尼系数计算\n过程时就是采用该规则。需要知道的是，在所构造的条件中不等号的方向实际上没有任何\n影响。当然，income只有两个取值只能找到一个切点只能构造一个规则，\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>GINI_A<|>EVENT<|>Calculation of the overall Gini coefficient for dataset A, indicating the purity of labels in the dataset)\n##\n("entity"<|>GINI_B1<|>EVENT<|>Gini coefficient for subset B1 after dataset A is divided based on a certain condition)\n##\n("entity"<|>GINI_B2<|>EVENT<|>Gini coefficient for subset B2, which contains only one label, thus having a Gini coefficient of 0)\n##\n("entity"<|>INCOME<|>ORGANIZATION<|>A feature in dataset A representing the income level, used to divide the dataset into subsets)\n##\n("entity"<|>CREDIT_RATING<|>ORGANIZATION<|>A feature in dataset A representing the credit rating level, used in the analysis of the dataset\'s purity)\n##\n("relationship"<|>GINI_A<|>INCOME<|>Gini_A\'s calculation involves the income feature as part of the dataset\'s attributes<|>5)\n##\n("relationship"<|>GINI_A<|>CREDIT_RATING<|>Gini_A\'s calculation involves the credit rating feature as part of the dataset\'s attributes<|>5)\n##\n("relationship"<|>GINI_B1<|>INCOME<|>Gini_B1\'s calculation is based on a condition set on the income feature<|>7)\n##\n("relationship"<|>GINI_B2<|>INCOME<|>Gini_B2\'s calculation is influenced by the division of the dataset using the income feature, even though it directly results in a Gini coefficient of 0<|>6)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:14,278 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28933, Requested 2822. Please try again in 3.51s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:14,279 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'matplotlib.lines.Line2D at 0x7fbeaafe80d0>,\n<matplotlib.lines.Line2D at 0x7fbeaafe8100>]\n多个数据集的平均指标\n在很多时候，我们不仅需要衡量单独数据集标签的纯度，我们还需要衡量多个数据集\n作为一个整体时的标签的纯度，例如一个父节点在划分成两个子节点时两个子节点整体的\n评估指标。此处我们举例说明：我们简化一组后续建模会用到的客户数据，简化后的数据\n集A共有两个特征、一个标签，并且标签只有0-1两个类别，数据集特征分别是收入\n（income）和信用评级（credit_rating），同样也都用有两个分类水平的离散变量表\n示。\n1\n此时我们首先可以计算该数据集整体的基尼系数：\nIn [10]:\np = 3/8\ngini_A = 1 - np.power([p, 1-p], 2).sum()\ngini_A\nOut[10]:\n0.46875\n然后我们随意设置一个分类条件。例如我们设置分类条件为income <= 1.5，则可以将上\n述数据集进一步划分成两个子数据集B1、B2:\n\n1\nIn [11]:\np = 2/5\ngini_B1 = 1 - np.power([p, 1-p], 2).sum()\ngini_B1\nOut[11]:\n0.48\nIn [12]:\n而B2数据集只包含一个标签，因此B2的基尼系数为0\ngini_B2 = 0\n而此时如果要计算B1、B2整体的基尼系数，则需要在gini_B1、gini_B2的基础上进行各自\n数据集样本数量占整体数据集比例的加权求和，即根据如下方式进行计算：\nGini(B) =\n其中 为子数据集 数据个数占父类数据集A中数据个数的比例。因此上述 、 整\n体基尼系数为：\n|Bi|\n|A|\nBi\nB1 B2\nIn [13]:\nOut[13]:\ngini_B = gini_B1 * 5/8 + gini_B2 * 3/8\ngini_B\n0.3\n至此，我们就构建了一个用于描述数据集划分完后两个子集的整体纯度的方法，而我们知\n道，子集整体纯度越高，其实也就说明对应分类规则越有效。接下来我们将详细讨论如何\n构建分类规则以及如何对这些分类规则进行评估。\n1.2 决策树备选规则创建方法\n正如此前所说，决策树模型的建模过程实际上就是在挑选有效分类规则的过程，而要\n挑选有效分类规则，首先就必须明确如何创建哪些备选规则，其实对于很多树模型，特征\n是离散型变量还是连续性变量会直接影响备选规则的创建，但对于CART树以及slearn中\n集成的方法来说，是将两种情况合二为一来进行看待，也就是根据如下方式来进行备选规\n则的创建：\n对于任何特征矩阵，首先需要逐列对其进行数值排序，例如上述数据集A，我们可以\n单独提取income和credit_rating两列来进行降序排序，排序结果如下：\n1\n|B1|\n|A|\nGini(B1) +\n|B2|\n|A|\nGini(B2)\n1\n据此，我们通过寻找这些特征不同取值之间的中间点作为切点，来构造备选规则。例\n如income有两个取值1、2，因此只有一个切点就是1.5，那么我们就能创造一个income\n<= 1.5的规则来对数据集进行划分，如此我们就能把income取值为1的数据划归一个子\n\n集、income取值为2的数据集划归另一个子集，实际上上面在介绍多数据集基尼系数计算\n过程时就是采用该规则。需要知道的是，在所构造的条件中不等号的方向实际上没有任何\n影响。当然，income只有两个取值只能找到一个切点只能构造一个规则，'}
11:04:14,302 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,302 openai._base_client INFO Retrying request to /chat/completions in 2.250000 seconds
11:04:14,312 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,314 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: , 0.9709505944546686, 0)\n同样，子节点整体信息熵就是每个子节点的信息熵加权求和计算得出，其权重就是各子节\n点数据集数量占父节点总数据量的比例：\nIn [20]:\nOut[20]:\nent_B = ent_B1 * 5/14 + ent_B2 * 5/14 + ent_B3 * 4/14\nent_B\n0.6935361388961919\n然后即可算出按照如此规则进行数据集划分，最终能够减少的不纯度数值：\nIn [21]:\nOut[21]:\n# 不纯度下降结果\nent_A - ent_B\n0.24674981977443922\n而该结果也被称为根据age列进行数据集划分后的信息增益（information gain），上述\n结果可写成Gain(age) = 0.247\n当然，至此我们只计算了按照age列的不同取值来进行数据集划分后数据集不纯度下\n降结果，而按照age列进行展开只能算是树的第一步生长中的一个备选划分规则，此外我\n们还需要测试按照income、student或者credit_rating列展开后数据集不纯度下降情况，\n具体计算过程和age列展开后的计算过程类似，此处直接给出结果，\nGain(income)=0.026、Gain(student)=0.151、Gain(credit_rating)=0.048。很明显，\n按照age列展开能够更有效的降低数据集的不纯度，因此树的第一层生长就是按照age列\n的不同取值对数据集进行划分。\n1\n接下来需要继续进行迭代，通过观察我们不难发现，对于数据集B1来说来说，按照\nstudent这一列来进行展开，能够让子节点的信息熵归零，而数据集B2按照如果按照\n\ncredit_rating来展开，也同样可以将子节点的标签纯度提高至100%。因此该模型最终树\n的生长形态如下：\n1\n至此，我们就完成了ID3决策树的建模全流程，具体模型结果解读和CART树完全一\n样，此处不做赘述。接下来简单对比ID3和CART树之间的差异：首先，由于ID3是按照列\n来提取规则、每次展开一列，因此每一步生长会有几个分支，其实完全由当前列有几个分\n类水平决定，而CART树只能进行二叉树的生长；其次，由于ID3每次展开一列，因此建模\n过程中对“列的消耗”非常快，数据集中特征个数就决定了树的最大深度，相比之下CART树\n的备选规则就要多的多，这也使得CART树能够进行更加精细的规则提取；当然，尽管\nCART树和ID3存在着基本理论层面的差异，但有的时候也能通过CART树的方法来挖掘出\n和ID3决策树相同的规律，例如ID3中按照age列一层展开所提取出的三个分类规则，也可\n以在CART树中通过两层树来实现，例如第一层按照是否是<=30来进行划分、第二层围绕\n不满足第一层条件的数据集进一步根据是否>40来进行划分。\n此外，需要注意的是，正因为ID3是按照列来进行展开，因此只能处理特征都是离散\n变量的数据集。另外，根据ID3的建模规则我们不难发现，ID3树在实际生长过程中会更倾\n向于挑选取值较多的分类变量展开，但如此一来便更加容易造成模型过拟合，而遗憾的是\nID3并没有任何防止过拟合的措施。而这些ID3的缺陷，则正是C4.5算法的改进方向。接\n下来我们继续讨论关于C4.5决策树的建模规\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>ID3 DECISION TREE<|>ORGANIZATION<|>A model that grows by expanding a column at each step, leading to multiple branches based on the number of categories in the current column. It is designed for datasets with discrete variables and can lead to overfitting due to its preference for variables with more categories)\n##\n("entity"<|>CART TREE<|>ORGANIZATION<|>A model that grows as a binary tree, allowing for more refined rule extraction compared to ID3. It can handle both discrete and continuous variables and offers a broader set of rules for model growth)\n##\n("entity"<|>C4.5 ALGORITHM<|>ORGANIZATION<|>An improvement over the ID3 decision tree model, addressing its limitations by allowing for the handling of continuous variables and implementing measures to prevent overfitting)\n##\n("relationship"<|>ID3 DECISION TREE<|>CART TREE<|>ID3 and CART represent different approaches to decision tree modeling, with ID3 expanding one column at a time and CART growing as a binary tree<|>5)\n##\n("relationship"<|>ID3 DECISION TREE<|>C4.5 ALGORITHM<|>The C4.5 algorithm is an evolution of the ID3 decision tree, designed to overcome its limitations<|>8)\n##\n("relationship"<|>CART TREE<|>C4.5 ALGORITHM<|>Both CART and C4.5 offer solutions to the limitations of the ID3 model, with C4.5 directly addressing ID3\'s shortcomings<|>6)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:14,314 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28935, Requested 2816. Please try again in 3.502s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:14,316 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ', 0.9709505944546686, 0)\n同样，子节点整体信息熵就是每个子节点的信息熵加权求和计算得出，其权重就是各子节\n点数据集数量占父节点总数据量的比例：\nIn [20]:\nOut[20]:\nent_B = ent_B1 * 5/14 + ent_B2 * 5/14 + ent_B3 * 4/14\nent_B\n0.6935361388961919\n然后即可算出按照如此规则进行数据集划分，最终能够减少的不纯度数值：\nIn [21]:\nOut[21]:\n# 不纯度下降结果\nent_A - ent_B\n0.24674981977443922\n而该结果也被称为根据age列进行数据集划分后的信息增益（information gain），上述\n结果可写成Gain(age) = 0.247\n当然，至此我们只计算了按照age列的不同取值来进行数据集划分后数据集不纯度下\n降结果，而按照age列进行展开只能算是树的第一步生长中的一个备选划分规则，此外我\n们还需要测试按照income、student或者credit_rating列展开后数据集不纯度下降情况，\n具体计算过程和age列展开后的计算过程类似，此处直接给出结果，\nGain(income)=0.026、Gain(student)=0.151、Gain(credit_rating)=0.048。很明显，\n按照age列展开能够更有效的降低数据集的不纯度，因此树的第一层生长就是按照age列\n的不同取值对数据集进行划分。\n1\n接下来需要继续进行迭代，通过观察我们不难发现，对于数据集B1来说来说，按照\nstudent这一列来进行展开，能够让子节点的信息熵归零，而数据集B2按照如果按照\n\ncredit_rating来展开，也同样可以将子节点的标签纯度提高至100%。因此该模型最终树\n的生长形态如下：\n1\n至此，我们就完成了ID3决策树的建模全流程，具体模型结果解读和CART树完全一\n样，此处不做赘述。接下来简单对比ID3和CART树之间的差异：首先，由于ID3是按照列\n来提取规则、每次展开一列，因此每一步生长会有几个分支，其实完全由当前列有几个分\n类水平决定，而CART树只能进行二叉树的生长；其次，由于ID3每次展开一列，因此建模\n过程中对“列的消耗”非常快，数据集中特征个数就决定了树的最大深度，相比之下CART树\n的备选规则就要多的多，这也使得CART树能够进行更加精细的规则提取；当然，尽管\nCART树和ID3存在着基本理论层面的差异，但有的时候也能通过CART树的方法来挖掘出\n和ID3决策树相同的规律，例如ID3中按照age列一层展开所提取出的三个分类规则，也可\n以在CART树中通过两层树来实现，例如第一层按照是否是<=30来进行划分、第二层围绕\n不满足第一层条件的数据集进一步根据是否>40来进行划分。\n此外，需要注意的是，正因为ID3是按照列来进行展开，因此只能处理特征都是离散\n变量的数据集。另外，根据ID3的建模规则我们不难发现，ID3树在实际生长过程中会更倾\n向于挑选取值较多的分类变量展开，但如此一来便更加容易造成模型过拟合，而遗憾的是\nID3并没有任何防止过拟合的措施。而这些ID3的缺陷，则正是C4.5算法的改进方向。接\n下来我们继续讨论关于C4.5决策树的建模规'}
11:04:14,364 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,365 openai._base_client INFO Retrying request to /chat/completions in 2.672000 seconds
11:04:14,537 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,538 openai._base_client INFO Retrying request to /chat/completions in 3.258000 seconds
11:04:14,569 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,572 openai._base_client INFO Retrying request to /chat/completions in 3.298000 seconds
11:04:14,915 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,948 openai._base_client INFO Retrying request to /chat/completions in 3.348000 seconds
11:04:15,81 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:15,83 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: ``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\n\nmin_impurity_split : float, default=0\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead.\nclass_weight : dict, list of dict or "balanced", default=None\nWeights associated with classes in the form ``{class_label: weight}``.\nIf None, all classes are supposed to have weight one. For\nmulti-output problems, a list of dicts can be provided in the same\norder as the columns of y.\nNote that for multioutput (including multilabel) weights should be\ndefined for each class of every column in its own dict. For example,\nfor four-class multilabel classification weights should be\n[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n[{1:1}, {2:5}, {3:1}, {4:1}].\nThe "balanced" mode uses the values of y to automatically adjust\nweights inversely proportional to class frequencies in the input data\nas ``n_samples / (n_classes * np.bincount(y))``\nFor multi-output, the weights of each column of y will be multiplied.\nNote that these weights will be multiplied with sample_weight (passed\nthrough the fit method) if sample_weight is specified.\npresort : deprecated, default=\'deprecated\'\nThis parameter is deprecated and will be removed in v0.24.\n.. deprecated:: 0.22\nccp_alpha : non-negative float, default=0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. The\nsubtree with the largest cost complexity that is smaller than\n``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n:ref:`minimal_cost_complexity_pruning` for details.\n.. versionadded:: 0.22\nAttributes\n---------\nclasses_ : ndarray of shape (n_classes,) or list of ndarray\nThe classes labels (single output problem),\nor a list of arrays of class labels (multi-output problem).\nfeature_importances_ : ndarray of shape (n_features,)\nThe impurity-based feature importances.\nThe higher, the more important the feature.\nThe importance of a feature is computed as the (normalized)\ntotal reduction of the criterion brought by that feature. It is also\nknown as the Gini importance [4]_.\nWarning: impurity-based feature importances can be misleading for\nhigh cardinality features (many unique values). See\n\n:func:`sklearn.inspection.permutation_importance` as an alternative.\nmax_features_ : int\nThe inferred value of max_features.\nn_classes_ : int or list of int\nThe number of classes (for single output problems),\nor a list containing the number of classes for each\noutput (for multi-output problems).\nn_features_ : int\nThe number of features when ``fit`` is performed.\nn_outputs_ : int\nThe number of outputs when ``fit`` is performed.\ntree_ : Tree\nThe underlying Tree object. Please refer to\n``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n:ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\nfor basic usage of these attributes.\nSee Also\n-------\nDecisionTreeRegressor : A decision tree regressor.\nNotes\n----\nThe default values for the parameters controlling the size of the trees\n(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\nunpruned trees which can potentially be very large on some data sets. To\nreduce memory consumption, the complexity and size of the trees should be\ncontrolled by setting those parameter values.\nReferences\n---------\n.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n.. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, "Classification\nand Regression Trees", Wadsworth, Belmont, CA, 1984.\n.. [3] T. Hastie, R. Tibshirani and J. Friedman. "Elements of Statistical\nLearning", Springer, 2009.\n.. [4] L. Breiman, and A. Cutler, "Random Forests",\nhttps://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\nExamples\n-------\n>>> from sklearn.datasets import load_iris\n>>> from sklearn.model_selection import cross_val_score\n>>> from sklearn.tree import DecisionTreeClassifier\n>>> clf = DecisionTreeClassifier(random_state=0)\n>>> iris = load_iris()\n>>> cross_val_score(clf, iris.data, iris.target, cv=10)\n...\n# doctest: +SKIP\n...\narray([ 1.\n, 0.93..., 0.86..., 0.93..., 0.93...,\n0.93..., 0.93..., 1.\n, 0.93..., 1.\n])\n\nFile:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\ns.py\nType:\nSubclasses:\nName\ncriterion\nsplitter\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>DECISIONTREECLASSIFIER<|>ORGANIZATION<|>A classifier with a decision tree model from the sklearn library, used for classifying data based on features)\n##\n("entity"<|>SKLEARN<|>ORGANIZATION<|>A machine learning library for the Python programming language)\n##\n("entity"<|>IRIS<|>ORGANIZATION<|>A dataset used for demonstrating the DecisionTreeClassifier in sklearn, consisting of data on iris flowers)\n##\n("relationship"<|>DECISIONTREECLASSIFIER<|>SKLEARN<|>DecisionTreeClassifier is a part of the sklearn library<|>9)\n##\n("relationship"<|>DECISIONTREECLASSIFIER<|>IRIS<|>DecisionTreeClassifier is demonstrated using the iris dataset in sklearn examples<|>5)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:15,83 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28223, Requested 2989. Please try again in 2.424s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:15,85 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\n\nmin_impurity_split : float, default=0\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead.\nclass_weight : dict, list of dict or "balanced", default=None\nWeights associated with classes in the form ``{class_label: weight}``.\nIf None, all classes are supposed to have weight one. For\nmulti-output problems, a list of dicts can be provided in the same\norder as the columns of y.\nNote that for multioutput (including multilabel) weights should be\ndefined for each class of every column in its own dict. For example,\nfor four-class multilabel classification weights should be\n[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n[{1:1}, {2:5}, {3:1}, {4:1}].\nThe "balanced" mode uses the values of y to automatically adjust\nweights inversely proportional to class frequencies in the input data\nas ``n_samples / (n_classes * np.bincount(y))``\nFor multi-output, the weights of each column of y will be multiplied.\nNote that these weights will be multiplied with sample_weight (passed\nthrough the fit method) if sample_weight is specified.\npresort : deprecated, default=\'deprecated\'\nThis parameter is deprecated and will be removed in v0.24.\n.. deprecated:: 0.22\nccp_alpha : non-negative float, default=0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. The\nsubtree with the largest cost complexity that is smaller than\n``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n:ref:`minimal_cost_complexity_pruning` for details.\n.. versionadded:: 0.22\nAttributes\n---------\nclasses_ : ndarray of shape (n_classes,) or list of ndarray\nThe classes labels (single output problem),\nor a list of arrays of class labels (multi-output problem).\nfeature_importances_ : ndarray of shape (n_features,)\nThe impurity-based feature importances.\nThe higher, the more important the feature.\nThe importance of a feature is computed as the (normalized)\ntotal reduction of the criterion brought by that feature. It is also\nknown as the Gini importance [4]_.\nWarning: impurity-based feature importances can be misleading for\nhigh cardinality features (many unique values). See\n\n:func:`sklearn.inspection.permutation_importance` as an alternative.\nmax_features_ : int\nThe inferred value of max_features.\nn_classes_ : int or list of int\nThe number of classes (for single output problems),\nor a list containing the number of classes for each\noutput (for multi-output problems).\nn_features_ : int\nThe number of features when ``fit`` is performed.\nn_outputs_ : int\nThe number of outputs when ``fit`` is performed.\ntree_ : Tree\nThe underlying Tree object. Please refer to\n``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n:ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\nfor basic usage of these attributes.\nSee Also\n-------\nDecisionTreeRegressor : A decision tree regressor.\nNotes\n----\nThe default values for the parameters controlling the size of the trees\n(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\nunpruned trees which can potentially be very large on some data sets. To\nreduce memory consumption, the complexity and size of the trees should be\ncontrolled by setting those parameter values.\nReferences\n---------\n.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n.. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, "Classification\nand Regression Trees", Wadsworth, Belmont, CA, 1984.\n.. [3] T. Hastie, R. Tibshirani and J. Friedman. "Elements of Statistical\nLearning", Springer, 2009.\n.. [4] L. Breiman, and A. Cutler, "Random Forests",\nhttps://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\nExamples\n-------\n>>> from sklearn.datasets import load_iris\n>>> from sklearn.model_selection import cross_val_score\n>>> from sklearn.tree import DecisionTreeClassifier\n>>> clf = DecisionTreeClassifier(random_state=0)\n>>> iris = load_iris()\n>>> cross_val_score(clf, iris.data, iris.target, cv=10)\n...\n# doctest: +SKIP\n...\narray([ 1.\n, 0.93..., 0.86..., 0.93..., 0.93...,\n0.93..., 0.93..., 1.\n, 0.93..., 1.\n])\n\nFile:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\ns.py\nType:\nSubclasses:\nName\ncriterion\nsplitter'}
11:04:16,939 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:16,941 openai._base_client INFO Retrying request to /chat/completions in 0.304000 seconds
11:04:17,246 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:17,249 openai._base_client INFO Retrying request to /chat/completions in 4.704000 seconds
11:04:17,355 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:17,358 openai._base_client INFO Retrying request to /chat/completions in 4.710000 seconds
11:04:17,393 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:17,394 openai._base_client INFO Retrying request to /chat/completions in 4.064000 seconds
11:04:17,394 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:17,395 openai._base_client INFO Retrying request to /chat/completions in 4.672000 seconds
11:04:17,590 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:17,591 openai._base_client INFO Retrying request to /chat/completions in 4.024000 seconds
11:04:17,877 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:17,878 openai._base_client INFO Retrying request to /chat/completions in 4.688000 seconds
11:04:18,208 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:18,210 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 种混合模型。\n此外，与其说CART树是一个非常“机器学习”的算法，不如说CART树是一个\n更加适合使用机器学习的方法来进行建模的模型，机器学习或者统计学建模\n方法更大程度上是一种建模思路，很多模型（像逻辑回归、包括树模型在\n内）其实都有机器学习实现的方式和统计学模型实现的方法。\n\nCHAID树\nCHAID是Chi-square automatic interaction detection的简称，由Kass在1975年提\n出，如果说CART树是一个典型的机器学习算法，那么CHAID树就是一个典型的统计学算\n法。从该算法的名字就能看出，整个决策树其实是基于卡方检验（Chi-square）的结果来\n构建的，并且整个决策树的建模流程（树的生长过程）及控制过拟合的方法（剪枝过程）\n都和C4.5、CART有根本性的区别，例如CART都只能构建二叉树，而CHAID可以构建多\n分枝的树（注：C4.5也可以构建多分枝的树）；例如C4.5和CART的剪枝都是自下而上\n（Bottom-up）进行剪枝，也被称为修剪法（Pruning Technique），而CHAID树则是自\n上而下（Top-Down）进行剪枝，也被称为盆栽法（Bonsai Technique）。当然，该决策\n树算法目前并非主流树模型，因此我们此处仅作简单介绍，并不做更加深入的探讨。\n上述讨论所涉及到的关键概念，如剪枝、划分规则提取方式、划分规则评估\n指标等内容，我们都将在下一小节进行详细介绍。\n在课程接下来的部分，我们将重点讨论关于CART树的建模流程，以及在Scikit-Learn\n中的实现方法。同时，ID3、C4.5决策树作为经典模型，尽管我们无法在sklearn中实现相\n关模型的建模，但对这些算法的了解仍然会非常有助于我们理解树模型的建模思想，因此\n我们后续也会以加餐形式介绍ID3、C4.5的基本建模流程。\nLesson 8.2 CART分类树的建模流程与\nsklearn评估器参数详解\n根据上一小节的介绍我们知道，CART树是目前机器学习领域内最通用的决策树，并\n且CART树能够同时解决分类问题和回归问题。本节我们将首先介绍关于CART树在进行分\n类问题建模时的基本流程，同时详细讲解sklearn中相关评估器的参数情况与使用方法。\nIn [1]:\n# 科学计算模块\nimport numpy as np\nimport pandas as pd\n# 绘图模块\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n# 自定义模块\nfrom ML_basic_function import *\n# Scikit-Learn相关模块\n# 评估器类\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\n# 实用函数\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\n# 数据准备\nfrom sklearn.datasets import load_iris\n一、CART决策树的分类流程\n从基本原理来说，决策是一种非常通用的模型，在模型训练时可以带入分类变量、也\n可以带入连续变量，同时在进行预测时既能解决分类问题也能解决回归问题，在介绍\nCART树的原理时，我们先从简单入手，先考虑自变量都是离散变量的分类预测问题，再\n逐步拓展连续变量的处理方法和回归类问题的预测方法。\n1.CART树的基本生长过程\n首先我们来看在特征都为分类变量时、围绕分类问题构建\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>CART树<|>ORGANIZATION<|>CART树是一种在机器学习领域内广泛使用的决策树，能够处理分类和回归问题)\n##\n("entity"<|>CHAID树<|>ORGANIZATION<|>CHAID树是基于卡方检验结果构建的决策树，能够构建多分枝的树，采用自上而下的剪枝方法)\n##\n("entity"<|>SCIKIT-LEARN<|>ORGANIZATION<|>Scikit-Learn是一个开源的机器学习库，提供了多种机器学习模型的实现)\n##\n("entity"<|>ID3<|>ORGANIZATION<|>ID3决策树是一种经典的决策树学习算法，主要用于处理分类问题)\n##\n("entity"<|>C4.5<|>ORGANIZATION<|>C4.5决策树是ID3算法的改进版本，可以构建多分枝的树，并处理更复杂的分类问题)\n##\n("relationship"<|>CART树<|>SCIKIT-LEARN<|>CART树的建模流程及其在Scikit-Learn中的实现方法将被详细讨论<|>8)\n##\n("relationship"<|>CHAID树<|>CART树<|>CHAID树与CART树在决策树构建和剪枝方法上有根本性的区别<|>5)\n##\n("relationship"<|>ID3<|>C4.5<|>C4.5是ID3算法的改进版本，处理更复杂的分类问题<|>9)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:18,210 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29497, Requested 2826. Please try again in 4.646s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:18,212 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '种混合模型。\n此外，与其说CART树是一个非常“机器学习”的算法，不如说CART树是一个\n更加适合使用机器学习的方法来进行建模的模型，机器学习或者统计学建模\n方法更大程度上是一种建模思路，很多模型（像逻辑回归、包括树模型在\n内）其实都有机器学习实现的方式和统计学模型实现的方法。\n\nCHAID树\nCHAID是Chi-square automatic interaction detection的简称，由Kass在1975年提\n出，如果说CART树是一个典型的机器学习算法，那么CHAID树就是一个典型的统计学算\n法。从该算法的名字就能看出，整个决策树其实是基于卡方检验（Chi-square）的结果来\n构建的，并且整个决策树的建模流程（树的生长过程）及控制过拟合的方法（剪枝过程）\n都和C4.5、CART有根本性的区别，例如CART都只能构建二叉树，而CHAID可以构建多\n分枝的树（注：C4.5也可以构建多分枝的树）；例如C4.5和CART的剪枝都是自下而上\n（Bottom-up）进行剪枝，也被称为修剪法（Pruning Technique），而CHAID树则是自\n上而下（Top-Down）进行剪枝，也被称为盆栽法（Bonsai Technique）。当然，该决策\n树算法目前并非主流树模型，因此我们此处仅作简单介绍，并不做更加深入的探讨。\n上述讨论所涉及到的关键概念，如剪枝、划分规则提取方式、划分规则评估\n指标等内容，我们都将在下一小节进行详细介绍。\n在课程接下来的部分，我们将重点讨论关于CART树的建模流程，以及在Scikit-Learn\n中的实现方法。同时，ID3、C4.5决策树作为经典模型，尽管我们无法在sklearn中实现相\n关模型的建模，但对这些算法的了解仍然会非常有助于我们理解树模型的建模思想，因此\n我们后续也会以加餐形式介绍ID3、C4.5的基本建模流程。\nLesson 8.2 CART分类树的建模流程与\nsklearn评估器参数详解\n根据上一小节的介绍我们知道，CART树是目前机器学习领域内最通用的决策树，并\n且CART树能够同时解决分类问题和回归问题。本节我们将首先介绍关于CART树在进行分\n类问题建模时的基本流程，同时详细讲解sklearn中相关评估器的参数情况与使用方法。\nIn [1]:\n# 科学计算模块\nimport numpy as np\nimport pandas as pd\n# 绘图模块\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n# 自定义模块\nfrom ML_basic_function import *\n# Scikit-Learn相关模块\n# 评估器类\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\n# 实用函数\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\n# 数据准备\nfrom sklearn.datasets import load_iris\n一、CART决策树的分类流程\n从基本原理来说，决策是一种非常通用的模型，在模型训练时可以带入分类变量、也\n可以带入连续变量，同时在进行预测时既能解决分类问题也能解决回归问题，在介绍\nCART树的原理时，我们先从简单入手，先考虑自变量都是离散变量的分类预测问题，再\n逐步拓展连续变量的处理方法和回归类问题的预测方法。\n1.CART树的基本生长过程\n首先我们来看在特征都为分类变量时、围绕分类问题构建'}
11:04:18,219 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:18,220 openai._base_client INFO Retrying request to /chat/completions in 4.624000 seconds
11:04:18,646 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:18,650 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 度，而C4.5也是目前最为通用的决策树模型的一般框架，后续尽管有其他的决策树\n模型诞生，但大都是在C4.5的基本流程上进行略微调整或者指标修改，甚至在C4.5还被\nIEEE评为10大数据挖掘算法之首，由此可见C4.5算法的巨大影响力。此外，由于C4.5开源\n时间较早，这也使得在过去的很长一段时间内，C4.5都是最通用的决策树算法。当然在此\n后，Ross Quinlan又公布了C5.0算法，进一步优化了运行效率和预测流程，通过一系列数\n据结构的调整使得其能够更加高效的利用内存、并提高执行速度。当然，由于C5.0在很长\n的一段时间是作为收费软件存在、并且多集成与像SAS软件中，因此并未被最广泛的应用\n于各领域。\n此外，值得一提的是，由于Ross Quinlan拥有非常深厚的数学背景，因此在设计决策\n树算法的时候，尽管决策树是一种非参数方法（无需提前进行数据训练的假设检验），但\n在实际执行决策树剪枝（一种防止过拟合的手段）时却需要用到非常多统计学方法，在实\n际构建模型时也无需划分训练集和测试集，因此C4.5其实更像是一种统计学算法，而非机\n器学习算法。\n需要知道的是，C4.5在树的生长上还是更像机器学习算法，而这种半“统计\n学”半“机器学习”的状态也是该算法存在争议的地方。\nCART决策树\nCART全称为Classification and Regression Trees，即分类与回归决策树，同时也被\n称为C&RT算法，在1984年由Breiman、Friedman、Olshen和Stone四人共同提出。\nCART树和C4.5决策树的构造过程非常类似，但拓展了回归类问题的计算流程（此前C4.5\n只能解决分类问题），并且允许采用更丰富的评估指标来指导建模流程，并且，最关键的\n是，CART算法其实是一个非常典型的机器学习算法，在早期CART树的训练过程中，就是\n通过划分训练集和验证集（或者测试集）来验证模型结果、并进一步据此来调整模型结\n构，当然，除此以外，CART树还能够用一套流程同时处理离散变量和连续变量、能够同\n时处理分类问题和回归问题，这些都符合一个机器学习领域要求算法有更普适的功能和更\n强的鲁棒性的要求，这也是为何近几年CART树会更加流行的主要原因。当然，在skelarn\n中，决策树模型评估器集成的也是CART树模型，稍后我们在介绍决策树建模流程的时候\n也将主要介绍CART树的建模流程。\n此处我们也可以参考sklearn中对于ID3、C4.5和CART树的对比描述：\n1\n需要注意的是，sklearn中也并非实现的是完全的CART树，通过相关评估器\n参数的调整，sklearn中也能实现“CART树的建模流程+C4.5的决策树生长\n指标”这种混合模型。\n此外，与其说CART树是一个非常“机器学习”的算法，不如说CART树是一个\n更加适合使用机器学习的方法来进行建模的模型，机器学习或者统计学建模\n方法更大程度上是一种建模思路，很多模型（像逻辑回\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>C4.5<|>ORGANIZATION<|>C4.5 is a widely used decision tree model framework, recognized for its significant impact in data mining and has been ranked by IEEE as one of the top 10 data mining algorithms. It is open-source and has been the most common decision tree algorithm for a long time. Ross Quinlan later introduced C5.0, an optimization of C4.5, enhancing efficiency and prediction processes but was initially proprietary and integrated into software like SAS, limiting its widespread application.)\n##\n("entity"<|>ROSS QUINLAN<|>PERSON<|>Ross Quinlan, with a strong background in mathematics, developed the C4.5 and C5.0 decision tree algorithms. His work incorporates statistical methods into the decision tree pruning process, blending statistics and machine learning in the design of these algorithms.)\n##\n("entity"<|>C5.0<|>ORGANIZATION<|>An algorithm developed by Ross Quinlan as an improvement over C4.5, focusing on operational efficiency and predictive process optimization. Initially proprietary, C5.0 was not as widely used as its predecessor due to its restricted access.)\n##\n("entity"<|>CART<|>ORGANIZATION<|>Classification and Regression Trees (CART), also known as C&RT, is a decision tree algorithm introduced in 1984 by Breiman, Friedman, Olshen, and Stone. It extends the capabilities of decision tree models to include regression problems, supports both discrete and continuous variables, and is integrated into machine learning frameworks like sklearn, reflecting its robustness and versatility in machine learning applications.)\n##\n("relationship"<|>C4.5<|>ROSS QUINLAN<|>Ross Quinlan developed the C4.5 algorithm, marking a significant contribution to the field of data mining and decision tree models.<|>9)\n##\n("relationship"<|>C5.0<|>ROSS QUINLAN<|>Ross Quinlan introduced C5.0 as an optimized version of C4.5, aiming to improve efficiency and prediction accuracy.<|>9)\n##\n("relationship"<|>C4.5<|>C5.0<|>C5.0 is an optimization and further development of the C4.5 algorithm by Ross Quinlan, designed to enhance performance and predictive processes.<|>8)\n##\n("relationship"<|>CART<|>C4.5<|>CART and C4.5 share similar construction processes but CART extends to regression problems and offers a more versatile framework for machine learning, indicating an evolution in decision tree algorithms.<|>7)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:18,650 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29257, Requested 3056. Please try again in 4.626s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:18,653 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '度，而C4.5也是目前最为通用的决策树模型的一般框架，后续尽管有其他的决策树\n模型诞生，但大都是在C4.5的基本流程上进行略微调整或者指标修改，甚至在C4.5还被\nIEEE评为10大数据挖掘算法之首，由此可见C4.5算法的巨大影响力。此外，由于C4.5开源\n时间较早，这也使得在过去的很长一段时间内，C4.5都是最通用的决策树算法。当然在此\n后，Ross Quinlan又公布了C5.0算法，进一步优化了运行效率和预测流程，通过一系列数\n据结构的调整使得其能够更加高效的利用内存、并提高执行速度。当然，由于C5.0在很长\n的一段时间是作为收费软件存在、并且多集成与像SAS软件中，因此并未被最广泛的应用\n于各领域。\n此外，值得一提的是，由于Ross Quinlan拥有非常深厚的数学背景，因此在设计决策\n树算法的时候，尽管决策树是一种非参数方法（无需提前进行数据训练的假设检验），但\n在实际执行决策树剪枝（一种防止过拟合的手段）时却需要用到非常多统计学方法，在实\n际构建模型时也无需划分训练集和测试集，因此C4.5其实更像是一种统计学算法，而非机\n器学习算法。\n需要知道的是，C4.5在树的生长上还是更像机器学习算法，而这种半“统计\n学”半“机器学习”的状态也是该算法存在争议的地方。\nCART决策树\nCART全称为Classification and Regression Trees，即分类与回归决策树，同时也被\n称为C&RT算法，在1984年由Breiman、Friedman、Olshen和Stone四人共同提出。\nCART树和C4.5决策树的构造过程非常类似，但拓展了回归类问题的计算流程（此前C4.5\n只能解决分类问题），并且允许采用更丰富的评估指标来指导建模流程，并且，最关键的\n是，CART算法其实是一个非常典型的机器学习算法，在早期CART树的训练过程中，就是\n通过划分训练集和验证集（或者测试集）来验证模型结果、并进一步据此来调整模型结\n构，当然，除此以外，CART树还能够用一套流程同时处理离散变量和连续变量、能够同\n时处理分类问题和回归问题，这些都符合一个机器学习领域要求算法有更普适的功能和更\n强的鲁棒性的要求，这也是为何近几年CART树会更加流行的主要原因。当然，在skelarn\n中，决策树模型评估器集成的也是CART树模型，稍后我们在介绍决策树建模流程的时候\n也将主要介绍CART树的建模流程。\n此处我们也可以参考sklearn中对于ID3、C4.5和CART树的对比描述：\n1\n需要注意的是，sklearn中也并非实现的是完全的CART树，通过相关评估器\n参数的调整，sklearn中也能实现“CART树的建模流程+C4.5的决策树生长\n指标”这种混合模型。\n此外，与其说CART树是一个非常“机器学习”的算法，不如说CART树是一个\n更加适合使用机器学习的方法来进行建模的模型，机器学习或者统计学建模\n方法更大程度上是一种建模思路，很多模型（像逻辑回'}
11:04:21,878 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:21,879 openai._base_client INFO Retrying request to /chat/completions in 0.024000 seconds
11:04:21,954 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:21,955 openai._base_client INFO Retrying request to /chat/completions in 0.312000 seconds
11:04:22,287 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:22,287 openai._base_client INFO Retrying request to /chat/completions in 4.364000 seconds
11:04:22,411 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:22,412 openai._base_client INFO Retrying request to /chat/completions in 4.364000 seconds
11:04:22,423 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:22,424 openai._base_client INFO Retrying request to /chat/completions in 4.418000 seconds
11:04:22,612 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:22,613 openai._base_client INFO Retrying request to /chat/completions in 4.360000 seconds
11:04:22,858 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:22,928 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:22,929 openai._base_client INFO Retrying request to /chat/completions in 3.728000 seconds
11:04:23,201 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:23,202 openai._base_client INFO Retrying request to /chat/completions in 4.664000 seconds
11:04:23,214 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:23,215 openai._base_client INFO Retrying request to /chat/completions in 3.604000 seconds
11:04:26,991 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:26,992 openai._base_client INFO Retrying request to /chat/completions in 0.540000 seconds
11:04:27,143 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:27,144 openai._base_client INFO Retrying request to /chat/completions in 0.512000 seconds
11:04:27,189 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:27,189 openai._base_client INFO Retrying request to /chat/completions in 4.526000 seconds
11:04:27,317 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:27,319 openai._base_client INFO Retrying request to /chat/completions in 4.284000 seconds
11:04:27,537 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:27,538 openai._base_client INFO Retrying request to /chat/completions in 4.382000 seconds
11:04:27,888 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:27,889 openai._base_client INFO Retrying request to /chat/completions in 3.686000 seconds
11:04:28,10 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:28,11 openai._base_client INFO Retrying request to /chat/completions in 3.680000 seconds
11:04:28,134 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:28,225 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:28,225 openai._base_client INFO Retrying request to /chat/completions in 4.278000 seconds
11:04:29,952 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:30,303 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:30,319 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:30,320 openai._base_client INFO Retrying request to /chat/completions in 5.072000 seconds
11:04:30,686 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:30,687 openai._base_client INFO Retrying request to /chat/completions in 4.812000 seconds
11:04:31,918 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:31,920 openai._base_client INFO Retrying request to /chat/completions in 3.646000 seconds
11:04:32,42 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:32,43 openai._base_client INFO Retrying request to /chat/completions in 4.212000 seconds
11:04:32,43 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:32,44 openai._base_client INFO Retrying request to /chat/completions in 3.034000 seconds
11:04:32,252 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:32,254 openai._base_client INFO Retrying request to /chat/completions in 3.624000 seconds
11:04:32,850 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:32,852 openai._base_client INFO Retrying request to /chat/completions in 3.028000 seconds
11:04:32,900 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:32,901 openai._base_client INFO Retrying request to /chat/completions in 3.592000 seconds
11:04:35,428 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:35,431 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 右两个节点的方差只和，但实际上是\n经过加权之后的方差只和。我们可以通过在手动实现过程中灵活调整\nmin_impurity_decrease参数来进行验证。\n需要注意的是，CART回归树的子节点整体MSE的计算方式是加权求和还是\n简单求和，不同的材料中有不同的描述，例如由Aurélien Géron等人所著\n《机器学习实战，基于Scikit-Learn、Keras和TensorFlow》一书中表示是\n通过加权求和方式算得，而在《统计学习方法》一书中则表示是根据子节点\n的MSE直接求和得到。\ncriterion=\'mae\'情况\n和MSE不同，MAE实际上计算的是预测值和真实值的差值的绝对值再除以样本总数，\n即可以通过如下公式计算得出：\nMAE =\n1\nm\nm\n∑\ni=1\n|(yi − ^yi)|\n也就是说，MSE是基于预测值和真实值之间的欧式距离进行的计算，而MAE则是基于二者\n的街道距离进行的计算，很多时候，MSE也被称为L2损失，而MAE则被称为L1损失。\n需要注意的是，当criterion取值为mae时，为了让每一次划分时子集内的MAE值最\n小，此时每个子集的模型预测值就不再是均值，而是中位数。此时中位数的选取其实和\nLesson 7中介绍的K-Means快速聚类的质心选取过程类似，当距离衡量方法改为街道距\n离时，能够让组内误差平方和最小的质心其实就是这一组数的中位数。\n再次强调，CART回归树的criterion不仅是划分方式挑选时的评估标准，同\n时也是划分子数据集后选取预测值的决定因素。也就是说，对于回归树来\n说，criterion的取值其实决定了两个方面，其一是决定了损失值的计算方\n式、其二是决定了每一个数据集的预测值的计算方式——数据集的预测值\n要求criterion取值最小，如果criterion=mse，则数据集的预测值要求在当\n前数据情况下mse取值最小，此时应该以数据集的标签的均值作为预测值；\n而如果criterion=mse，则数据集的预测值要求在当前数据情况下mae取值\n最小，此时应该以数据集标签的座位数作为预测值。\n并且一般来说，如果希望模型对极端值（非常大或者非常小的值，也被称为离群值）\n的忍耐程度比较高，整体建模过程不受极端值影响，可以考虑使用mae参数（就类似于中\n位数会更少的受到极端值的影响），此时模型一般不会为极端值单独设置规则。而如果希\n望模型具备较好的识别极端值的能力，则可以考虑使用mse参数，此时模型会更大程度受\n到极端值影响（就类似于均值更容易受到极端值影响），更大概率会围绕极端值单独设置\n规则，从而帮助建模者对极端值进行识别。\n\n为什么需要用模型来识别离群点？主要是因为对于高维空间中的样本点，我\n们很难通过简单的大小比较将离群点挑选出来。\ncriterion=\'friedman_mse\'情况\nfriedman_mse是一种基于mse的改进型指标，是由GBDT（梯度提升树，一种集成算\n法）的提出者friedman所设计的一种残差计算方法，是sklearn中树梯度提树默认的\ncriterion取值，对于单独的树决策树模型\n######################\nOutput:', 'kwargs': {}}
11:04:35,431 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 27691, Requested 2435. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:35,434 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "右两个节点的方差只和，但实际上是\n经过加权之后的方差只和。我们可以通过在手动实现过程中灵活调整\nmin_impurity_decrease参数来进行验证。\n需要注意的是，CART回归树的子节点整体MSE的计算方式是加权求和还是\n简单求和，不同的材料中有不同的描述，例如由Aurélien Géron等人所著\n《机器学习实战，基于Scikit-Learn、Keras和TensorFlow》一书中表示是\n通过加权求和方式算得，而在《统计学习方法》一书中则表示是根据子节点\n的MSE直接求和得到。\ncriterion='mae'情况\n和MSE不同，MAE实际上计算的是预测值和真实值的差值的绝对值再除以样本总数，\n即可以通过如下公式计算得出：\nMAE =\n1\nm\nm\n∑\ni=1\n|(yi − ^yi)|\n也就是说，MSE是基于预测值和真实值之间的欧式距离进行的计算，而MAE则是基于二者\n的街道距离进行的计算，很多时候，MSE也被称为L2损失，而MAE则被称为L1损失。\n需要注意的是，当criterion取值为mae时，为了让每一次划分时子集内的MAE值最\n小，此时每个子集的模型预测值就不再是均值，而是中位数。此时中位数的选取其实和\nLesson 7中介绍的K-Means快速聚类的质心选取过程类似，当距离衡量方法改为街道距\n离时，能够让组内误差平方和最小的质心其实就是这一组数的中位数。\n再次强调，CART回归树的criterion不仅是划分方式挑选时的评估标准，同\n时也是划分子数据集后选取预测值的决定因素。也就是说，对于回归树来\n说，criterion的取值其实决定了两个方面，其一是决定了损失值的计算方\n式、其二是决定了每一个数据集的预测值的计算方式——数据集的预测值\n要求criterion取值最小，如果criterion=mse，则数据集的预测值要求在当\n前数据情况下mse取值最小，此时应该以数据集的标签的均值作为预测值；\n而如果criterion=mse，则数据集的预测值要求在当前数据情况下mae取值\n最小，此时应该以数据集标签的座位数作为预测值。\n并且一般来说，如果希望模型对极端值（非常大或者非常小的值，也被称为离群值）\n的忍耐程度比较高，整体建模过程不受极端值影响，可以考虑使用mae参数（就类似于中\n位数会更少的受到极端值的影响），此时模型一般不会为极端值单独设置规则。而如果希\n望模型具备较好的识别极端值的能力，则可以考虑使用mse参数，此时模型会更大程度受\n到极端值影响（就类似于均值更容易受到极端值影响），更大概率会围绕极端值单独设置\n规则，从而帮助建模者对极端值进行识别。\n\n为什么需要用模型来识别离群点？主要是因为对于高维空间中的样本点，我\n们很难通过简单的大小比较将离群点挑选出来。\ncriterion='friedman_mse'情况\nfriedman_mse是一种基于mse的改进型指标，是由GBDT（梯度提升树，一种集成算\n法）的提出者friedman所设计的一种残差计算方法，是sklearn中树梯度提树默认的\ncriterion取值，对于单独的树决策树模型"}
11:04:35,766 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:35,767 openai._base_client INFO Retrying request to /chat/completions in 1.226000 seconds
11:04:35,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:35,853 openai._base_client INFO Retrying request to /chat/completions in 0.258000 seconds
11:04:36,237 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:36,238 openai._base_client INFO Retrying request to /chat/completions in 3.606000 seconds
11:04:36,240 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:36,242 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 集划归另一个子集，实际上上面在介绍多数据集基尼系数计算\n过程时就是采用该规则。需要知道的是，在所构造的条件中不等号的方向实际上没有任何\n影响。当然，income只有两个取值只能找到一个切点只能构造一个规则，而\ncredit_rating特征也有两个取值，因此也能找到一个切点构造一个备选规则，即我们其实\n也可以根据credit_rating <= 1.5来切分出两个子集。\n而其实如果特征是三个取值的特征，则可以找到两个切点、找到两种划分数据集的方\n式。更进一步的，如果该数据中某特征是连续变量，每条不同的数据取值都不同，例如：\n1\n则此时可以将其看成是拥有8个分类水平的分类变量，仍然还是寻找相邻取值水平的中间\n值作为切点来构造划分规则，此时由于age特征有8个不同的取值，因此可以构造7个备选\n的划分数据集的方法，例如age <= 36、age <= 34.5等等。也就是说，对于任何一个特\n征无论是连续型变量还是分类变量，只要有N个取值，就可以创造N-1个划分条件将原数\n据集划分成两份。\n正是因为可以用一种方法就能同时处理连续变量和离散变量，因此在决策树\n建模的过程中我们无需特别区分两种类型特征的区别。\n此外，需要注意的是，CART树用这种方法同时处理离散变量和连续变量，\n而C4.5只用这种方式处理连续变量（离散变量采用另一种方法），因此这\n里我们可以理解成是CART树将离散变量“连续化”，也就是将离散变量看成\n是连续变量，这也就是为何sklearn在说明文档中强调，sklearn的树模型无\n法处理分类变量的原因（原文：scikit-learn implementation does not\nsupport categorical variables for now.）。此处所谓的无法处理分类变量\n并不是不能带入分类变量进行建模，而是不支持类似C4.5的方法从离散特\n征中提取备选划分规则，而是会将离散变量也看成是连续变量，采用C4.5\n处理连续变量的方法处理离散变量。关于C4.5从离散特征中批量提取备选\n规则的方法我们会在课后阅读中介绍详细介绍。\n实际上，机器学习不同统计算法，大多数时候都不会刻意区分特征的连续与\n离散。\n1.3 挑选最佳分类规则划分数据集\n当然，对于上述A数据集，总共有两个特征，每个特征有一个备选划分规则，因此在\n对根结点划分时，其实是有两种数据集的划分方法，我们已经简单查看采用income <=\n1.5进行分类的结果：\n1\n而如果我们采用credit_rating <= 1.5来对数据集进行划分，则将出现下述结果：\n\n1\n从结果上来看，这两个划分条件都能切分出一个只包含一类标签的数据集，结果区分不是\n很大，那么到底应该选用哪个分类规则对数据集进行第一次切分、让决策树完成第一步的\n生长呢？这个时候就要用到此前我们介绍的关于评价分类规则是否有效的评估指标了，一\n般来说对于多个规则，我们首先会计算父节点的基尼系数（Gini(A)），然后计算划分出的\n两个子节点整体基尼系数（Gini(B)），然后通过对比哪种划分方式能够让二者差值更大，\n即能够让子节点的基尼系数下降更快，我们就选用哪个规则\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:36,243 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29661, Requested 2533. Please try again in 4.388s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:36,246 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '集划归另一个子集，实际上上面在介绍多数据集基尼系数计算\n过程时就是采用该规则。需要知道的是，在所构造的条件中不等号的方向实际上没有任何\n影响。当然，income只有两个取值只能找到一个切点只能构造一个规则，而\ncredit_rating特征也有两个取值，因此也能找到一个切点构造一个备选规则，即我们其实\n也可以根据credit_rating <= 1.5来切分出两个子集。\n而其实如果特征是三个取值的特征，则可以找到两个切点、找到两种划分数据集的方\n式。更进一步的，如果该数据中某特征是连续变量，每条不同的数据取值都不同，例如：\n1\n则此时可以将其看成是拥有8个分类水平的分类变量，仍然还是寻找相邻取值水平的中间\n值作为切点来构造划分规则，此时由于age特征有8个不同的取值，因此可以构造7个备选\n的划分数据集的方法，例如age <= 36、age <= 34.5等等。也就是说，对于任何一个特\n征无论是连续型变量还是分类变量，只要有N个取值，就可以创造N-1个划分条件将原数\n据集划分成两份。\n正是因为可以用一种方法就能同时处理连续变量和离散变量，因此在决策树\n建模的过程中我们无需特别区分两种类型特征的区别。\n此外，需要注意的是，CART树用这种方法同时处理离散变量和连续变量，\n而C4.5只用这种方式处理连续变量（离散变量采用另一种方法），因此这\n里我们可以理解成是CART树将离散变量“连续化”，也就是将离散变量看成\n是连续变量，这也就是为何sklearn在说明文档中强调，sklearn的树模型无\n法处理分类变量的原因（原文：scikit-learn implementation does not\nsupport categorical variables for now.）。此处所谓的无法处理分类变量\n并不是不能带入分类变量进行建模，而是不支持类似C4.5的方法从离散特\n征中提取备选划分规则，而是会将离散变量也看成是连续变量，采用C4.5\n处理连续变量的方法处理离散变量。关于C4.5从离散特征中批量提取备选\n规则的方法我们会在课后阅读中介绍详细介绍。\n实际上，机器学习不同统计算法，大多数时候都不会刻意区分特征的连续与\n离散。\n1.3 挑选最佳分类规则划分数据集\n当然，对于上述A数据集，总共有两个特征，每个特征有一个备选划分规则，因此在\n对根结点划分时，其实是有两种数据集的划分方法，我们已经简单查看采用income <=\n1.5进行分类的结果：\n1\n而如果我们采用credit_rating <= 1.5来对数据集进行划分，则将出现下述结果：\n\n1\n从结果上来看，这两个划分条件都能切分出一个只包含一类标签的数据集，结果区分不是\n很大，那么到底应该选用哪个分类规则对数据集进行第一次切分、让决策树完成第一步的\n生长呢？这个时候就要用到此前我们介绍的关于评价分类规则是否有效的评估指标了，一\n般来说对于多个规则，我们首先会计算父节点的基尼系数（Gini(A)），然后计算划分出的\n两个子节点整体基尼系数（Gini(B)），然后通过对比哪种划分方式能够让二者差值更大，\n即能够让子节点的基尼系数下降更快，我们就选用哪个规则'}
11:04:36,471 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:36,472 openai._base_client INFO Retrying request to /chat/completions in 4.400000 seconds
11:04:36,522 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:36,616 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:36,618 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:04:36,861 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:36,862 openai._base_client INFO Retrying request to /chat/completions in 5.540000 seconds
11:04:36,905 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:36,907 openai._base_client INFO Retrying request to /chat/completions in 4.666000 seconds
11:04:37,348 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:37,349 openai._base_client INFO Retrying request to /chat/completions in 5.528000 seconds
11:04:40,237 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:40,241 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: # 预测结果\nplt.plot(np.arange(1, 1.5, 0.1), np.full_like(np.arange(1, 1.5, 0.1), 1), \'r-\')\nplt.plot(np.arange(1.5, 3.5, 0.1), np.full_like(np.arange(1.5, 3.5, 0.1), 3), \'r\nplt.plot(np.arange(3.5, 5, 0.1), np.full_like(np.arange(3.5, 5, 0.1), 6), \'r-\')\nOut[21]:\n[<matplotlib.lines.Line2D at 0x7fb9d916a4c0>]\n不难发现，回归树的对标签的预测，实际上是一种“分区定值”的预测，建模过程的实际表\n现是对样本进行划分、然后每个区间给定一个预测值，并且树的深度越深、对样本空间的\n划分次数就越多、样本空间就会被分割成更多的子空间。在sklearn的说明文档中也有相\n关例子：\n1\n回归树的预测过程\n\n而一旦当模型已经构建完成后，回归树的预测过程其实和分类树非常类似，新数据只\n要根据划分规则分配到所属样本空间，则该空间模型的预测结果就是该数据的预测结果。\n至此，我们就在一个极简的数据集上完成了CART回归树的构建。不难发现，回归树\n和分类树的构建过程大致相同、迭代过程也基本一致，我们可以将其视作同一种建模思想\n的两种不同实现形式。\n二、CART回归树的Scikit-Learn实现方法\n1.CART回归树的sklearn快速实现\nIn [26]:\nIn [35]:\nIn [36]:\n接下来，我们尝试在sklearn中调用回归树评估器围绕上述数据集进行建模，并对上\n述过程进行简单验证。回归树也是在tree模块下，我们可以通过如下方式进行导入：\nfrom sklearn.tree import DecisionTreeRegressor\n然后进行模型训练：\nclf = DecisionTreeRegressor().fit(data[:, 0].reshape(-1, 1), data[:, 1])\n# 同样可以借助tree.plot_tree进行结果的可视化呈现\nplt.figure(figsize=(6, 2), dpi=150)\ntree.plot_tree(clf)\nOut[36]:\n[Text(418.5, 188.75, \'X[0] <= 3.5\\nmse = 3.76\\nsamples = 5\\nvalue = 3.8\'),\nText(279.0, 113.25, \'X[0] <= 1.5\\nmse = 0.889\\nsamples = 3\\nvalue = 2.333\'),\nText(139.5, 37.75, \'mse = 0.0\\nsamples = 1\\nvalue = 1.0\'),\nText(418.5, 37.75, \'mse = 0.0\\nsamples = 2\\nvalue = 3.0\'),\nText(558.0, 113.25, \'mse = 0.0\\nsamples = 2\\nvalue = 6.0\')]\n发现和我们手动实现过程一致。\n2.CART回归树评估器的参数解释\n接下来，详细讨论关于CART回归树评估器中的相关参数。尽管CART回归树和分类树\n是由不同评估器实现相关过程，但由于两种模型基本理论一致，因此两种不同评估器的参\n数也大都一致。\nIn [25]:\nDecisionTreeRegressor?\n\nInit signature:\nDecisionTreeRegressor(\n*,\ncriterion=\'mse\',\nsplitter=\'best\',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_impurity_decrease=0.0,\nmin_impurity_split=None,\npresort=\'deprecated\',\nccp_alpha=0.0,\n)\nDocstring:\nA decision tree regressor.\nRead more in the :ref:`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for\n######################\nOutput:', 'kwargs': {}}
11:04:40,241 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 27928, Requested 2448. Please try again in 752ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:40,243 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '# 预测结果\nplt.plot(np.arange(1, 1.5, 0.1), np.full_like(np.arange(1, 1.5, 0.1), 1), \'r-\')\nplt.plot(np.arange(1.5, 3.5, 0.1), np.full_like(np.arange(1.5, 3.5, 0.1), 3), \'r\nplt.plot(np.arange(3.5, 5, 0.1), np.full_like(np.arange(3.5, 5, 0.1), 6), \'r-\')\nOut[21]:\n[<matplotlib.lines.Line2D at 0x7fb9d916a4c0>]\n不难发现，回归树的对标签的预测，实际上是一种“分区定值”的预测，建模过程的实际表\n现是对样本进行划分、然后每个区间给定一个预测值，并且树的深度越深、对样本空间的\n划分次数就越多、样本空间就会被分割成更多的子空间。在sklearn的说明文档中也有相\n关例子：\n1\n回归树的预测过程\n\n而一旦当模型已经构建完成后，回归树的预测过程其实和分类树非常类似，新数据只\n要根据划分规则分配到所属样本空间，则该空间模型的预测结果就是该数据的预测结果。\n至此，我们就在一个极简的数据集上完成了CART回归树的构建。不难发现，回归树\n和分类树的构建过程大致相同、迭代过程也基本一致，我们可以将其视作同一种建模思想\n的两种不同实现形式。\n二、CART回归树的Scikit-Learn实现方法\n1.CART回归树的sklearn快速实现\nIn [26]:\nIn [35]:\nIn [36]:\n接下来，我们尝试在sklearn中调用回归树评估器围绕上述数据集进行建模，并对上\n述过程进行简单验证。回归树也是在tree模块下，我们可以通过如下方式进行导入：\nfrom sklearn.tree import DecisionTreeRegressor\n然后进行模型训练：\nclf = DecisionTreeRegressor().fit(data[:, 0].reshape(-1, 1), data[:, 1])\n# 同样可以借助tree.plot_tree进行结果的可视化呈现\nplt.figure(figsize=(6, 2), dpi=150)\ntree.plot_tree(clf)\nOut[36]:\n[Text(418.5, 188.75, \'X[0] <= 3.5\\nmse = 3.76\\nsamples = 5\\nvalue = 3.8\'),\nText(279.0, 113.25, \'X[0] <= 1.5\\nmse = 0.889\\nsamples = 3\\nvalue = 2.333\'),\nText(139.5, 37.75, \'mse = 0.0\\nsamples = 1\\nvalue = 1.0\'),\nText(418.5, 37.75, \'mse = 0.0\\nsamples = 2\\nvalue = 3.0\'),\nText(558.0, 113.25, \'mse = 0.0\\nsamples = 2\\nvalue = 6.0\')]\n发现和我们手动实现过程一致。\n2.CART回归树评估器的参数解释\n接下来，详细讨论关于CART回归树评估器中的相关参数。尽管CART回归树和分类树\n是由不同评估器实现相关过程，但由于两种模型基本理论一致，因此两种不同评估器的参\n数也大都一致。\nIn [25]:\nDecisionTreeRegressor?\n\nInit signature:\nDecisionTreeRegressor(\n*,\ncriterion=\'mse\',\nsplitter=\'best\',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_impurity_decrease=0.0,\nmin_impurity_split=None,\npresort=\'deprecated\',\nccp_alpha=0.0,\n)\nDocstring:\nA decision tree regressor.\nRead more in the :ref:`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for'}
11:04:41,289 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:41,291 openai._base_client INFO Retrying request to /chat/completions in 0.716000 seconds
11:04:42,561 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:42,565 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead.\npresort : deprecated, default=\'deprecated\'\nThis parameter is deprecated and will be removed in v0.24.\n.. deprecated:: 0.22\nccp_alpha : non-negative float, default=0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. The\nsubtree with the largest cost complexity that is smaller than\n``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n:ref:`minimal_cost_complexity_pruning` for details.\n.. versionadded:: 0.22\nAttributes\n---------\nfeature_importances_ : ndarray of shape (n_features,)\nThe feature importances.\nThe higher, the more important the feature.\nThe importance of a feature is computed as the\n(normalized) total reduction of the criterion brought\nby that feature. It is also known as the Gini importance [4]_.\nWarning: impurity-based feature importances can be misleading for\nhigh cardinality features (many unique values). See\n:func:`sklearn.inspection.permutation_importance` as an alternative.\nmax_features_ : int\nThe inferred value of max_features.\nn_features_ : int\nThe number of features when ``fit`` is performed.\nn_outputs_ : int\nThe number of outputs when ``fit`` is performed.\ntree_ : Tree\nThe underlying Tree object. Please refer to\n``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n:ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\nfor basic usage of these attributes.\nSee Also\n\n-------\nDecisionTreeClassifier : A decision tree classifier.\nNotes\n----\nThe default values for the parameters controlling the size of the trees\n(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\nunpruned trees which can potentially be very large on some data sets. To\nreduce memory consumption, the complexity and size of the trees should be\ncontrolled by setting those parameter values.\nReferences\n---------\n.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n.. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, "Classification\nand Regression Trees", Wadsworth, Belmont, CA, 1984.\n.. [3] T. Hastie, R. Tibshirani and J. Friedman. "Elements of Statistical\nLearning", Springer, 2009.\n.. [4] L. Breiman, and A. Cutler, "Random Forests",\nhttps://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\nExamples\n-------\n>>> from sklearn.datasets import load_diabetes\n>>> from sklearn.model_selection import cross_val_score\n>>> from sklearn.tree import DecisionTreeRegressor\n>>> X, y = load_diabetes(return_X_y=True)\n>>> regressor = DecisionTreeRegressor(random_state=0)\n>>> cross_val_score(regressor, X, y, cv=10)\n...\n# doctest: +SKIP\n...\narray([-0.39..., -0.46..., 0.02..., 0.06..., -0.50...,\n0.16..., 0.11..., -0.73..., -0.30..., -0.00...])\nFile:\ns.py\nType:\nSubclasses:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\nABCMeta\nExtraTreeRegressor\n不难发现，其中大多数参数我们在Lesson 8.2中都进行了详细的讲解，此处重点讲解\ncriterion参数取值。criterion是备选划分规则的选取指标，对于CART分类树来说默认基\n尼系数、可选信息熵，而对于CART回归树来说默认mse，同时可选mae和\nfriedman_mse，同时在新版sklearn中，还加入了poisson作为可选参数取值。接下来我\n们就这几个参数不同取值进行介绍：\ncriterion=\'mse\'情况\n当criterion取值为mse时当然是计算误差平方和再除以样本总数，其基本计算流程与\n上述手动实现过程层类似。但有一点可能会对阅读源码的同学造成困扰，那就是在源码中\n子节点整体的MSE计算公式描述如下：\n1\n\n尽管上述公式看起来像是子节点的整体MSE就等于左右两个节点的方差只和，但实际上是\n经过加权之后的方差只和。我们可以通过在手动实现过程中灵活调整\nmin_impurity_decrease参数来进行验证。\n需要注意的是，CART回归树的子节点整体MSE的计算方式是加权求和还是\n简单求和，不同的材料\n######################\nOutput:', 'kwargs': {}}
11:04:42,565 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29516, Requested 2683. Please try again in 4.398s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:42,569 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead.\npresort : deprecated, default=\'deprecated\'\nThis parameter is deprecated and will be removed in v0.24.\n.. deprecated:: 0.22\nccp_alpha : non-negative float, default=0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. The\nsubtree with the largest cost complexity that is smaller than\n``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n:ref:`minimal_cost_complexity_pruning` for details.\n.. versionadded:: 0.22\nAttributes\n---------\nfeature_importances_ : ndarray of shape (n_features,)\nThe feature importances.\nThe higher, the more important the feature.\nThe importance of a feature is computed as the\n(normalized) total reduction of the criterion brought\nby that feature. It is also known as the Gini importance [4]_.\nWarning: impurity-based feature importances can be misleading for\nhigh cardinality features (many unique values). See\n:func:`sklearn.inspection.permutation_importance` as an alternative.\nmax_features_ : int\nThe inferred value of max_features.\nn_features_ : int\nThe number of features when ``fit`` is performed.\nn_outputs_ : int\nThe number of outputs when ``fit`` is performed.\ntree_ : Tree\nThe underlying Tree object. Please refer to\n``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n:ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\nfor basic usage of these attributes.\nSee Also\n\n-------\nDecisionTreeClassifier : A decision tree classifier.\nNotes\n----\nThe default values for the parameters controlling the size of the trees\n(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\nunpruned trees which can potentially be very large on some data sets. To\nreduce memory consumption, the complexity and size of the trees should be\ncontrolled by setting those parameter values.\nReferences\n---------\n.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n.. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, "Classification\nand Regression Trees", Wadsworth, Belmont, CA, 1984.\n.. [3] T. Hastie, R. Tibshirani and J. Friedman. "Elements of Statistical\nLearning", Springer, 2009.\n.. [4] L. Breiman, and A. Cutler, "Random Forests",\nhttps://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\nExamples\n-------\n>>> from sklearn.datasets import load_diabetes\n>>> from sklearn.model_selection import cross_val_score\n>>> from sklearn.tree import DecisionTreeRegressor\n>>> X, y = load_diabetes(return_X_y=True)\n>>> regressor = DecisionTreeRegressor(random_state=0)\n>>> cross_val_score(regressor, X, y, cv=10)\n...\n# doctest: +SKIP\n...\narray([-0.39..., -0.46..., 0.02..., 0.06..., -0.50...,\n0.16..., 0.11..., -0.73..., -0.30..., -0.00...])\nFile:\ns.py\nType:\nSubclasses:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\nABCMeta\nExtraTreeRegressor\n不难发现，其中大多数参数我们在Lesson 8.2中都进行了详细的讲解，此处重点讲解\ncriterion参数取值。criterion是备选划分规则的选取指标，对于CART分类树来说默认基\n尼系数、可选信息熵，而对于CART回归树来说默认mse，同时可选mae和\nfriedman_mse，同时在新版sklearn中，还加入了poisson作为可选参数取值。接下来我\n们就这几个参数不同取值进行介绍：\ncriterion=\'mse\'情况\n当criterion取值为mse时当然是计算误差平方和再除以样本总数，其基本计算流程与\n上述手动实现过程层类似。但有一点可能会对阅读源码的同学造成困扰，那就是在源码中\n子节点整体的MSE计算公式描述如下：\n1\n\n尽管上述公式看起来像是子节点的整体MSE就等于左右两个节点的方差只和，但实际上是\n经过加权之后的方差只和。我们可以通过在手动实现过程中灵活调整\nmin_impurity_decrease参数来进行验证。\n需要注意的是，CART回归树的子节点整体MSE的计算方式是加权求和还是\n简单求和，不同的材料'}
11:04:42,578 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:42,579 openai._base_client INFO Retrying request to /chat/completions in 4.292000 seconds
11:04:43,55 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:43,56 openai._base_client INFO Retrying request to /chat/completions in 4.248000 seconds
11:04:43,239 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:43,240 openai._base_client INFO Retrying request to /chat/completions in 4.530000 seconds
11:04:47,662 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:47,666 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: :`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for potential splits,\nand "mae" for the mean absolute error, which minimizes the L1 loss\nusing the median of each terminal node.\n.. versionadded:: 0.18\nMean Absolute Error (MAE) criterion.\nsplitter : {"best", "random"}, default="best"\nThe strategy used to choose the split at each node. Supported\nstrategies are "best" to choose the best split and "random" to choose\nthe best random split.\nmax_depth : int, default=None\nThe maximum depth of the tree. If None, then nodes are expanded until\nall leaves are pure or until all leaves contain less than\nmin_samples_split samples.\nmin_samples_split : int or float, default=2\nThe minimum number of samples required to split an internal node:\n- If int, then consider `min_samples_split` as the minimum number.\n- If float, then `min_samples_split` is a fraction and\n`ceil(min_samples_split * n_samples)` are the minimum\nnumber of samples for each split.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_samples_leaf : int or float, default=1\nThe minimum number of samples required to be at a leaf node.\nA split point at any depth will only be considered if it leaves at\n\nleast ``min_samples_leaf`` training samples in each of the left and\nright branches. This may have the effect of smoothing the model,\nespecially in regression.\n- If int, then consider `min_samples_leaf` as the minimum number.\n- If float, then `min_samples_leaf` is a fraction and\n`ceil(min_samples_leaf * n_samples)` are the minimum\nnumber of samples for each node.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_weight_fraction_leaf : float, default=0.0\nThe minimum weighted fraction of the sum total of weights (of all\nthe input samples) required to be at a leaf node. Samples have\nequal weight when sample_weight is not provided.\nmax_features : int, float or {"auto", "sqrt", "log2"}, default=None\nThe number of features to consider when looking for the best split:\n- If int, then consider `max_features` features at each split.\n- If float, then `max_features` is a fraction and\n`int(max_features * n_features)` features are considered at each\nsplit.\n- If "auto", then `max_features=n_features`.\n- If "sqrt", then `max_features=sqrt(n_features)`.\n- If "log2", then `max_features=log2(n_features)`.\n- If None, then `max_features=n_features`.\nNote: the search for a split does not stop until at least one\nvalid partition of the node samples is found, even if it requires to\neffectively inspect more than ``max_features`` features.\nrandom_state : int, RandomState instance, default=None\nControls the randomness of the estimator. The features are always\nrandomly permuted at each split, even if ``splitter`` is set to\n``"best"``. When ``max_features < n_features``, the algorithm will\nselect ``max_features`` at random at each split before finding the best\nsplit among them. But the best found split may vary across different\nruns, even if ``max_features=n_features``. That is the case, if the\nimprovement of the criterion is identical for several splits and one\nsplit has to be selected at random. To obtain a deterministic behaviour\nduring fitting, ``random_state`` has to be fixed to an integer.\nSee :term:`Glossary <random_state>` for details.\nmax_leaf_nodes : int, default=None\nGrow a tree with ``max_leaf_nodes`` in best-first fashion.\nBest nodes are defined as relative reduction in impurity.\nIf None then unlimited number of leaf nodes.\nmin_impurity_decrease : float, default=0.0\nA node will be split if this split induces a decrease of the impurity\ngreater than or equal to this value.\nThe weighted impurity decrease equation is the following::\nN_t / N * (impurity - N_t_R / N_t * right_impurity\n- N_t_L / N_t * left_impurity)\nwhere ``N`` is the total number of samples, ``N_t`` is the number of\n\nsamples at the current node, ``N_t_L`` is the number of samples in the\nleft child, and ``N_t_R`` is the number of samples in the right child.\n``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\nmin_impurity_split : float, (default=0)\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead\n######################\nOutput:', 'kwargs': {}}
11:04:47,666 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29598, Requested 2842. Please try again in 4.88s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:47,669 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ':`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for potential splits,\nand "mae" for the mean absolute error, which minimizes the L1 loss\nusing the median of each terminal node.\n.. versionadded:: 0.18\nMean Absolute Error (MAE) criterion.\nsplitter : {"best", "random"}, default="best"\nThe strategy used to choose the split at each node. Supported\nstrategies are "best" to choose the best split and "random" to choose\nthe best random split.\nmax_depth : int, default=None\nThe maximum depth of the tree. If None, then nodes are expanded until\nall leaves are pure or until all leaves contain less than\nmin_samples_split samples.\nmin_samples_split : int or float, default=2\nThe minimum number of samples required to split an internal node:\n- If int, then consider `min_samples_split` as the minimum number.\n- If float, then `min_samples_split` is a fraction and\n`ceil(min_samples_split * n_samples)` are the minimum\nnumber of samples for each split.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_samples_leaf : int or float, default=1\nThe minimum number of samples required to be at a leaf node.\nA split point at any depth will only be considered if it leaves at\n\nleast ``min_samples_leaf`` training samples in each of the left and\nright branches. This may have the effect of smoothing the model,\nespecially in regression.\n- If int, then consider `min_samples_leaf` as the minimum number.\n- If float, then `min_samples_leaf` is a fraction and\n`ceil(min_samples_leaf * n_samples)` are the minimum\nnumber of samples for each node.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_weight_fraction_leaf : float, default=0.0\nThe minimum weighted fraction of the sum total of weights (of all\nthe input samples) required to be at a leaf node. Samples have\nequal weight when sample_weight is not provided.\nmax_features : int, float or {"auto", "sqrt", "log2"}, default=None\nThe number of features to consider when looking for the best split:\n- If int, then consider `max_features` features at each split.\n- If float, then `max_features` is a fraction and\n`int(max_features * n_features)` features are considered at each\nsplit.\n- If "auto", then `max_features=n_features`.\n- If "sqrt", then `max_features=sqrt(n_features)`.\n- If "log2", then `max_features=log2(n_features)`.\n- If None, then `max_features=n_features`.\nNote: the search for a split does not stop until at least one\nvalid partition of the node samples is found, even if it requires to\neffectively inspect more than ``max_features`` features.\nrandom_state : int, RandomState instance, default=None\nControls the randomness of the estimator. The features are always\nrandomly permuted at each split, even if ``splitter`` is set to\n``"best"``. When ``max_features < n_features``, the algorithm will\nselect ``max_features`` at random at each split before finding the best\nsplit among them. But the best found split may vary across different\nruns, even if ``max_features=n_features``. That is the case, if the\nimprovement of the criterion is identical for several splits and one\nsplit has to be selected at random. To obtain a deterministic behaviour\nduring fitting, ``random_state`` has to be fixed to an integer.\nSee :term:`Glossary <random_state>` for details.\nmax_leaf_nodes : int, default=None\nGrow a tree with ``max_leaf_nodes`` in best-first fashion.\nBest nodes are defined as relative reduction in impurity.\nIf None then unlimited number of leaf nodes.\nmin_impurity_decrease : float, default=0.0\nA node will be split if this split induces a decrease of the impurity\ngreater than or equal to this value.\nThe weighted impurity decrease equation is the following::\nN_t / N * (impurity - N_t_R / N_t * right_impurity\n- N_t_L / N_t * left_impurity)\nwhere ``N`` is the total number of samples, ``N_t`` is the number of\n\nsamples at the current node, ``N_t_L`` is the number of samples in the\nleft child, and ``N_t_R`` is the number of samples in the right child.\n``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\nmin_impurity_split : float, (default=0)\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead'}
11:04:48,127 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:48,129 openai._base_client INFO Retrying request to /chat/completions in 4.288000 seconds
11:04:52,835 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:52,836 openai._base_client INFO Retrying request to /chat/completions in 0.194000 seconds
11:04:53,380 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:54,396 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:05:11,632 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:05:18,418 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:05:24,41 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:05:24,103 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:05:24,106 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:05:24,140 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:05:24,142 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:05:24,169 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:05:24,174 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:05:24,180 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:05:24,221 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:05:24,223 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:05:24,224 graphrag.utils.storage INFO reading table from storage: communities.parquet
11:05:24,233 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 15
11:05:44,464 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:06:03,127 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:06:07,757 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:06:07,814 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:06:07,818 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:06:07,821 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:06:07,823 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:06:07,825 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
11:06:07,828 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
11:06:07,828 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
11:06:07,870 graphrag.index.operations.embed_text.strategies.openai INFO embedding 28 inputs via 28 snippets using 2 batches. max_batch_size=16, batch_max_tokens=8191
11:06:08,936 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:10,708 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:11,422 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
11:06:11,425 graphrag.index.operations.embed_text.strategies.openai INFO embedding 3 inputs via 3 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
11:06:12,95 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:12,353 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
11:06:12,387 graphrag.index.operations.embed_text.strategies.openai INFO embedding 33 inputs via 33 snippets using 6 batches. max_batch_size=16, batch_max_tokens=8191
11:06:13,203 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:13,309 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:13,312 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:13,415 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:13,691 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:14,297 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:14,819 graphrag.cli.index INFO All workflows completed successfully.
11:38:31,517 graphrag.cli.index INFO Logging enabled at /Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/logs/indexing-engine.log
11:38:33,128 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:34,233 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:38:34,238 graphrag.cli.index INFO Starting pipeline run. dry_run=False
11:38:34,239 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "api_base": "https://ai.devtool.tech/proxy/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
11:38:34,241 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/output
11:38:34,242 graphrag.index.input.factory INFO loading input from root_dir=input
11:38:34,242 graphrag.index.input.factory INFO using file storage for input
11:38:34,244 graphrag.storage.file_pipeline_storage INFO search /Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/input for files matching .*\.txt$
11:38:34,251 graphrag.index.input.util INFO Found 2 InputFileType.text files, loading 2
11:38:34,253 graphrag.index.input.util INFO Total number of unfiltered InputFileType.text rows: 2
11:38:34,256 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 2
11:38:34,282 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:38:34,347 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:38:34,350 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:38:34,366 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:38:36,776 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,399 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,538 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,564 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,578 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,581 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,587 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,624 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,666 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,674 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,676 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,922 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:39,249 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:39,685 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:39,697 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:40,400 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:40,452 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:41,416 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:41,763 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:41,765 openai._base_client INFO Retrying request to /chat/completions in 5.228000 seconds
11:38:41,987 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:43,287 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:43,656 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:43,659 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:38:44,354 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:44,720 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:44,722 openai._base_client INFO Retrying request to /chat/completions in 5.356000 seconds
11:38:46,135 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:46,506 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:46,506 openai._base_client INFO Retrying request to /chat/completions in 4.474000 seconds
11:38:46,816 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:47,194 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:47,197 openai._base_client INFO Retrying request to /chat/completions in 5.504000 seconds
11:38:47,356 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:47,357 openai._base_client INFO Retrying request to /chat/completions in 5.228000 seconds
11:38:48,260 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:48,627 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:48,629 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:38:49,360 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:49,378 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:49,380 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:38:49,699 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:49,733 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:49,734 openai._base_client INFO Retrying request to /chat/completions in 6.548000 seconds
11:38:50,70 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:50,71 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:38:50,363 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:50,431 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:50,440 openai._base_client INFO Retrying request to /chat/completions in 5.356000 seconds
11:38:50,755 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:50,756 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:38:51,27 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:51,257 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:51,351 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:51,352 openai._base_client INFO Retrying request to /chat/completions in 4.474000 seconds
11:38:51,389 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:51,389 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:38:51,509 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:51,633 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:51,634 openai._base_client INFO Retrying request to /chat/completions in 6.314000 seconds
11:38:51,901 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:51,903 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:38:52,945 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:52,947 openai._base_client INFO Retrying request to /chat/completions in 5.228000 seconds
11:38:53,13 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:53,113 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:53,114 openai._base_client INFO Retrying request to /chat/completions in 5.504000 seconds
11:38:53,632 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:54,676 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:54,679 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:54,681 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:38:55,205 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:55,208 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:55,209 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:38:55,209 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:38:55,780 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:56,150 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:56,151 openai._base_client INFO Retrying request to /chat/completions in 5.356000 seconds
11:38:56,376 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:56,376 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:38:56,384 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:56,384 openai._base_client INFO Retrying request to /chat/completions in 4.474000 seconds
11:38:56,626 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:56,628 openai._base_client INFO Retrying request to /chat/completions in 6.548000 seconds
11:38:56,825 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:56,828 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:38:57,456 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:57,458 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:38:58,94 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:58,96 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:38:58,326 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:58,327 openai._base_client INFO Retrying request to /chat/completions in 6.314000 seconds
11:38:58,538 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:58,539 openai._base_client INFO Retrying request to /chat/completions in 5.228000 seconds
11:38:58,968 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:58,969 openai._base_client INFO Retrying request to /chat/completions in 5.504000 seconds
11:39:00,483 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:00,484 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:39:00,938 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:00,940 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:39:01,223 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:01,225 openai._base_client INFO Retrying request to /chat/completions in 4.474000 seconds
11:39:01,287 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:01,288 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:01,878 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:01,879 openai._base_client INFO Retrying request to /chat/completions in 5.356000 seconds
11:39:02,522 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:02,524 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:39:02,919 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:02,921 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:03,510 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:03,511 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:39:03,545 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:03,547 openai._base_client INFO Retrying request to /chat/completions in 6.548000 seconds
11:39:04,134 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:04,134 openai._base_client INFO Retrying request to /chat/completions in 5.228000 seconds
11:39:04,302 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:04,303 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:39:04,852 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:04,852 openai._base_client INFO Retrying request to /chat/completions in 5.504000 seconds
11:39:05,4 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:05,5 openai._base_client INFO Retrying request to /chat/completions in 6.314000 seconds
11:39:06,56 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:06,57 openai._base_client INFO Retrying request to /chat/completions in 4.474000 seconds
11:39:06,276 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:06,277 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:39:06,650 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:06,651 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:39:07,350 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:07,350 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:07,587 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:07,589 openai._base_client INFO Retrying request to /chat/completions in 5.356000 seconds
11:39:08,652 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:08,653 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:39:08,999 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:09,1 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:09,560 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:09,561 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:39:09,725 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:09,726 openai._base_client INFO Retrying request to /chat/completions in 5.228000 seconds
11:39:10,467 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:10,468 openai._base_client INFO Retrying request to /chat/completions in 6.548000 seconds
11:39:10,500 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:10,501 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:39:10,875 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:10,876 openai._base_client INFO Retrying request to /chat/completions in 4.474000 seconds
11:39:10,942 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:10,943 openai._base_client INFO Retrying request to /chat/completions in 5.504000 seconds
11:39:11,690 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:11,691 openai._base_client INFO Retrying request to /chat/completions in 6.314000 seconds
11:39:12,70 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:12,71 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:39:12,380 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:12,381 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:39:13,295 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:13,295 openai._base_client INFO Retrying request to /chat/completions in 5.356000 seconds
11:39:13,421 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:13,421 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:14,776 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:14,777 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:39:15,76 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:15,77 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:15,317 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:15,318 openai._base_client INFO Retrying request to /chat/completions in 5.228000 seconds
11:39:15,603 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:15,604 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:39:15,699 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:15,700 openai._base_client INFO Retrying request to /chat/completions in 4.474000 seconds
11:39:16,703 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:16,703 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:39:16,833 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:16,834 openai._base_client INFO Retrying request to /chat/completions in 5.410000 seconds
11:39:17,829 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:17,830 openai._base_client INFO Retrying request to /chat/completions in 5.440000 seconds
11:39:17,862 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:17,863 openai._base_client INFO Retrying request to /chat/completions in 4.300000 seconds
11:39:18,331 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:18,332 openai._base_client INFO Retrying request to /chat/completions in 3.758000 seconds
11:39:18,368 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:18,368 openai._base_client INFO Retrying request to /chat/completions in 4.660000 seconds
11:39:18,996 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:18,997 openai._base_client INFO Retrying request to /chat/completions in 3.076000 seconds
11:39:19,485 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:19,486 openai._base_client INFO Retrying request to /chat/completions in 2.950000 seconds
11:39:20,527 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:20,528 openai._base_client INFO Retrying request to /chat/completions in 0.664000 seconds
11:39:20,909 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:20,910 openai._base_client INFO Retrying request to /chat/completions in 1.598000 seconds
11:39:20,911 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:20,911 openai._base_client INFO Retrying request to /chat/completions in 1.040000 seconds
11:39:21,156 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:21,157 openai._base_client INFO Retrying request to /chat/completions in 1.280000 seconds
11:39:21,655 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:21,656 openai._base_client INFO Retrying request to /chat/completions in 0.748000 seconds
11:39:22,163 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:39:22,317 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,318 openai._base_client INFO Retrying request to /chat/completions in 4.104000 seconds
11:39:22,423 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,423 openai._base_client INFO Retrying request to /chat/completions in 4.708000 seconds
11:39:22,541 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,542 openai._base_client INFO Retrying request to /chat/completions in 4.680000 seconds
11:39:22,667 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,667 openai._base_client INFO Retrying request to /chat/completions in 4.478000 seconds
11:39:22,780 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,781 openai._base_client INFO Retrying request to /chat/completions in 4.680000 seconds
11:39:22,800 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,801 openai._base_client INFO Retrying request to /chat/completions in 4.694000 seconds
11:39:22,854 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,855 openai._base_client INFO Retrying request to /chat/completions in 4.436000 seconds
11:39:22,908 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,909 openai._base_client INFO Retrying request to /chat/completions in 4.710000 seconds
11:39:23,24 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:23,25 openai._base_client INFO Retrying request to /chat/completions in 4.470000 seconds
11:39:23,97 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:23,98 openai._base_client INFO Retrying request to /chat/completions in 4.462000 seconds
11:39:23,387 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:23,388 openai._base_client INFO Retrying request to /chat/completions in 4.706000 seconds
11:39:23,690 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:23,691 openai._base_client INFO Retrying request to /chat/completions in 4.690000 seconds
11:39:26,868 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:26,869 openai._base_client INFO Retrying request to /chat/completions in 0.232000 seconds
11:39:27,607 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:27,607 openai._base_client INFO Retrying request to /chat/completions in 4.996000 seconds
11:39:27,655 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:27,655 openai._base_client INFO Retrying request to /chat/completions in 4.980000 seconds
11:39:27,843 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:27,846 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:39:27,876 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:27,879 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:27,974 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:27,975 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:39:28,77 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:28,78 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:28,159 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:28,160 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:39:28,456 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:28,456 openai._base_client INFO Retrying request to /chat/completions in 6.314000 seconds
11:39:28,863 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:28,864 openai._base_client INFO Retrying request to /chat/completions in 6.548000 seconds
11:39:30,232 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:39:32,967 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:32,969 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:39:33,4 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:33,5 openai._base_client INFO Retrying request to /chat/completions in 5.504000 seconds
11:39:33,902 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:33,902 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:39:33,951 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:33,952 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:34,156 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:34,157 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:34,310 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:34,311 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:39:34,424 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:34,425 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:39:34,613 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:39:35,124 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:35,125 openai._base_client INFO Retrying request to /chat/completions in 6.314000 seconds
11:39:35,772 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:35,774 openai._base_client INFO Retrying request to /chat/completions in 6.548000 seconds
11:39:38,336 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:39:38,775 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:38,776 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:39:38,871 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:38,872 openai._base_client INFO Retrying request to /chat/completions in 5.504000 seconds
11:39:39,953 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:39,954 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:39:40,18 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:40,19 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:40,227 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:40,227 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:40,455 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:40,456 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:39:40,620 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:40,620 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:39:41,788 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:41,789 openai._base_client INFO Retrying request to /chat/completions in 6.314000 seconds
11:39:42,692 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:42,694 openai._base_client INFO Retrying request to /chat/completions in 6.014000 seconds
11:39:44,580 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:44,590 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: # 预测结果\nplt.plot(np.arange(1, 1.5, 0.1), np.full_like(np.arange(1, 1.5, 0.1), 1), \'r-\')\nplt.plot(np.arange(1.5, 3.5, 0.1), np.full_like(np.arange(1.5, 3.5, 0.1), 3), \'r\nplt.plot(np.arange(3.5, 5, 0.1), np.full_like(np.arange(3.5, 5, 0.1), 6), \'r-\')\nOut[21]:\n[<matplotlib.lines.Line2D at 0x7fb9d916a4c0>]\n不难发现，回归树的对标签的预测，实际上是一种“分区定值”的预测，建模过程的实际表\n现是对样本进行划分、然后每个区间给定一个预测值，并且树的深度越深、对样本空间的\n划分次数就越多、样本空间就会被分割成更多的子空间。在sklearn的说明文档中也有相\n关例子：\n1\n回归树的预测过程\n\n而一旦当模型已经构建完成后，回归树的预测过程其实和分类树非常类似，新数据只\n要根据划分规则分配到所属样本空间，则该空间模型的预测结果就是该数据的预测结果。\n至此，我们就在一个极简的数据集上完成了CART回归树的构建。不难发现，回归树\n和分类树的构建过程大致相同、迭代过程也基本一致，我们可以将其视作同一种建模思想\n的两种不同实现形式。\n二、CART回归树的Scikit-Learn实现方法\n1.CART回归树的sklearn快速实现\nIn [26]:\nIn [35]:\nIn [36]:\n接下来，我们尝试在sklearn中调用回归树评估器围绕上述数据集进行建模，并对上\n述过程进行简单验证。回归树也是在tree模块下，我们可以通过如下方式进行导入：\nfrom sklearn.tree import DecisionTreeRegressor\n然后进行模型训练：\nclf = DecisionTreeRegressor().fit(data[:, 0].reshape(-1, 1), data[:, 1])\n# 同样可以借助tree.plot_tree进行结果的可视化呈现\nplt.figure(figsize=(6, 2), dpi=150)\ntree.plot_tree(clf)\nOut[36]:\n[Text(418.5, 188.75, \'X[0] <= 3.5\\nmse = 3.76\\nsamples = 5\\nvalue = 3.8\'),\nText(279.0, 113.25, \'X[0] <= 1.5\\nmse = 0.889\\nsamples = 3\\nvalue = 2.333\'),\nText(139.5, 37.75, \'mse = 0.0\\nsamples = 1\\nvalue = 1.0\'),\nText(418.5, 37.75, \'mse = 0.0\\nsamples = 2\\nvalue = 3.0\'),\nText(558.0, 113.25, \'mse = 0.0\\nsamples = 2\\nvalue = 6.0\')]\n发现和我们手动实现过程一致。\n2.CART回归树评估器的参数解释\n接下来，详细讨论关于CART回归树评估器中的相关参数。尽管CART回归树和分类树\n是由不同评估器实现相关过程，但由于两种模型基本理论一致，因此两种不同评估器的参\n数也大都一致。\nIn [25]:\nDecisionTreeRegressor?\n\nInit signature:\nDecisionTreeRegressor(\n*,\ncriterion=\'mse\',\nsplitter=\'best\',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_impurity_decrease=0.0,\nmin_impurity_split=None,\npresort=\'deprecated\',\nccp_alpha=0.0,\n)\nDocstring:\nA decision tree regressor.\nRead more in the :ref:`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>DECISIONTREEREGRESSOR<|>ORGANIZATION<|>A Scikit-Learn class for creating a decision tree regressor model, capable of fitting to data and predicting values)\n##\n("entity"<|>CART<|>EVENT<|>CART (Classification And Regression Trees) methodology used for constructing decision trees that can be used for classification or regression tasks)\n##\n("entity"<|>SKLEARN<|>ORGANIZATION<|>Scikit-Learn, a popular Python library for machine learning, providing tools for data mining and data analysis)\n##\n("relationship"<|>DECISIONTREEREGRESSOR<|>CART<|>DecisionTreeRegressor is an implementation of the CART algorithm in Scikit-Learn<|>9)\n##\n("relationship"<|>DECISIONTREEREGRESSOR<|>SKLEARN<|>DecisionTreeRegressor is a part of the Scikit-Learn library<|>9)\n##\n("relationship"<|>CART<|>SKLEARN<|>CART methodology is implemented in Scikit-Learn through models like DecisionTreeRegressor<|>8)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:44,590 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28791, Requested 2722. Please try again in 3.026s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:44,594 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '# 预测结果\nplt.plot(np.arange(1, 1.5, 0.1), np.full_like(np.arange(1, 1.5, 0.1), 1), \'r-\')\nplt.plot(np.arange(1.5, 3.5, 0.1), np.full_like(np.arange(1.5, 3.5, 0.1), 3), \'r\nplt.plot(np.arange(3.5, 5, 0.1), np.full_like(np.arange(3.5, 5, 0.1), 6), \'r-\')\nOut[21]:\n[<matplotlib.lines.Line2D at 0x7fb9d916a4c0>]\n不难发现，回归树的对标签的预测，实际上是一种“分区定值”的预测，建模过程的实际表\n现是对样本进行划分、然后每个区间给定一个预测值，并且树的深度越深、对样本空间的\n划分次数就越多、样本空间就会被分割成更多的子空间。在sklearn的说明文档中也有相\n关例子：\n1\n回归树的预测过程\n\n而一旦当模型已经构建完成后，回归树的预测过程其实和分类树非常类似，新数据只\n要根据划分规则分配到所属样本空间，则该空间模型的预测结果就是该数据的预测结果。\n至此，我们就在一个极简的数据集上完成了CART回归树的构建。不难发现，回归树\n和分类树的构建过程大致相同、迭代过程也基本一致，我们可以将其视作同一种建模思想\n的两种不同实现形式。\n二、CART回归树的Scikit-Learn实现方法\n1.CART回归树的sklearn快速实现\nIn [26]:\nIn [35]:\nIn [36]:\n接下来，我们尝试在sklearn中调用回归树评估器围绕上述数据集进行建模，并对上\n述过程进行简单验证。回归树也是在tree模块下，我们可以通过如下方式进行导入：\nfrom sklearn.tree import DecisionTreeRegressor\n然后进行模型训练：\nclf = DecisionTreeRegressor().fit(data[:, 0].reshape(-1, 1), data[:, 1])\n# 同样可以借助tree.plot_tree进行结果的可视化呈现\nplt.figure(figsize=(6, 2), dpi=150)\ntree.plot_tree(clf)\nOut[36]:\n[Text(418.5, 188.75, \'X[0] <= 3.5\\nmse = 3.76\\nsamples = 5\\nvalue = 3.8\'),\nText(279.0, 113.25, \'X[0] <= 1.5\\nmse = 0.889\\nsamples = 3\\nvalue = 2.333\'),\nText(139.5, 37.75, \'mse = 0.0\\nsamples = 1\\nvalue = 1.0\'),\nText(418.5, 37.75, \'mse = 0.0\\nsamples = 2\\nvalue = 3.0\'),\nText(558.0, 113.25, \'mse = 0.0\\nsamples = 2\\nvalue = 6.0\')]\n发现和我们手动实现过程一致。\n2.CART回归树评估器的参数解释\n接下来，详细讨论关于CART回归树评估器中的相关参数。尽管CART回归树和分类树\n是由不同评估器实现相关过程，但由于两种模型基本理论一致，因此两种不同评估器的参\n数也大都一致。\nIn [25]:\nDecisionTreeRegressor?\n\nInit signature:\nDecisionTreeRegressor(\n*,\ncriterion=\'mse\',\nsplitter=\'best\',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_impurity_decrease=0.0,\nmin_impurity_split=None,\npresort=\'deprecated\',\nccp_alpha=0.0,\n)\nDocstring:\nA decision tree regressor.\nRead more in the :ref:`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for'}
11:39:44,738 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:44,741 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Lesson 8.3 ID3、C4.5决策树的建模流程\nID3和C4.5作为的经典决策树算法，尽管无法通过sklearn来进行建模，但其基本原理仍然值得讨论\n与学习。接下来我们详细介绍关于ID3和C4.5这两种决策树模型的建模基本思路和原理。ID3和C4.5的基\n本建模流程和CART树是类似的，也是根据纯度评估指标选取最佳的数据集划分方式，只是不过ID3和\nC4.5是以信息熵为评估指标，而数据集的离散特征划分方式也是一次展开一列，而不是寻找切点进行切\n分。我们先从ID3的基本原理开始介绍，随后讨论C4.5在ID3基础上的改善措施。\nimport numpy as np\nfrom ML_basic_function import *\n一、ID3决策树的基本建模流程\nID3是一个只能围绕离散型变量进行分类问题建模的决策树模型，即ID3无法处理连续型特征、也无\n法处理回归问题，如果带入训练数据有连续型变量，则首先需要对其进行离散化处理，也就是连续变量\n分箱。例如如下个人消费数据，各特征都是离散型变量，能够看出，其中age和income两列就是连续型\n变量分箱之后的结果，例如age列就是以30、40为界进行连续变量分箱。当然，除了如下表示外，我们\n还可以将分箱之后的结果直接赋予一个离散的值，如1、2、3等。\n更多关于连续变量的离散化的方法将在特征工程部分进行介绍。\nID3的生长过程其实和CART树基本一致，其目标都是尽可能降低数据集的不纯度，其生长的过程也\n就是数据集不断划分的过程。只不过ID3的数据集划分过程（规律提取过程）和CART树有所不同，CART\n树是在所有特征中寻找切分点、然后再从中挑选出能够最大程度降低数据集不纯度的节分方式，换而言\n之就是CART树是按照某切分点来展开，而ID3则是按照列来展开，即根据某列的不同取值来对数据集进\n行划分。例如根据上述数据集中的age列的不同取值来对原始数据集进行划分，则划分结果如下：\n同样，我们可以计算在以age的不同取值为划分规则、对数据集进行划分后数据集整体不纯度下降结果，\nID3中采用信息熵作为评估指标，具体计算过程如下：\n首先计算父节点的信息熵\n# 父节点A的信息熵\nent_A = -5/14 * np.log2(5/14) - 9/14 * np.log2(9/14)\nent_A\n0.9402859586706311\n然后计算每个子节点的信息熵\n# 子节点B的信息熵\nent_B1 = entropy(2/5)\nent_B2 = entropy(2/5)\nent_B3 = 0\nent_B1, ent_B2, ent_B3\n\n(0.9709505944546686, 0.9709505944546686, 0)\n同样，子节点整体信息熵就是每个子节点的信息熵加权求和计算得出，其权重就是各子节点数据集数量\n占父节点总数据量的比例：\nent_B = ent_B1 * 5/14 + ent_B2 * 5/14 + ent_B3 * 4/14\nent_B\n0.6935361388961919\n然后即可算出按照如此规则进行数据集划分，最终能够减少的不纯度数值：\n# 不纯度下降结果\nent_A - ent_B\n0.24674981977443922\n而该结果也被称为根据age列进行数据集划分后的信息增益（information gain），上述结果可写\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>ID3<|>ORGANIZATION<|>ID3 is a classic decision tree algorithm that focuses on classification problems around discrete variables and cannot handle continuous features or regression problems without discretization of those continuous variables)\n##\n("entity"<|>C4.5<|>ORGANIZATION<|>C4.5 builds upon ID3 by improving the handling of continuous variables and other aspects of decision tree modeling, using information entropy as a measure for dataset splitting)\n##\n("entity"<|>CART<|>ORGANIZATION<|>CART tree is a type of decision tree that looks for splitting points across all features to reduce dataset impurity, contrasting with ID3\'s approach of expanding by columns)\n##\n("relationship"<|>ID3<|>C4.5<|>C4.5 is an improvement on the ID3 decision tree algorithm, addressing some of its limitations<|>8)\n##\n("relationship"<|>ID3<|>CART<|>ID3 and CART share the basic modeling process of reducing dataset impurity through splits, but differ in their splitting criteria<|>7)\n##\n("relationship"<|>C4.5<|>CART<|>C4.5 and CART both aim to reduce dataset impurity but use different measures and methods for splitting the dataset<|>6)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:44,741 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28711, Requested 2752. Please try again in 2.926s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:44,744 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'Lesson 8.3 ID3、C4.5决策树的建模流程\nID3和C4.5作为的经典决策树算法，尽管无法通过sklearn来进行建模，但其基本原理仍然值得讨论\n与学习。接下来我们详细介绍关于ID3和C4.5这两种决策树模型的建模基本思路和原理。ID3和C4.5的基\n本建模流程和CART树是类似的，也是根据纯度评估指标选取最佳的数据集划分方式，只是不过ID3和\nC4.5是以信息熵为评估指标，而数据集的离散特征划分方式也是一次展开一列，而不是寻找切点进行切\n分。我们先从ID3的基本原理开始介绍，随后讨论C4.5在ID3基础上的改善措施。\nimport numpy as np\nfrom ML_basic_function import *\n一、ID3决策树的基本建模流程\nID3是一个只能围绕离散型变量进行分类问题建模的决策树模型，即ID3无法处理连续型特征、也无\n法处理回归问题，如果带入训练数据有连续型变量，则首先需要对其进行离散化处理，也就是连续变量\n分箱。例如如下个人消费数据，各特征都是离散型变量，能够看出，其中age和income两列就是连续型\n变量分箱之后的结果，例如age列就是以30、40为界进行连续变量分箱。当然，除了如下表示外，我们\n还可以将分箱之后的结果直接赋予一个离散的值，如1、2、3等。\n更多关于连续变量的离散化的方法将在特征工程部分进行介绍。\nID3的生长过程其实和CART树基本一致，其目标都是尽可能降低数据集的不纯度，其生长的过程也\n就是数据集不断划分的过程。只不过ID3的数据集划分过程（规律提取过程）和CART树有所不同，CART\n树是在所有特征中寻找切分点、然后再从中挑选出能够最大程度降低数据集不纯度的节分方式，换而言\n之就是CART树是按照某切分点来展开，而ID3则是按照列来展开，即根据某列的不同取值来对数据集进\n行划分。例如根据上述数据集中的age列的不同取值来对原始数据集进行划分，则划分结果如下：\n同样，我们可以计算在以age的不同取值为划分规则、对数据集进行划分后数据集整体不纯度下降结果，\nID3中采用信息熵作为评估指标，具体计算过程如下：\n首先计算父节点的信息熵\n# 父节点A的信息熵\nent_A = -5/14 * np.log2(5/14) - 9/14 * np.log2(9/14)\nent_A\n0.9402859586706311\n然后计算每个子节点的信息熵\n# 子节点B的信息熵\nent_B1 = entropy(2/5)\nent_B2 = entropy(2/5)\nent_B3 = 0\nent_B1, ent_B2, ent_B3\n\n(0.9709505944546686, 0.9709505944546686, 0)\n同样，子节点整体信息熵就是每个子节点的信息熵加权求和计算得出，其权重就是各子节点数据集数量\n占父节点总数据量的比例：\nent_B = ent_B1 * 5/14 + ent_B2 * 5/14 + ent_B3 * 4/14\nent_B\n0.6935361388961919\n然后即可算出按照如此规则进行数据集划分，最终能够减少的不纯度数值：\n# 不纯度下降结果\nent_A - ent_B\n0.24674981977443922\n而该结果也被称为根据age列进行数据集划分后的信息增益（information gain），上述结果可写'}
11:39:46,14 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:46,17 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 决策树之后，我们也能够对一个树模型的内部结构来进行说明。\n对上述决策树来说，我们可以将其看成是点（数据集）和线构成的一个图结构（准确来说\n应该是一种有向无环图），而对于任何一个图结构，我们都能够通过点和线来构建对其的\n基本认知，对于决策树来说，我们主要将借助边的方向来定义不同类型点，首先我们知道\n如果一条边从A点引向B点，则我们这条边对于A点来说是出边、对于B点来说是入边，A\n节点是B节点的父节点，据此我们可以将决策树中所有的点进行如下类别划分：\n(1)根节点（root node）：没有入边，但有零条或者多条出边的点；\n(2)内部点（internal node）：只有一条入边并且有两条或多条出边的点；\n(3)叶节点（leaf node）：只有入边但没有出边的点；\n因此，我们知道在一次次划分数据集的过程中，原始的完整数据集对应着决策树的根\n节点，而根结点划分出的子数据集就构成了决策树中的内部节点，同时迭代停止的时候所\n对应的数据集，其实就是决策树中的叶节点。并且在上述二叉树（每一层只有两个分支）\n中，一个父节点对应两个子节点。并且根据上述决策树的建模过程不难理解，其实每个数\n据集都是由一系列分类规则最终划分出来的，我们也可以理解成每个节点其实都对应着一\n系列分类规则，例如上述E节点实际上就是petal length (cm) <= 2.5和petal length\n(cm) <= 4.879同时为False时划分出来的数据集。\n在了解决策树的一般建模过程和模型本质后，接下来我们来简单说明一下目前树模型\n的主流派系，然后详细讨论目前最通用的机器学习流派的决策树模型的建模过程。\n二、决策树的分类与流派\n正如此前所说，树模型并不是一个模型，而是一类模型。需要知道的是，尽管树模型\n的核心思想都是源于一种名为贪心算法的局部最优求解算法，但时至今日，树模型已经有\n数十种之多，并且划分为多个流派。目前主流的机器学习算法类别可划分如下：\nID3(Iterative Dichotomiser 3) 、C4.5、C5.0决策树\n是最为经典的决策树算法、同时也是真正将树模型发扬光大的一派算法。最早的ID3\n决策树由Ross Quinlan在1975年（博士毕业论文中）提出，至此也奠定了现在决策树算\n法的基本框架——确定分类规则判别指标、寻找能够最快速降低信息熵的方式进行数据集\n划分（分类规则提取），不断迭代直至收敛；而C4.5则是ID3的后继者，C4.5在ID3的基\n础上补充了一系列基础概念、同时也优化了决策树的算法流程，一方面使得现在的树模型\n\n能够处理连续变量（此前的ID3只能处理分类变量），同时也能够一定程度提高树模型的\n生长速度，而C4.5也是目前最为通用的决策树模型的一般框架，后续尽管有其他的决策树\n模型诞生，但大都是在C4.5的基本流程上进行略微调整或者指标修改，甚至在C4.5还被\nIEEE评为10大数据\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>ID3<|>ORGANIZATION<|>ID3 (Iterative Dichotomiser 3) is a classic decision tree algorithm developed by Ross Quinlan in 1975 as part of his PhD dissertation, laying the foundation for decision tree algorithms by establishing classification rule indicators and seeking ways to reduce information entropy rapidly for data set division)\n##\n("entity"<|>C4.5<|>ORGANIZATION<|>C4.5 is a successor to the ID3 algorithm, introduced to address limitations of ID3 by including continuous variables and improving the growth speed of tree models, making it one of the most widely used decision tree frameworks)\n##\n("entity"<|>C5.0<|>ORGANIZATION<|>C5.0 is an advanced version of the C4.5 decision tree algorithm, further optimizing the decision tree process and often considered in the lineage of classic decision tree algorithms)\n##\n("entity"<|>ROSS QUINLAN<|>PERSON<|>Ross Quinlan is a computer scientist who introduced the ID3 decision tree algorithm in 1975, significantly contributing to the field of machine learning and decision tree models)\n##\n("relationship"<|>ID3<|>ROSS QUINLAN<|>Ross Quinlan developed the ID3 decision tree algorithm<|>9)\n##\n("relationship"<|>C4.5<|>ID3<|>C4.5 was developed as a successor to the ID3 algorithm, improving upon its methodology and capabilities<|>8)\n##\n("relationship"<|>C5.0<|>C4.5<|>C5.0 is an advancement of the C4.5 decision tree algorithm, indicating a lineage of development in decision tree models<|>7)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:46,17 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28079, Requested 2843. Please try again in 1.844s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:46,21 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '决策树之后，我们也能够对一个树模型的内部结构来进行说明。\n对上述决策树来说，我们可以将其看成是点（数据集）和线构成的一个图结构（准确来说\n应该是一种有向无环图），而对于任何一个图结构，我们都能够通过点和线来构建对其的\n基本认知，对于决策树来说，我们主要将借助边的方向来定义不同类型点，首先我们知道\n如果一条边从A点引向B点，则我们这条边对于A点来说是出边、对于B点来说是入边，A\n节点是B节点的父节点，据此我们可以将决策树中所有的点进行如下类别划分：\n(1)根节点（root node）：没有入边，但有零条或者多条出边的点；\n(2)内部点（internal node）：只有一条入边并且有两条或多条出边的点；\n(3)叶节点（leaf node）：只有入边但没有出边的点；\n因此，我们知道在一次次划分数据集的过程中，原始的完整数据集对应着决策树的根\n节点，而根结点划分出的子数据集就构成了决策树中的内部节点，同时迭代停止的时候所\n对应的数据集，其实就是决策树中的叶节点。并且在上述二叉树（每一层只有两个分支）\n中，一个父节点对应两个子节点。并且根据上述决策树的建模过程不难理解，其实每个数\n据集都是由一系列分类规则最终划分出来的，我们也可以理解成每个节点其实都对应着一\n系列分类规则，例如上述E节点实际上就是petal length (cm) <= 2.5和petal length\n(cm) <= 4.879同时为False时划分出来的数据集。\n在了解决策树的一般建模过程和模型本质后，接下来我们来简单说明一下目前树模型\n的主流派系，然后详细讨论目前最通用的机器学习流派的决策树模型的建模过程。\n二、决策树的分类与流派\n正如此前所说，树模型并不是一个模型，而是一类模型。需要知道的是，尽管树模型\n的核心思想都是源于一种名为贪心算法的局部最优求解算法，但时至今日，树模型已经有\n数十种之多，并且划分为多个流派。目前主流的机器学习算法类别可划分如下：\nID3(Iterative Dichotomiser 3) 、C4.5、C5.0决策树\n是最为经典的决策树算法、同时也是真正将树模型发扬光大的一派算法。最早的ID3\n决策树由Ross Quinlan在1975年（博士毕业论文中）提出，至此也奠定了现在决策树算\n法的基本框架——确定分类规则判别指标、寻找能够最快速降低信息熵的方式进行数据集\n划分（分类规则提取），不断迭代直至收敛；而C4.5则是ID3的后继者，C4.5在ID3的基\n础上补充了一系列基础概念、同时也优化了决策树的算法流程，一方面使得现在的树模型\n\n能够处理连续变量（此前的ID3只能处理分类变量），同时也能够一定程度提高树模型的\n生长速度，而C4.5也是目前最为通用的决策树模型的一般框架，后续尽管有其他的决策树\n模型诞生，但大都是在C4.5的基本流程上进行略微调整或者指标修改，甚至在C4.5还被\nIEEE评为10大数据'}
11:39:46,82 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:46,82 openai._base_client INFO Retrying request to /chat/completions in 1.796000 seconds
11:39:46,525 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:46,526 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: cv=10)\n...\n# doctest: +SKIP\n...\narray([ 1.\n, 0.93..., 0.86..., 0.93..., 0.93...,\n0.93..., 0.93..., 1.\n, 0.93..., 1.\n])\n\nFile:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\ns.py\nType:\nSubclasses:\nName\ncriterion\nsplitter\nmax_depth\nmin_samples_split\nmin_samples_leaf\nmin_weight_fraction_leaf\nmax_features\nrandom_state\nmax_leaf_nodes\nmin_impurity_decrease\nmin_impurity_split\nclass_weight\npresort\nccp_alpha\nABCMeta\nExtraTreeClassifier\nDescription\n规则评估指标或损失函数，默认基尼系数，可选信息熵\n树模型生长方式，默认以损失函数取值减少最快方式生长，可选\n随机根据某条件进行划分\n树的最大生长深度，类似max_iter，即总共迭代几次\n内部节点再划分所需最小样本数\n叶节点包含最少样本数\n叶节点所需最小权重和\n在进行切分时候最多带入多少个特征进行划分规则挑选\n随机数种子\n叶节点最大个数\n数据集再划分至少需要降低的损失值\n数据集再划分所需最低不纯度，将在0.25版本中移除\n各类样本权重\n已在0.24版本中移除\n在执行CART树原生原理中的剪枝流程时结构复杂度惩罚因子的\n系数，默认情况下不使用该方法进行剪枝\n接下来围绕一些重点参数进行详细讲解：\ncriterion：不纯度衡量指标\n首先，我们发现尽管sklearn的树模型在默认情况下是CART树，但同样支持使用信息\n熵来衡量不纯度。不过需要注意的是，哪怕我们在criterion参数中选择信息熵，实际树模\n型的建模过程也不是按照ID3或者C4.5的流程执行，此时的树模型只能算是一种混合模\n型。而关于到底应该选择哪个指标来衡量数据集的不纯度，其实大多数情况下选择哪个指\n标并不会实质影响树模型的结构，但相比信息熵，基尼系数复杂度更低、计算速度更快，\n一般情况下推荐使用基尼系数。而如果一定要寻找二者在使用上的不同，一般认为在有些\n情况下，基尼不纯度更倾向于在数据集中分割出多数类，而信息熵则更倾向于生成出更加\n平衡的树。\nccp_alpha：结构风险权重\nccp是复杂度剪枝（Cost-Complexity Pruning）的简称，这是一个在sklearn的0.22\n版本中才加入的参数，这也是唯一一个为实现CART原生原理中的剪枝过程所设置的参\n数。此处首先需要知道的是在sklearn中并不一定要通过该方法进行剪枝，因此该参数其\n实也并不是一个必选参数。其次，带有ccp项的剪枝也被称为最小复杂度剪枝，其原理是\n在决策树的损失函数上加上一个结构风险项，类似于正则化项在线性方程的损失函数中作\n\n用相同。\n我们可以设T为某决策树， 为决策树在训练集上整体不纯度，即代表模型的经验\n风险，令 表示模型结构风险，其中 为参数， 为树的叶节点数量，则我们可以修\n改模型损失函数如下：\nR(T)\nα| ˜T|\nα\n| ˜T|\nRα(T) = R(T) + α| ˜T|\n其中Rα(T)就是加入风险结构项后的损失函数，而α则是风险结构项的系数。由此可\n知， 取值越大、对模型的结构风险惩罚力度就越大、模型结构就越\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>SKLEARN<|>ORGANIZATION<|>Sklearn is a machine learning library for the Python programming language, providing tools for machine learning and statistical modeling including classification, regression, clustering, and dimensionality reduction)\n##\n("entity"<|>EXTRATREECLASSIFIER<|>ORGANIZATION<|>ExtraTreeClassifier is a type of decision tree classifier provided by sklearn that works by fitting a number of randomized decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting)\n##\n("entity"<|>CRITERION<|>EVENT<|>Criterion refers to the function used to measure the quality of a split in the decision tree models within sklearn, with options like Gini impurity and information gain (entropy))\n##\n("entity"<|>CCP_ALPHA<|>EVENT<|>CCP_Alpha is a parameter used in sklearn\'s decision tree and ensemble algorithms for Cost Complexity Pruning, a technique to prevent overfitting by penalizing the complexity of the decision trees)\n##\n("relationship"<|>EXTRATREECLASSIFIER<|>SKLEARN<|>ExtraTreeClassifier is a component of the sklearn library, designed for classification tasks<|>9)\n##\n("relationship"<|>CRITERION<|>EXTRATREECLASSIFIER<|>Criterion is a parameter that can be set for the ExtraTreeClassifier to define the measure for splitting the nodes<|>8)\n##\n("relationship"<|>CCP_ALPHA<|>EXTRATREECLASSIFIER<|>CCP_Alpha is a parameter available in ExtraTreeClassifier for applying Cost Complexity Pruning<|>8)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:46,526 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 27818, Requested 2857. Please try again in 1.35s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:46,526 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'cv=10)\n...\n# doctest: +SKIP\n...\narray([ 1.\n, 0.93..., 0.86..., 0.93..., 0.93...,\n0.93..., 0.93..., 1.\n, 0.93..., 1.\n])\n\nFile:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\ns.py\nType:\nSubclasses:\nName\ncriterion\nsplitter\nmax_depth\nmin_samples_split\nmin_samples_leaf\nmin_weight_fraction_leaf\nmax_features\nrandom_state\nmax_leaf_nodes\nmin_impurity_decrease\nmin_impurity_split\nclass_weight\npresort\nccp_alpha\nABCMeta\nExtraTreeClassifier\nDescription\n规则评估指标或损失函数，默认基尼系数，可选信息熵\n树模型生长方式，默认以损失函数取值减少最快方式生长，可选\n随机根据某条件进行划分\n树的最大生长深度，类似max_iter，即总共迭代几次\n内部节点再划分所需最小样本数\n叶节点包含最少样本数\n叶节点所需最小权重和\n在进行切分时候最多带入多少个特征进行划分规则挑选\n随机数种子\n叶节点最大个数\n数据集再划分至少需要降低的损失值\n数据集再划分所需最低不纯度，将在0.25版本中移除\n各类样本权重\n已在0.24版本中移除\n在执行CART树原生原理中的剪枝流程时结构复杂度惩罚因子的\n系数，默认情况下不使用该方法进行剪枝\n接下来围绕一些重点参数进行详细讲解：\ncriterion：不纯度衡量指标\n首先，我们发现尽管sklearn的树模型在默认情况下是CART树，但同样支持使用信息\n熵来衡量不纯度。不过需要注意的是，哪怕我们在criterion参数中选择信息熵，实际树模\n型的建模过程也不是按照ID3或者C4.5的流程执行，此时的树模型只能算是一种混合模\n型。而关于到底应该选择哪个指标来衡量数据集的不纯度，其实大多数情况下选择哪个指\n标并不会实质影响树模型的结构，但相比信息熵，基尼系数复杂度更低、计算速度更快，\n一般情况下推荐使用基尼系数。而如果一定要寻找二者在使用上的不同，一般认为在有些\n情况下，基尼不纯度更倾向于在数据集中分割出多数类，而信息熵则更倾向于生成出更加\n平衡的树。\nccp_alpha：结构风险权重\nccp是复杂度剪枝（Cost-Complexity Pruning）的简称，这是一个在sklearn的0.22\n版本中才加入的参数，这也是唯一一个为实现CART原生原理中的剪枝过程所设置的参\n数。此处首先需要知道的是在sklearn中并不一定要通过该方法进行剪枝，因此该参数其\n实也并不是一个必选参数。其次，带有ccp项的剪枝也被称为最小复杂度剪枝，其原理是\n在决策树的损失函数上加上一个结构风险项，类似于正则化项在线性方程的损失函数中作\n\n用相同。\n我们可以设T为某决策树， 为决策树在训练集上整体不纯度，即代表模型的经验\n风险，令 表示模型结构风险，其中 为参数， 为树的叶节点数量，则我们可以修\n改模型损失函数如下：\nR(T)\nα| ˜T|\nα\n| ˜T|\nRα(T) = R(T) + α| ˜T|\n其中Rα(T)就是加入风险结构项后的损失函数，而α则是风险结构项的系数。由此可\n知， 取值越大、对模型的结构风险惩罚力度就越大、模型结构就越'}
11:39:46,598 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:46,600 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 8961919\n然后即可算出按照如此规则进行数据集划分，最终能够减少的不纯度数值：\n# 不纯度下降结果\nent_A - ent_B\n0.24674981977443922\n而该结果也被称为根据age列进行数据集划分后的信息增益（information gain），上述结果可写成\nGain(age) = 0.247\n当然，至此我们只计算了按照age列的不同取值来进行数据集划分后数据集不纯度下降结果，而按照\nage列进行展开只能算是树的第一步生长中的一个备选划分规则，此外我们还需要测试按照income、\nstudent或者credit_rating列展开后数据集不纯度下降情况，具体计算过程和age列展开后的计算过程类\n似，此处直接给出结果，Gain(income)=0.026、Gain(student)=0.151、Gain(credit_rating)=0.048。很\n明显，按照age列展开能够更有效的降低数据集的不纯度，因此树的第一层生长就是按照age列的不同取\n值对数据集进行划分。\n接下来需要继续进行迭代，通过观察我们不难发现，对于数据集B1来说来说，按照student这一列来\n进行展开，能够让子节点的信息熵归零，而数据集B2按照如果按照credit_rating来展开，也同样可以将\n子节点的标签纯度提高至100%。因此该模型最终树的生长形态如下：\n至此，我们就完成了ID3决策树的建模全流程，具体模型结果解读和CART树完全一样，此处不做赘\n述。接下来简单对比ID3和CART树之间的差异：首先，由于ID3是按照列来提取规则、每次展开一列，因\n此每一步生长会有几个分支，其实完全由当前列有几个分类水平决定，而CART树只能进行二叉树的生\n长；其次，由于ID3每次展开一列，因此建模过程中对“列的消耗”非常快，数据集中特征个数就决定了树\n的最大深度，相比之下CART树的备选规则就要多的多，这也使得CART树能够进行更加精细的规则提\n取；当然，尽管CART树和ID3存在着基本理论层面的差异，但有的时候也能通过CART树的方法来挖掘出\n和ID3决策树相同的规律，例如ID3中按照age列一层展开所提取出的三个分类规则，也可以在CART树中\n通过两层树来实现，例如第一层按照是否是<=30来进行划分、第二层围绕不满足第一层条件的数据集进\n一步根据是否>40来进行划分。\n\n此外，需要注意的是，正因为ID3是按照列来进行展开，因此只能处理特征都是离散变量的数据集。\n另外，根据ID3的建模规则我们不难发现，ID3树在实际生长过程中会更倾向于挑选取值较多的分类变量\n展开，但如此一来便更加容易造成模型过拟合，而遗憾的是ID3并没有任何防止过拟合的措施。而这些\nID3的缺陷，则正是C4.5算法的改进方向。接下来我们继续讨论关于C4.5决策树的建模规则。\n当然，对于ID3来说，规则是和分类变量的取值一一绑定的，\n二、C4.5决策树的基本建模流程\n作为ID3的改进版算法，C4.5在ID3的基础上进行了三个方面的优化，首先在衡量不纯度降低的数值\n计算过程中引入信息值（information value，也被称为划分信息度、分支度等）概�\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>ID3 DECISION TREE<|>ORGANIZATION<|>ID3 Decision Tree is a model that uses information gain to decide how to split data sets based on different column values to reduce impurity. It is prone to overfitting as it tends to choose variables with more categories for splitting and lacks measures to prevent overfitting.)\n##\n("entity"<|>CART TREE<|>ORGANIZATION<|>CART Tree, unlike ID3, can perform binary splits allowing for more detailed rule extraction and can handle both discrete and continuous variables. It has a broader set of rules for splitting, potentially reducing the risk of overfitting compared to ID3.)\n##\n("entity"<|>C4.5 DECISION TREE<|>ORGANIZATION<|>C4.5 Decision Tree is an improvement over the ID3 model, optimizing the process of measuring impurity reduction by introducing the concept of information value. It aims to address the limitations of ID3, including its tendency towards overfitting and its limitation to discrete variables.)\n##\n("relationship"<|>ID3 DECISION TREE<|>CART TREE<|>CART Tree is developed as an alternative to the ID3 Decision Tree, capable of binary splits and handling more complex data sets.<|>7)\n##\n("relationship"<|>ID3 DECISION TREE<|>C4.5 DECISION TREE<|>C4.5 Decision Tree is an improvement on the ID3 model, addressing its shortcomings and optimizing its decision-making process.<|>8)\n##\n("relationship"<|>C4.5 DECISION TREE<|>CART TREE<|>Both C4.5 and CART Trees offer advancements over the ID3 model, with C4.5 directly improving upon ID3\'s methodology and CART providing a different approach to tree construction.<|>6)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:46,600 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 27783, Requested 2888. Please try again in 1.342s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:46,602 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '8961919\n然后即可算出按照如此规则进行数据集划分，最终能够减少的不纯度数值：\n# 不纯度下降结果\nent_A - ent_B\n0.24674981977443922\n而该结果也被称为根据age列进行数据集划分后的信息增益（information gain），上述结果可写成\nGain(age) = 0.247\n当然，至此我们只计算了按照age列的不同取值来进行数据集划分后数据集不纯度下降结果，而按照\nage列进行展开只能算是树的第一步生长中的一个备选划分规则，此外我们还需要测试按照income、\nstudent或者credit_rating列展开后数据集不纯度下降情况，具体计算过程和age列展开后的计算过程类\n似，此处直接给出结果，Gain(income)=0.026、Gain(student)=0.151、Gain(credit_rating)=0.048。很\n明显，按照age列展开能够更有效的降低数据集的不纯度，因此树的第一层生长就是按照age列的不同取\n值对数据集进行划分。\n接下来需要继续进行迭代，通过观察我们不难发现，对于数据集B1来说来说，按照student这一列来\n进行展开，能够让子节点的信息熵归零，而数据集B2按照如果按照credit_rating来展开，也同样可以将\n子节点的标签纯度提高至100%。因此该模型最终树的生长形态如下：\n至此，我们就完成了ID3决策树的建模全流程，具体模型结果解读和CART树完全一样，此处不做赘\n述。接下来简单对比ID3和CART树之间的差异：首先，由于ID3是按照列来提取规则、每次展开一列，因\n此每一步生长会有几个分支，其实完全由当前列有几个分类水平决定，而CART树只能进行二叉树的生\n长；其次，由于ID3每次展开一列，因此建模过程中对“列的消耗”非常快，数据集中特征个数就决定了树\n的最大深度，相比之下CART树的备选规则就要多的多，这也使得CART树能够进行更加精细的规则提\n取；当然，尽管CART树和ID3存在着基本理论层面的差异，但有的时候也能通过CART树的方法来挖掘出\n和ID3决策树相同的规律，例如ID3中按照age列一层展开所提取出的三个分类规则，也可以在CART树中\n通过两层树来实现，例如第一层按照是否是<=30来进行划分、第二层围绕不满足第一层条件的数据集进\n一步根据是否>40来进行划分。\n\n此外，需要注意的是，正因为ID3是按照列来进行展开，因此只能处理特征都是离散变量的数据集。\n另外，根据ID3的建模规则我们不难发现，ID3树在实际生长过程中会更倾向于挑选取值较多的分类变量\n展开，但如此一来便更加容易造成模型过拟合，而遗憾的是ID3并没有任何防止过拟合的措施。而这些\nID3的缺陷，则正是C4.5算法的改进方向。接下来我们继续讨论关于C4.5决策树的建模规则。\n当然，对于ID3来说，规则是和分类变量的取值一一绑定的，\n二、C4.5决策树的基本建模流程\n作为ID3的改进版算法，C4.5在ID3的基础上进行了三个方面的优化，首先在衡量不纯度降低的数值\n计算过程中引入信息值（information value，也被称为划分信息度、分支度等）概�'}
11:39:46,803 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:46,805 openai._base_client INFO Retrying request to /chat/completions in 1.196000 seconds
11:39:48,431 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:48,434 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 4.5决策树的基本建模流程\n作为ID3的改进版算法，C4.5在ID3的基础上进行了三个方面的优化，首先在衡量不纯度降低的数值\n计算过程中引入信息值（information value，也被称为划分信息度、分支度等）概念来修正信息熵的计\n算结果，以抑制ID3更倾向于寻找分类水平较多的列来展开的情况，从而间接抑制模型过拟合倾向；其二\n则是新增了连续变量的处理方法，也就是CART树中寻找相邻取值的中间值作为切分点的方法；其三是加\n入了决策树的剪枝流程，使得模型泛化能力能够得到进一步提升。但需要注意的是，尽管有如此改进，\n但C4.5仍然只能解决分类问题，其本质仍然还是一种分类树。接下来我们详细讨论C4.5的具体改进策\n略。\n信息值（information value）\nC4.5中信息值（以下简称IV值）是一个用于衡量数据集在划分时分支个数的指标，如果划分时分支\n越多，IV值就越高。具体IV值的计算公式如下：\nIV值计算公式和信息熵的计算公式基本一致，只是具体计算的比例不再是各类样本所占比例，而是\n各划分后子节点的数据所占比例，或者说信息熵是计算标签不同取值的混乱程度，而IV值就是计算\n特征不同取值的混乱程度\n其中K表示某次划分是总共分支个数，$v_i$表示划分后的某样本，$P(v_i)$表示该样本数量占父节点数据\n量的比例。对于如下三种数据集划分情况，简单计算IV值：\n# 父节点按照50%-50%进行划分\n- (1/2 * np.log2(1/2) + 1/2 * np.log2(1/2))\n1.0\n# 父节点按照1/4-1/2-1/4进行划分\n- (1/4 * np.log2(1/4) + 1/2 * np.log2(1/2)+ 1/4 * np.log2(1/4))\n1.5\n\n# 父节点按照1/4-1/4-1/4-1/4进行划分\n- (1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 *\nnp.log2(1/4))\n2.0\n而在实际建模过程中，ID3是通过信息增益的计算结果挑选划分规则，而C4.5采用IV值对信息增益计算结\n果进行修正，构建新的数据集划分评估指标：增益比例（Gain Ratio，被称为获利比例或增益率），来指\n导具体的划分规则的挑选。GR的计算公式如下：\n也就是说，在C4.5的建模过程中，需要先计算GR，然后选择GR计算结果较大的列来执行这一次展\n开。例如对于上述例子来看，以age列展开后Information Gain结果为：\nIG = ent_A - ent_B\nIG\n0.24674981977443922\n而IV值为：\nIV = - (5/14 * np.log2(5/14) + 5/14 * np.log2(5/14)+ 4/14 * np.log2(4/14))\nIV\n1.5774062828523454\n因此计算得到GR值为：\nGR = IG / IV\nGR\n0.1564275624211752\n然后据此进一步计算其他各列展开后的GR值，并选择GR较大者进行数据集划分。\n\nC4.5的连续变量处理方法\nC4.5允许带入连续变量进行建模，并且围绕连续变量的规则提取方式和此前介绍的CART树一致。即\n在连续变量中寻找相邻的取值的中间点作为备选切分点\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>ID3<|>ORGANIZATION<|>A precursor algorithm to C4.5, known for its approach to decision tree modeling by using information gain but criticized for favoring attributes with more categories and potentially leading to overfitting)##\n("entity"<|>C4.5<|>ORGANIZATION<|>An improved version of the ID3 algorithm that optimizes decision tree modeling by introducing the concept of information value (IV) to adjust information entropy calculations, handling continuous variables, and incorporating a pruning process to enhance model generalization)##\n("entity"<|>INFORMATION VALUE<|>EVENT<|>A metric used in C4.5 to measure the number of branches during data set division, aiming to adjust the calculation of information entropy and indirectly suppress model overfitting tendencies)##\n("entity"<|>GAIN RATIO<|>EVENT<|>An evaluation metric introduced by C4.5 to correct information gain calculations by using the information value (IV), guiding the selection of attributes for data set division)##\n("relationship"<|>C4.5<|>ID3<|>C4.5 is an improved version of the ID3 algorithm, designed to address its limitations and enhance decision tree modeling<|>9)##\n("relationship"<|>C4.5<|>INFORMATION VALUE<|>C4.5 uses the concept of information value (IV) to refine the process of calculating information entropy and to mitigate the tendency towards overfitting<|>8)##\n("relationship"<|>C4.5<|>GAIN RATIO<|>C4.5 introduces the gain ratio as a new metric to adjust information gain calculations and to assist in the selection of attributes for data set division<|>8)##\n("relationship"<|>INFORMATION VALUE<|>GAIN RATIO<|>The information value (IV) is used in the calculation of the gain ratio (GR) in C4.5 to evaluate data set division<|>7)<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:48,434 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29784, Requested 2857. Please try again in 5.282s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:48,437 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '4.5决策树的基本建模流程\n作为ID3的改进版算法，C4.5在ID3的基础上进行了三个方面的优化，首先在衡量不纯度降低的数值\n计算过程中引入信息值（information value，也被称为划分信息度、分支度等）概念来修正信息熵的计\n算结果，以抑制ID3更倾向于寻找分类水平较多的列来展开的情况，从而间接抑制模型过拟合倾向；其二\n则是新增了连续变量的处理方法，也就是CART树中寻找相邻取值的中间值作为切分点的方法；其三是加\n入了决策树的剪枝流程，使得模型泛化能力能够得到进一步提升。但需要注意的是，尽管有如此改进，\n但C4.5仍然只能解决分类问题，其本质仍然还是一种分类树。接下来我们详细讨论C4.5的具体改进策\n略。\n信息值（information value）\nC4.5中信息值（以下简称IV值）是一个用于衡量数据集在划分时分支个数的指标，如果划分时分支\n越多，IV值就越高。具体IV值的计算公式如下：\nIV值计算公式和信息熵的计算公式基本一致，只是具体计算的比例不再是各类样本所占比例，而是\n各划分后子节点的数据所占比例，或者说信息熵是计算标签不同取值的混乱程度，而IV值就是计算\n特征不同取值的混乱程度\n其中K表示某次划分是总共分支个数，$v_i$表示划分后的某样本，$P(v_i)$表示该样本数量占父节点数据\n量的比例。对于如下三种数据集划分情况，简单计算IV值：\n# 父节点按照50%-50%进行划分\n- (1/2 * np.log2(1/2) + 1/2 * np.log2(1/2))\n1.0\n# 父节点按照1/4-1/2-1/4进行划分\n- (1/4 * np.log2(1/4) + 1/2 * np.log2(1/2)+ 1/4 * np.log2(1/4))\n1.5\n\n# 父节点按照1/4-1/4-1/4-1/4进行划分\n- (1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 *\nnp.log2(1/4))\n2.0\n而在实际建模过程中，ID3是通过信息增益的计算结果挑选划分规则，而C4.5采用IV值对信息增益计算结\n果进行修正，构建新的数据集划分评估指标：增益比例（Gain Ratio，被称为获利比例或增益率），来指\n导具体的划分规则的挑选。GR的计算公式如下：\n也就是说，在C4.5的建模过程中，需要先计算GR，然后选择GR计算结果较大的列来执行这一次展\n开。例如对于上述例子来看，以age列展开后Information Gain结果为：\nIG = ent_A - ent_B\nIG\n0.24674981977443922\n而IV值为：\nIV = - (5/14 * np.log2(5/14) + 5/14 * np.log2(5/14)+ 4/14 * np.log2(4/14))\nIV\n1.5774062828523454\n因此计算得到GR值为：\nGR = IG / IV\nGR\n0.1564275624211752\n然后据此进一步计算其他各列展开后的GR值，并选择GR较大者进行数据集划分。\n\nC4.5的连续变量处理方法\nC4.5允许带入连续变量进行建模，并且围绕连续变量的规则提取方式和此前介绍的CART树一致。即\n在连续变量中寻找相邻的取值的中间点作为备选切分点'}
11:39:48,465 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:48,466 openai._base_client INFO Retrying request to /chat/completions in 0.012000 seconds
11:39:48,842 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:48,845 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead.\npresort : deprecated, default=\'deprecated\'\nThis parameter is deprecated and will be removed in v0.24.\n.. deprecated:: 0.22\nccp_alpha : non-negative float, default=0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. The\nsubtree with the largest cost complexity that is smaller than\n``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n:ref:`minimal_cost_complexity_pruning` for details.\n.. versionadded:: 0.22\nAttributes\n---------\nfeature_importances_ : ndarray of shape (n_features,)\nThe feature importances.\nThe higher, the more important the feature.\nThe importance of a feature is computed as the\n(normalized) total reduction of the criterion brought\nby that feature. It is also known as the Gini importance [4]_.\nWarning: impurity-based feature importances can be misleading for\nhigh cardinality features (many unique values). See\n:func:`sklearn.inspection.permutation_importance` as an alternative.\nmax_features_ : int\nThe inferred value of max_features.\nn_features_ : int\nThe number of features when ``fit`` is performed.\nn_outputs_ : int\nThe number of outputs when ``fit`` is performed.\ntree_ : Tree\nThe underlying Tree object. Please refer to\n``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n:ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\nfor basic usage of these attributes.\nSee Also\n\n-------\nDecisionTreeClassifier : A decision tree classifier.\nNotes\n----\nThe default values for the parameters controlling the size of the trees\n(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\nunpruned trees which can potentially be very large on some data sets. To\nreduce memory consumption, the complexity and size of the trees should be\ncontrolled by setting those parameter values.\nReferences\n---------\n.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n.. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, "Classification\nand Regression Trees", Wadsworth, Belmont, CA, 1984.\n.. [3] T. Hastie, R. Tibshirani and J. Friedman. "Elements of Statistical\nLearning", Springer, 2009.\n.. [4] L. Breiman, and A. Cutler, "Random Forests",\nhttps://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\nExamples\n-------\n>>> from sklearn.datasets import load_diabetes\n>>> from sklearn.model_selection import cross_val_score\n>>> from sklearn.tree import DecisionTreeRegressor\n>>> X, y = load_diabetes(return_X_y=True)\n>>> regressor = DecisionTreeRegressor(random_state=0)\n>>> cross_val_score(regressor, X, y, cv=10)\n...\n# doctest: +SKIP\n...\narray([-0.39..., -0.46..., 0.02..., 0.06..., -0.50...,\n0.16..., 0.11..., -0.73..., -0.30..., -0.00...])\nFile:\ns.py\nType:\nSubclasses:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\nABCMeta\nExtraTreeRegressor\n不难发现，其中大多数参数我们在Lesson 8.2中都进行了详细的讲解，此处重点讲解\ncriterion参数取值。criterion是备选划分规则的选取指标，对于CART分类树来说默认基\n尼系数、可选信息熵，而对于CART回归树来说默认mse，同时可选mae和\nfriedman_mse，同时在新版sklearn中，还加入了poisson作为可选参数取值。接下来我\n们就这几个参数不同取值进行介绍：\ncriterion=\'mse\'情况\n当criterion取值为mse时当然是计算误差平方和再除以样本总数，其基本计算流程与\n上述手动实现过程层类似。但有一点可能会对阅读源码的同学造成困扰，那就是在源码中\n子节点整体的MSE计算公式描述如下：\n1\n\n尽管上述公式看起来像是子节点的整体MSE就等于左右两个节点的方差只和，但实际上是\n经过加权之后的方差只和。我们可以通过在手动实现过程中灵活调整\nmin_impurity_decrease参数来进行验证。\n需要注意的是，CART回归树的子节点整体MSE的计算方式是加权求和还是\n简单求和，不同的材料\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>DECISIONTREEREGRESSOR<|>ORGANIZATION<|>A regressor that is part of the sklearn library, used for regression tasks with decision trees)\n##\n("entity"<|>SKLEARN<|>ORGANIZATION<|>A machine learning library for the Python programming language)\n##\n("entity"<|>MIN_IMPURITY_DECREASE<|>EVENT<|>A parameter in sklearn\'s DecisionTreeRegressor that controls when a node will split based on the decrease in impurity)\n##\n("entity"<|>MIN_IMPURITY_SPLIT<|>EVENT<|>A deprecated parameter in sklearn\'s DecisionTreeRegressor that was used to control the splitting of nodes)\n##\n("entity"<|>CCP_ALPHA<|>EVENT<|>A complexity parameter in sklearn\'s DecisionTreeRegressor used for Minimal Cost-Complexity Pruning)\n##\n("entity"<|>LOAD_DIABETES<|>ORGANIZATION<|>A function in sklearn to load the diabetes dataset)\n##\n("entity"<|>CROSS_VAL_SCORE<|>EVENT<|>A function in sklearn to perform cross-validation scoring)\n##\n("relationship"<|>DECISIONTREEREGRESSOR<|>SKLEARN<|>DecisionTreeRegressor is a part of the sklearn library<|>9)\n##\n("relationship"<|>MIN_IMPURITY_DECREASE<|>DECISIONTREEREGRESSOR<|>min_impurity_decrease is a parameter used in DecisionTreeRegressor<|>8)\n##\n("relationship"<|>MIN_IMPURITY_SPLIT<|>DECISIONTREEREGRESSOR<|>min_impurity_split was a parameter used in DecisionTreeRegressor but is now deprecated<|>7)\n##\n("relationship"<|>CCP_ALPHA<|>DECISIONTREEREGRESSOR<|>ccp_alpha is a parameter used in DecisionTreeRegressor for pruning<|>8)\n##\n("relationship"<|>LOAD_DIABETES<|>SKLEARN<|>load_diabetes is a function provided by sklearn to load a dataset<|>9)\n##\n("relationship"<|>CROSS_VAL_SCORE<|>SKLEARN<|>cross_val_score is a function provided by sklearn for cross-validation<|>9)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:48,845 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29582, Requested 3157. Please try again in 5.478s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:48,848 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead.\npresort : deprecated, default=\'deprecated\'\nThis parameter is deprecated and will be removed in v0.24.\n.. deprecated:: 0.22\nccp_alpha : non-negative float, default=0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. The\nsubtree with the largest cost complexity that is smaller than\n``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n:ref:`minimal_cost_complexity_pruning` for details.\n.. versionadded:: 0.22\nAttributes\n---------\nfeature_importances_ : ndarray of shape (n_features,)\nThe feature importances.\nThe higher, the more important the feature.\nThe importance of a feature is computed as the\n(normalized) total reduction of the criterion brought\nby that feature. It is also known as the Gini importance [4]_.\nWarning: impurity-based feature importances can be misleading for\nhigh cardinality features (many unique values). See\n:func:`sklearn.inspection.permutation_importance` as an alternative.\nmax_features_ : int\nThe inferred value of max_features.\nn_features_ : int\nThe number of features when ``fit`` is performed.\nn_outputs_ : int\nThe number of outputs when ``fit`` is performed.\ntree_ : Tree\nThe underlying Tree object. Please refer to\n``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n:ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\nfor basic usage of these attributes.\nSee Also\n\n-------\nDecisionTreeClassifier : A decision tree classifier.\nNotes\n----\nThe default values for the parameters controlling the size of the trees\n(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\nunpruned trees which can potentially be very large on some data sets. To\nreduce memory consumption, the complexity and size of the trees should be\ncontrolled by setting those parameter values.\nReferences\n---------\n.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n.. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, "Classification\nand Regression Trees", Wadsworth, Belmont, CA, 1984.\n.. [3] T. Hastie, R. Tibshirani and J. Friedman. "Elements of Statistical\nLearning", Springer, 2009.\n.. [4] L. Breiman, and A. Cutler, "Random Forests",\nhttps://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\nExamples\n-------\n>>> from sklearn.datasets import load_diabetes\n>>> from sklearn.model_selection import cross_val_score\n>>> from sklearn.tree import DecisionTreeRegressor\n>>> X, y = load_diabetes(return_X_y=True)\n>>> regressor = DecisionTreeRegressor(random_state=0)\n>>> cross_val_score(regressor, X, y, cv=10)\n...\n# doctest: +SKIP\n...\narray([-0.39..., -0.46..., 0.02..., 0.06..., -0.50...,\n0.16..., 0.11..., -0.73..., -0.30..., -0.00...])\nFile:\ns.py\nType:\nSubclasses:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\nABCMeta\nExtraTreeRegressor\n不难发现，其中大多数参数我们在Lesson 8.2中都进行了详细的讲解，此处重点讲解\ncriterion参数取值。criterion是备选划分规则的选取指标，对于CART分类树来说默认基\n尼系数、可选信息熵，而对于CART回归树来说默认mse，同时可选mae和\nfriedman_mse，同时在新版sklearn中，还加入了poisson作为可选参数取值。接下来我\n们就这几个参数不同取值进行介绍：\ncriterion=\'mse\'情况\n当criterion取值为mse时当然是计算误差平方和再除以样本总数，其基本计算流程与\n上述手动实现过程层类似。但有一点可能会对阅读源码的同学造成困扰，那就是在源码中\n子节点整体的MSE计算公式描述如下：\n1\n\n尽管上述公式看起来像是子节点的整体MSE就等于左右两个节点的方差只和，但实际上是\n经过加权之后的方差只和。我们可以通过在手动实现过程中灵活调整\nmin_impurity_decrease参数来进行验证。\n需要注意的是，CART回归树的子节点整体MSE的计算方式是加权求和还是\n简单求和，不同的材料'}
11:39:49,7 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:39:49,59 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:49,60 openai._base_client INFO Retrying request to /chat/completions in 5.494000 seconds
11:39:55,372 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:55,375 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: :`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for potential splits,\nand "mae" for the mean absolute error, which minimizes the L1 loss\nusing the median of each terminal node.\n.. versionadded:: 0.18\nMean Absolute Error (MAE) criterion.\nsplitter : {"best", "random"}, default="best"\nThe strategy used to choose the split at each node. Supported\nstrategies are "best" to choose the best split and "random" to choose\nthe best random split.\nmax_depth : int, default=None\nThe maximum depth of the tree. If None, then nodes are expanded until\nall leaves are pure or until all leaves contain less than\nmin_samples_split samples.\nmin_samples_split : int or float, default=2\nThe minimum number of samples required to split an internal node:\n- If int, then consider `min_samples_split` as the minimum number.\n- If float, then `min_samples_split` is a fraction and\n`ceil(min_samples_split * n_samples)` are the minimum\nnumber of samples for each split.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_samples_leaf : int or float, default=1\nThe minimum number of samples required to be at a leaf node.\nA split point at any depth will only be considered if it leaves at\n\nleast ``min_samples_leaf`` training samples in each of the left and\nright branches. This may have the effect of smoothing the model,\nespecially in regression.\n- If int, then consider `min_samples_leaf` as the minimum number.\n- If float, then `min_samples_leaf` is a fraction and\n`ceil(min_samples_leaf * n_samples)` are the minimum\nnumber of samples for each node.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_weight_fraction_leaf : float, default=0.0\nThe minimum weighted fraction of the sum total of weights (of all\nthe input samples) required to be at a leaf node. Samples have\nequal weight when sample_weight is not provided.\nmax_features : int, float or {"auto", "sqrt", "log2"}, default=None\nThe number of features to consider when looking for the best split:\n- If int, then consider `max_features` features at each split.\n- If float, then `max_features` is a fraction and\n`int(max_features * n_features)` features are considered at each\nsplit.\n- If "auto", then `max_features=n_features`.\n- If "sqrt", then `max_features=sqrt(n_features)`.\n- If "log2", then `max_features=log2(n_features)`.\n- If None, then `max_features=n_features`.\nNote: the search for a split does not stop until at least one\nvalid partition of the node samples is found, even if it requires to\neffectively inspect more than ``max_features`` features.\nrandom_state : int, RandomState instance, default=None\nControls the randomness of the estimator. The features are always\nrandomly permuted at each split, even if ``splitter`` is set to\n``"best"``. When ``max_features < n_features``, the algorithm will\nselect ``max_features`` at random at each split before finding the best\nsplit among them. But the best found split may vary across different\nruns, even if ``max_features=n_features``. That is the case, if the\nimprovement of the criterion is identical for several splits and one\nsplit has to be selected at random. To obtain a deterministic behaviour\nduring fitting, ``random_state`` has to be fixed to an integer.\nSee :term:`Glossary <random_state>` for details.\nmax_leaf_nodes : int, default=None\nGrow a tree with ``max_leaf_nodes`` in best-first fashion.\nBest nodes are defined as relative reduction in impurity.\nIf None then unlimited number of leaf nodes.\nmin_impurity_decrease : float, default=0.0\nA node will be split if this split induces a decrease of the impurity\ngreater than or equal to this value.\nThe weighted impurity decrease equation is the following::\nN_t / N * (impurity - N_t_R / N_t * right_impurity\n- N_t_L / N_t * left_impurity)\nwhere ``N`` is the total number of samples, ``N_t`` is the number of\n\nsamples at the current node, ``N_t_L`` is the number of samples in the\nleft child, and ``N_t_R`` is the number of samples in the right child.\n``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\nmin_impurity_split : float, (default=0)\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>MSE<|>EVENT<|>Mean Squared Error (MSE) is a criterion for measuring the quality of a split in decision trees, focusing on minimizing the L2 loss by using the mean of each terminal node)\n##\n("entity"<|>FRIEDMAN_MSE<|>EVENT<|>Friedman MSE uses mean squared error with Friedman\'s improvement score for potential splits in decision trees)\n##\n("entity"<|>MAE<|>EVENT<|>Mean Absolute Error (MAE) is a criterion that minimizes the L1 loss using the median of each terminal node in decision trees)\n##\n("entity"<|>BEST<|>EVENT<|>A strategy used in decision trees to choose the best split at each node)\n##\n("entity"<|>RANDOM<|>EVENT<|>A strategy used in decision trees to choose a split randomly at each node)\n##\n("entity"<|>RANDOM_STATE<|>EVENT<|>Controls the randomness of the estimator in decision trees, affecting feature permutation and split selection)\n##\n("relationship"<|>MSE<|>MAE<|>Both MSE and MAE are criteria used to measure the quality of a split in decision trees, but they focus on minimizing different types of loss<|>5)\n##\n("relationship"<|>BEST<|>RANDOM<|>Both are strategies used to choose the split at each node in decision trees, but they follow different approaches<|>5)\n##\n("relationship"<|>RANDOM_STATE<|>BEST<|>Random state controls the randomness in the \'best\' strategy by affecting feature permutation and split selection<|>4)\n##\n("relationship"<|>RANDOM_STATE<|>RANDOM<|>Random state also influences the \'random\' strategy by determining how features and splits are selected randomly<|>4)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:55,375 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 26861, Requested 3274. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:55,377 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ':`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for potential splits,\nand "mae" for the mean absolute error, which minimizes the L1 loss\nusing the median of each terminal node.\n.. versionadded:: 0.18\nMean Absolute Error (MAE) criterion.\nsplitter : {"best", "random"}, default="best"\nThe strategy used to choose the split at each node. Supported\nstrategies are "best" to choose the best split and "random" to choose\nthe best random split.\nmax_depth : int, default=None\nThe maximum depth of the tree. If None, then nodes are expanded until\nall leaves are pure or until all leaves contain less than\nmin_samples_split samples.\nmin_samples_split : int or float, default=2\nThe minimum number of samples required to split an internal node:\n- If int, then consider `min_samples_split` as the minimum number.\n- If float, then `min_samples_split` is a fraction and\n`ceil(min_samples_split * n_samples)` are the minimum\nnumber of samples for each split.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_samples_leaf : int or float, default=1\nThe minimum number of samples required to be at a leaf node.\nA split point at any depth will only be considered if it leaves at\n\nleast ``min_samples_leaf`` training samples in each of the left and\nright branches. This may have the effect of smoothing the model,\nespecially in regression.\n- If int, then consider `min_samples_leaf` as the minimum number.\n- If float, then `min_samples_leaf` is a fraction and\n`ceil(min_samples_leaf * n_samples)` are the minimum\nnumber of samples for each node.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_weight_fraction_leaf : float, default=0.0\nThe minimum weighted fraction of the sum total of weights (of all\nthe input samples) required to be at a leaf node. Samples have\nequal weight when sample_weight is not provided.\nmax_features : int, float or {"auto", "sqrt", "log2"}, default=None\nThe number of features to consider when looking for the best split:\n- If int, then consider `max_features` features at each split.\n- If float, then `max_features` is a fraction and\n`int(max_features * n_features)` features are considered at each\nsplit.\n- If "auto", then `max_features=n_features`.\n- If "sqrt", then `max_features=sqrt(n_features)`.\n- If "log2", then `max_features=log2(n_features)`.\n- If None, then `max_features=n_features`.\nNote: the search for a split does not stop until at least one\nvalid partition of the node samples is found, even if it requires to\neffectively inspect more than ``max_features`` features.\nrandom_state : int, RandomState instance, default=None\nControls the randomness of the estimator. The features are always\nrandomly permuted at each split, even if ``splitter`` is set to\n``"best"``. When ``max_features < n_features``, the algorithm will\nselect ``max_features`` at random at each split before finding the best\nsplit among them. But the best found split may vary across different\nruns, even if ``max_features=n_features``. That is the case, if the\nimprovement of the criterion is identical for several splits and one\nsplit has to be selected at random. To obtain a deterministic behaviour\nduring fitting, ``random_state`` has to be fixed to an integer.\nSee :term:`Glossary <random_state>` for details.\nmax_leaf_nodes : int, default=None\nGrow a tree with ``max_leaf_nodes`` in best-first fashion.\nBest nodes are defined as relative reduction in impurity.\nIf None then unlimited number of leaf nodes.\nmin_impurity_decrease : float, default=0.0\nA node will be split if this split induces a decrease of the impurity\ngreater than or equal to this value.\nThe weighted impurity decrease equation is the following::\nN_t / N * (impurity - N_t_R / N_t * right_impurity\n- N_t_L / N_t * left_impurity)\nwhere ``N`` is the total number of samples, ``N_t`` is the number of\n\nsamples at the current node, ``N_t_L`` is the number of samples in the\nleft child, and ``N_t_R`` is the number of samples in the right child.\n``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\nmin_impurity_split : float, (default=0)\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead'}
11:40:03,658 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:08,817 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:08,829 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:10,235 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:10,429 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:11,834 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:12,20 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:13,216 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:14,142 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:15,485 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:23,890 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:27,116 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:27,174 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:40:27,180 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:40:27,224 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:40:27,226 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:40:27,255 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:40:27,257 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:40:27,259 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:40:27,291 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:40:27,292 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:40:27,294 graphrag.utils.storage INFO reading table from storage: communities.parquet
11:40:27,300 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 23
11:40:45,432 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:57,953 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:41:04,526 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:41:05,212 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:41:13,842 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:41:13,903 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:41:13,910 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:41:13,915 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:41:13,921 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:41:13,929 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
11:41:13,936 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
11:41:13,936 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
11:41:14,200 graphrag.index.operations.embed_text.strategies.openai INFO embedding 52 inputs via 52 snippets using 4 batches. max_batch_size=16, batch_max_tokens=8191
11:41:15,329 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:41:16,705 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:41:16,844 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:41:17,28 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:41:17,755 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
11:41:17,759 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
11:41:18,251 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:41:18,689 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
11:41:18,714 graphrag.index.operations.embed_text.strategies.openai INFO embedding 37 inputs via 37 snippets using 6 batches. max_batch_size=16, batch_max_tokens=8191
11:41:19,453 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:41:19,933 graphrag.cli.index INFO All workflows completed successfully.
