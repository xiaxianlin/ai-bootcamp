11:02:52,151 graphrag.cli.index INFO Logging enabled at /Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/logs/indexing-engine.log
11:02:58,597 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:00,539 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:03:00,541 graphrag.cli.index INFO Starting pipeline run. dry_run=False
11:03:00,543 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
11:03:00,543 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/output
11:03:00,544 graphrag.index.input.factory INFO loading input from root_dir=input
11:03:00,544 graphrag.index.input.factory INFO using file storage for input
11:03:00,546 graphrag.storage.file_pipeline_storage INFO search /Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/input for files matching .*\.txt$
11:03:00,551 graphrag.index.input.util INFO Found 1 InputFileType.text files, loading 1
11:03:00,551 graphrag.index.input.util INFO Total number of unfiltered InputFileType.text rows: 1
11:03:00,554 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 1
11:03:00,586 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:03:00,665 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:03:00,667 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:03:00,685 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:03:06,874 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:07,830 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,830 openai._base_client INFO Retrying request to /chat/completions in 2.694000 seconds
11:03:07,831 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,832 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,832 openai._base_client INFO Retrying request to /chat/completions in 2.686000 seconds
11:03:07,833 openai._base_client INFO Retrying request to /chat/completions in 2.374000 seconds
11:03:07,838 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,839 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:07,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,855 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:07,858 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,859 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:07,864 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,865 openai._base_client INFO Retrying request to /chat/completions in 2.346000 seconds
11:03:07,879 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:07,880 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:08,352 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:08,446 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:08,582 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:08,596 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:08,658 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:08,698 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:08,699 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:08,877 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:08,878 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:08,938 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:08,939 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:08,950 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:08,951 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:09,14 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:09,17 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:10,66 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:10,450 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:10,451 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:10,556 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:10,556 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:10,558 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:10,558 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:10,867 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:10,868 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:10,879 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:10,883 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:12,413 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:12,790 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:12,791 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:03:12,969 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:12,971 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:13,198 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:13,198 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:13,602 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:13,616 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:13,618 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:13,931 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:13,932 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:13,936 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:13,937 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:13,938 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:13,938 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:13,960 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:13,961 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:14,126 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:14,126 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:14,296 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:14,297 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:14,405 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:14,784 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:14,786 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:14,832 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:14,882 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:15,74 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:15,175 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,176 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:15,190 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:15,202 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,203 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:15,236 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,237 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:15,424 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,424 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:03:15,518 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,519 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:15,542 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,542 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:15,543 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,543 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:15,733 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:15,736 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:16,74 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:16,75 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:16,90 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:16,92 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:16,752 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:16,951 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:17,106 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:17,107 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:03:17,329 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:17,330 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:03:18,154 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:18,156 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:18,524 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:18,525 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:18,890 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:18,891 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:18,986 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:18,987 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:19,182 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:19,184 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:03:19,192 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:19,194 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:19,195 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:19,197 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:19,372 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:19,374 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:19,382 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:19,383 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:19,715 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:19,717 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:20,461 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:20,491 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:20,494 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:20,534 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:20,535 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:20,579 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:20,580 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:20,811 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:20,812 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:03:20,850 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:20,852 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:20,944 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:20,945 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:20,951 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:20,952 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:21,285 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:21,286 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:21,300 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:21,301 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:21,311 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:21,312 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:21,324 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:21,325 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:21,343 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:21,349 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:03:21,567 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:03:21,990 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:21,992 openai._base_client INFO Retrying request to /chat/completions in 6.112000 seconds
11:03:23,109 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:23,110 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:03:23,266 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:23,266 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:23,391 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:23,392 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:03:23,912 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:23,913 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:23,914 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:23,914 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:24,97 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:24,98 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:24,432 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:24,433 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:24,628 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:24,629 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:24,857 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:24,858 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:25,144 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:25,146 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:25,147 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:25,148 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:25,517 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:25,518 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:03:25,531 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:25,532 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:25,670 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:25,671 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:26,193 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:26,193 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:26,198 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:26,198 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:26,525 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:26,527 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:26,530 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:26,531 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:26,720 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:26,722 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:26,822 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:26,823 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:03:26,926 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:26,927 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:27,111 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:27,112 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:27,280 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:27,281 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:03:27,426 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:27,427 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:28,368 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:28,369 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:28,460 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:28,460 openai._base_client INFO Retrying request to /chat/completions in 6.112000 seconds
11:03:28,861 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:28,863 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:29,150 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:29,152 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:29,165 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:29,166 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:03:29,224 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:29,225 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:29,363 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:29,365 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:03:29,681 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:29,682 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:29,910 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:29,911 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:30,88 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:30,89 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:30,530 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:30,531 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:30,548 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:30,549 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:30,737 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:30,737 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:30,912 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:30,913 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:31,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:31,444 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:31,801 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:31,802 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:31,841 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:31,842 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:03:31,963 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:31,965 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:32,141 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:32,142 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:32,488 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:32,489 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:32,493 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:32,495 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:32,842 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:32,843 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:03:32,893 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:32,893 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:33,192 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:33,193 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:03:33,540 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:33,541 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:33,563 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:33,564 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:33,884 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:33,885 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:34,206 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:34,207 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:34,534 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:34,535 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:34,906 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:34,907 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:34,927 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:34,928 openai._base_client INFO Retrying request to /chat/completions in 6.112000 seconds
11:03:35,222 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:35,222 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:35,222 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:35,223 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:03:35,408 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:35,409 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:35,409 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:35,410 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:03:35,762 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:35,762 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:35,810 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:35,811 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:35,930 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:35,931 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:36,604 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:36,605 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:36,669 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:36,670 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:37,5 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:37,6 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:37,345 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:37,347 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:37,651 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:37,651 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:38,148 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:38,149 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:38,169 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:38,169 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:03:38,207 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:38,207 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:38,651 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:38,653 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:38,688 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:38,689 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:38,830 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:38,831 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:38,853 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:38,854 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:03:39,119 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:39,120 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:03:39,311 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:39,313 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:39,683 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:39,685 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:39,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:39,851 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:40,130 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:40,131 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:40,487 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:40,488 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:40,656 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:40,656 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:40,747 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:40,748 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:40,889 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:40,890 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:41,215 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:41,216 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:03:41,304 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:41,304 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:41,380 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:41,381 openai._base_client INFO Retrying request to /chat/completions in 6.112000 seconds
11:03:41,383 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:41,383 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:03:41,773 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:41,774 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:42,229 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:42,230 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:42,427 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:42,427 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:42,564 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:42,565 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:43,339 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:43,339 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:43,796 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:43,797 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:43,797 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:43,798 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:43,799 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:43,800 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:43,919 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:43,920 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:44,350 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:44,351 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:44,494 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:44,494 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:44,501 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:44,502 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:03:44,852 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:44,853 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:03:45,45 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:45,46 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:03:45,172 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:45,173 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:45,365 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:45,366 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:45,738 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:45,739 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:45,748 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:45,749 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:45,891 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:45,892 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:45,895 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:45,896 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:46,416 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:46,417 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:46,746 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:46,748 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:46,947 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:46,948 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:47,266 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:47,268 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:03:47,462 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:47,464 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:03:47,464 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:47,465 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:47,800 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:47,801 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:47,836 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:47,837 openai._base_client INFO Retrying request to /chat/completions in 6.112000 seconds
11:03:48,219 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:48,219 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:48,744 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:48,745 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:48,896 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:48,897 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:49,38 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:49,40 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:49,392 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:49,394 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:49,458 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:49,459 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:49,636 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:49,638 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:50,285 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,287 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:50,489 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,489 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:50,613 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,615 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:50,726 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,727 openai._base_client INFO Retrying request to /chat/completions in 4.638000 seconds
11:03:50,836 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,837 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:03:50,854 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,855 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:03:50,955 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,956 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:03:50,988 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:50,989 openai._base_client INFO Retrying request to /chat/completions in 4.902000 seconds
11:03:51,135 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:51,136 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:03:51,488 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:51,489 openai._base_client INFO Retrying request to /chat/completions in 4.712000 seconds
11:03:52,17 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:52,18 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:03:52,183 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:52,184 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:52,185 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:52,185 openai._base_client INFO Retrying request to /chat/completions in 4.818000 seconds
11:03:52,708 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:52,709 openai._base_client INFO Retrying request to /chat/completions in 4.864000 seconds
11:03:53,53 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:53,54 openai._base_client INFO Retrying request to /chat/completions in 4.858000 seconds
11:03:53,255 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:53,255 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:03:53,455 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:53,456 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:03:53,758 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:53,760 openai._base_client INFO Retrying request to /chat/completions in 4.598000 seconds
11:03:53,983 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:53,985 openai._base_client INFO Retrying request to /chat/completions in 5.404000 seconds
11:03:54,47 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:54,49 openai._base_client INFO Retrying request to /chat/completions in 4.754000 seconds
11:03:54,293 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:54,293 openai._base_client INFO Retrying request to /chat/completions in 6.112000 seconds
11:03:54,443 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:54,445 openai._base_client INFO Retrying request to /chat/completions in 4.698000 seconds
11:03:54,822 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:54,823 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:03:55,166 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:55,166 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:03:55,352 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:55,353 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:03:55,709 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:55,724 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: .79155147]),\n, 2.8825456 , 1.72445091]),\n, 2.88019419, 1.65301627]),\n, 2.88195891, 1.57737666]),\n, 2.88257639, 1.50019671]),\n, 2.87738246, 1.42399342]),\n, 2.87838348, 1.34196882]),\n, 2.87819075, 1.25807283]),\n, 2.87837266, 1.17126788]),\n, 2.87954995, 1.08097403]),\n, 2.87461386, 0.99136144]),\n, 2.87753456, 0.8936161 ]),\n, 2.87862803, 0.79343685]),\n, 2.87693487, 0.69125766]),\n, 2.88278875, 0.57993285]),\n, 2.88375547, 0.4673023 ]),\n, 2.8905426 , 0.34569528]),\n, 2.89382002, 0.22104421]),\n, 2.89895922, 0.08901774]),\n]),\n, 2.84407415, 0.\n, 2.77380838, 0.\n, 2.69757572, 0.\n, 2.62431686, 0.\n, 2.54003727, 0.\n, 2.45326688, 0.\n, 2.3624031, 0.\n, 2.26654779, 0.\n, 2.16159776, 0.\n, 2.05106895, 0.\n, 1.93251455, 0.\n, 1.80075548, 0.\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n])]\n\nl1C0.2\n\n\nIn [69]:\nIn [71]:\nOut[71]:\nIn [72]:\nOut[72]:\nclf = LogisticRegression(penalty=\'l1\', C=0.2, max_iter=int(1e6), solver=\'saga\').\nclf.coef_, clf.intercept_\n(array([[0.\n, 0.\narray([-13.88186328]))\nclf.score(X, y)\n0.93\n, 2.84518611, 0.\n]]),\n\n93%\nx=bb\nIn [75]:\nOut[75]:\nb = 13.88186328 / 2.84518611\nb\n4.87907038179657\nx=b\n\nIn [84]:\nplt.plot(X[:, 2][y==1], X[:, 3][y==1], \'ro\')\nplt.plot(X[:, 2][y==2], X[:, 3][y==2], \'bo\')\nplt.plot(np.array([b]*20), np.arange(0.5, 2.5, 0.1), \'r--\')\nOut[84]:\n[<matplotlib.lines.Line2D at 0x7ffb992d39a0>]\nIn [80]:\nIn [79]:\nOut[79]:\nx=b\ny_pred = clf.predict(X)\nplt.scatter(X[:, 2], X[:, 3], c=y_pred)\nplt.plot(np.array([b]*20), np.arange(0.5, 2.5, 0.1), \'r--\')\n[<matplotlib.lines.Line2D at 0x7ffbab00c4c0>]\n\n\nmvm\n\n\nx=b100%\npetal length (cm) <=\n######################\nOutput:', 'kwargs': {}}
11:03:55,724 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 30000, Requested 2319. Please try again in 4.638s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:03:55,727 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ".79155147]),\n, 2.8825456 , 1.72445091]),\n, 2.88019419, 1.65301627]),\n, 2.88195891, 1.57737666]),\n, 2.88257639, 1.50019671]),\n, 2.87738246, 1.42399342]),\n, 2.87838348, 1.34196882]),\n, 2.87819075, 1.25807283]),\n, 2.87837266, 1.17126788]),\n, 2.87954995, 1.08097403]),\n, 2.87461386, 0.99136144]),\n, 2.87753456, 0.8936161 ]),\n, 2.87862803, 0.79343685]),\n, 2.87693487, 0.69125766]),\n, 2.88278875, 0.57993285]),\n, 2.88375547, 0.4673023 ]),\n, 2.8905426 , 0.34569528]),\n, 2.89382002, 0.22104421]),\n, 2.89895922, 0.08901774]),\n]),\n, 2.84407415, 0.\n, 2.77380838, 0.\n, 2.69757572, 0.\n, 2.62431686, 0.\n, 2.54003727, 0.\n, 2.45326688, 0.\n, 2.3624031, 0.\n, 2.26654779, 0.\n, 2.16159776, 0.\n, 2.05106895, 0.\n, 1.93251455, 0.\n, 1.80075548, 0.\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n]),\n])]\n\nl1C0.2\n\n\nIn [69]:\nIn [71]:\nOut[71]:\nIn [72]:\nOut[72]:\nclf = LogisticRegression(penalty='l1', C=0.2, max_iter=int(1e6), solver='saga').\nclf.coef_, clf.intercept_\n(array([[0.\n, 0.\narray([-13.88186328]))\nclf.score(X, y)\n0.93\n, 2.84518611, 0.\n]]),\n\n93%\nx=bb\nIn [75]:\nOut[75]:\nb = 13.88186328 / 2.84518611\nb\n4.87907038179657\nx=b\n\nIn [84]:\nplt.plot(X[:, 2][y==1], X[:, 3][y==1], 'ro')\nplt.plot(X[:, 2][y==2], X[:, 3][y==2], 'bo')\nplt.plot(np.array([b]*20), np.arange(0.5, 2.5, 0.1), 'r--')\nOut[84]:\n[<matplotlib.lines.Line2D at 0x7ffb992d39a0>]\nIn [80]:\nIn [79]:\nOut[79]:\nx=b\ny_pred = clf.predict(X)\nplt.scatter(X[:, 2], X[:, 3], c=y_pred)\nplt.plot(np.array([b]*20), np.arange(0.5, 2.5, 0.1), 'r--')\n[<matplotlib.lines.Line2D at 0x7ffbab00c4c0>]\n\n\nmvm\n\n\nx=b100%\npetal length (cm) <="}
11:03:55,855 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:55,855 openai._base_client INFO Retrying request to /chat/completions in 4.962000 seconds
11:03:55,867 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:55,867 openai._base_client INFO Retrying request to /chat/completions in 4.874000 seconds
11:03:56,75 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:56,77 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:03:56,88 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:56,89 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:03:56,243 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:56,244 openai._base_client INFO Retrying request to /chat/completions in 4.854000 seconds
11:03:56,382 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:56,383 openai._base_client INFO Retrying request to /chat/completions in 4.714000 seconds
11:03:56,544 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:56,546 openai._base_client INFO Retrying request to /chat/completions in 4.360000 seconds
11:03:56,902 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:56,904 openai._base_client INFO Retrying request to /chat/completions in 4.998000 seconds
11:03:56,905 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:56,906 openai._base_client INFO Retrying request to /chat/completions in 4.930000 seconds
11:03:57,238 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:57,239 openai._base_client INFO Retrying request to /chat/completions in 4.942000 seconds
11:03:57,426 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:57,429 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Gini(A)\nGini(B)\n\nincome <= 1.5\nIn [14]:\nOut[14]:\ngini_A - gini_B\n0.16875\n\nIn [15]:\np = 3/4\ngini_B2 = 1 - np.power([p, 1-p], 2).sum()\ngini_B2\nOut[15]:\nIn [16]:\nIn [17]:\nOut[17]:\nIn [18]:\nOut[18]:\n0.375\ngini_B1 = 0\ngini_B = gini_B1 * 1/2 + gini_B2 * 1/2\ngini_B\n0.1875\ngini_A - gini_B\n0.28125\n\ncredit_rating <= 1.5\n\nID3C4.5\n1.4 \n\nB1B2\n1\n\nB10B2\n0.375\nAB2\nB2income <= 1.5\n1\nC1C20C\n0\n\n\n\n\n\n\nK-Means\nSSE\n\n\n\n\n######################\nOutput:', 'kwargs': {}}
11:03:57,430 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29422, Requested 2409. Please try again in 3.662s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:03:57,433 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'Gini(A)\nGini(B)\n\nincome <= 1.5\nIn [14]:\nOut[14]:\ngini_A - gini_B\n0.16875\n\nIn [15]:\np = 3/4\ngini_B2 = 1 - np.power([p, 1-p], 2).sum()\ngini_B2\nOut[15]:\nIn [16]:\nIn [17]:\nOut[17]:\nIn [18]:\nOut[18]:\n0.375\ngini_B1 = 0\ngini_B = gini_B1 * 1/2 + gini_B2 * 1/2\ngini_B\n0.1875\ngini_A - gini_B\n0.28125\n\ncredit_rating <= 1.5\n\nID3C4.5\n1.4 \n\nB1B2\n1\n\nB10B2\n0.375\nAB2\nB2income <= 1.5\n1\nC1C20C\n0\n\n\n\n\n\n\nK-Means\nSSE\n\n\n\n'}
11:03:57,546 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:57,547 openai._base_client INFO Retrying request to /chat/completions in 3.668000 seconds
11:03:57,778 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:57,779 openai._base_client INFO Retrying request to /chat/completions in 3.168000 seconds
11:03:57,951 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:57,953 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: cv=10)\n...\n# doctest: +SKIP\n...\narray([ 1.\n, 0.93..., 0.86..., 0.93..., 0.93...,\n0.93..., 0.93..., 1.\n, 0.93..., 1.\n])\n\nFile:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\ns.py\nType:\nSubclasses:\nName\ncriterion\nsplitter\nmax_depth\nmin_samples_split\nmin_samples_leaf\nmin_weight_fraction_leaf\nmax_features\nrandom_state\nmax_leaf_nodes\nmin_impurity_decrease\nmin_impurity_split\nclass_weight\npresort\nccp_alpha\nABCMeta\nExtraTreeClassifier\nDescription\n\n\n\nmax_iter\n\n\n\n\n\n\n\n0.25\n\n0.24\nCART\n\n\ncriterion\nsklearnCART\ncriterion\nID3C4.5\n\n\n\n\n\nccp_alpha\nccpCost-Complexity Pruningsklearn0.22\nCART\nsklearn\nccp\n\n\n\nT \n   \n\nR(T)\n| T|\n\n| T|\nR(T) = R(T) + | T|\nR(T)\n \n######################\nOutput:', 'kwargs': {}}
11:03:57,953 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29136, Requested 2432. Please try again in 3.136s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:03:57,955 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'cv=10)\n...\n# doctest: +SKIP\n...\narray([ 1.\n, 0.93..., 0.86..., 0.93..., 0.93...,\n0.93..., 0.93..., 1.\n, 0.93..., 1.\n])\n\nFile:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\ns.py\nType:\nSubclasses:\nName\ncriterion\nsplitter\nmax_depth\nmin_samples_split\nmin_samples_leaf\nmin_weight_fraction_leaf\nmax_features\nrandom_state\nmax_leaf_nodes\nmin_impurity_decrease\nmin_impurity_split\nclass_weight\npresort\nccp_alpha\nABCMeta\nExtraTreeClassifier\nDescription\n\n\n\nmax_iter\n\n\n\n\n\n\n\n0.25\n\n0.24\nCART\n\n\ncriterion\nsklearnCART\ncriterion\nID3C4.5\n\n\n\n\n\nccp_alpha\nccpCost-Complexity Pruningsklearn0.22\nCART\nsklearn\nccp\n\n\n\nT \n   \n\nR(T)\n| T|\n\n| T|\nR(T) = R(T) + | T|\nR(T)\n '}
11:03:58,152 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:58,153 openai._base_client INFO Retrying request to /chat/completions in 3.832000 seconds
11:03:58,277 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:58,278 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \n\n\n\nABABA\nB\n(1)root node\n(2)internal node\n(3)leaf node\n\n\n\n\n\nEpetal length (cm) <= 2.5petal length\n(cm) <= 4.879False\n\n\n\n\n\n\nID3(Iterative Dichotomiser 3) C4.5C5.0\nID3\nRoss Quinlan1975\n\nC4.5ID3C4.5ID3\n\n\nID3\nC4.5\nC4.5C4.5\nIEEE10\n######################\nOutput:', 'kwargs': {}}
11:03:58,278 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28976, Requested 2429. Please try again in 2.81s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:03:58,279 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '\n\n\n\nABABA\nB\n(1)root node\n(2)internal node\n(3)leaf node\n\n\n\n\n\nEpetal length (cm) <= 2.5petal length\n(cm) <= 4.879False\n\n\n\n\n\n\nID3(Iterative Dichotomiser 3) C4.5C5.0\nID3\nRoss Quinlan1975\n\nC4.5ID3C4.5ID3\n\n\nID3\nC4.5\nC4.5C4.5\nIEEE10'}
11:03:58,324 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:58,324 openai._base_client INFO Retrying request to /chat/completions in 2.620000 seconds
11:03:58,625 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:58,626 openai._base_client INFO Retrying request to /chat/completions in 2.468000 seconds
11:03:58,712 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:58,714 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: ]:\nax = plt.gca()\nax.plot(C_l, coef_l)\nax.set_xlim(ax.get_xlim()[::-1])\nplt.xlabel(\'C\')\nplt.ylabel(\'weights\')\nOut[68]:\nText(0, 0.5, \'weights\')\n\nIn [67]:\ncoef_l\n\nOut[67]:\n[array([-1.12493251, -0.96058774, 3.23208646, 4.18486998]),\narray([-1.10210628, -0.91621566, 3.23983307, 4.15696154]),\narray([-1.09239629, -0.89555328, 3.23399288, 4.13377003]),\narray([-1.08811789, -0.88498435, 3.22207551, 4.11256892]),\narray([-1.06705294, -0.84236856, 3.2289702 , 4.08417288]),\narray([-1.05818676, -0.82271916, 3.22212123, 4.06049626]),\narray([-1.04514314, -0.79483425, 3.22012176, 4.034832 ]),\narray([-1.03859953, -0.77953758, 3.21025372, 4.01174608]),\narray([-1.02237904, -0.74473771, 3.21227469, 3.98396209]),\narray([-1.01620836, -0.73001684, 3.20160007, 3.96062442]),\narray([-0.99903143, -0.69243737, 3.20521982, 3.9315887 ]),\narray([-0.98882191, -0.66904752, 3.19966674, 3.90573051]),\narray([-0.97415883, -0.63587402, 3.2003062 , 3.87718618]),\narray([-0.96452518, -0.61330431, 3.19380232, 3.8510462 ]),\narray([-0.95257941, -0.58551283, 3.19060737, 3.8232743 ]),\narray([-0.9405302 , -0.55717711, 3.18755498, 3.79513594]),\narray([-0.92797551, -0.52743767, 3.18526488, 3.76634082]),\narray([-0.92072072, -0.50938749, 3.17475278, 3.74036246]),\narray([-0.90510269, -0.47211112, 3.17719028, 3.70899839]),\narray([-0.89009202, -0.43569901, 3.1788934 , 3.67756566]),\narray([-0.87766924, -0.4050523 , 3.17640578, 3.64738615]),\narray([-0.87286899, -0.39228757, 3.16090415, 3.62179933]),\narray([-0.85425355, -0.34619248, 3.16885758, 3.58676224]),\narray([-0.84887206, -0.33207553, 3.15364443, 3.56032998]),\narray([-0.83147761, -0.28802875, 3.15964514, 3.52515956]),\narray([-0.81352053, -0.24176251, 3.16723112, 3.4889317 ]),\narray([-0.80378813, -0.21608039, 3.15931029, 3.45833305]),\narray([-0.7917758 , -0.1843569 , 3.15554737, 3.42568574]),\narray([-0.7759623 , -0.14232637, 3.15919161, 3.38962502]),\narray([-0.76332702, -0.10825391, 3.15647641, 3.35556836]),\narray([-0.74997069, -0.07184156, 3.15520495, 3.32047552]),\narray([-0.73849732, -0.04031354, 3.14976963, 3.28653383]),\narray([-0.72392909, 0.\n, 3.15076775, 3.24952256]),\narray([-0.72367263, 0.\narray([-0.71773131, 0.\narray([-0.72374493, 0.\narray([-0.7173857 , 0.\narray([-0.70523493, 0.\narray([-0.69782327, 0.\narray([-0.69307433, 0.\narray([-0.65156996, 0.\narray([-0.61274879, 0.\narray([-0.58509755, 0.\n, 3.12039086, 3.22470745]),\n, 3.09818066, 3.19766659]),\n, 3.05891014, 3.1747754 ]),\n, 3.03697755, 3.14715043]),\n, 3.02056866, 3.11785887]),\n,\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:03:58,714 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28763, Requested 2299. Please try again in 2.124s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:03:58,716 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "]:\nax = plt.gca()\nax.plot(C_l, coef_l)\nax.set_xlim(ax.get_xlim()[::-1])\nplt.xlabel('C')\nplt.ylabel('weights')\nOut[68]:\nText(0, 0.5, 'weights')\n\nIn [67]:\ncoef_l\n\nOut[67]:\n[array([-1.12493251, -0.96058774, 3.23208646, 4.18486998]),\narray([-1.10210628, -0.91621566, 3.23983307, 4.15696154]),\narray([-1.09239629, -0.89555328, 3.23399288, 4.13377003]),\narray([-1.08811789, -0.88498435, 3.22207551, 4.11256892]),\narray([-1.06705294, -0.84236856, 3.2289702 , 4.08417288]),\narray([-1.05818676, -0.82271916, 3.22212123, 4.06049626]),\narray([-1.04514314, -0.79483425, 3.22012176, 4.034832 ]),\narray([-1.03859953, -0.77953758, 3.21025372, 4.01174608]),\narray([-1.02237904, -0.74473771, 3.21227469, 3.98396209]),\narray([-1.01620836, -0.73001684, 3.20160007, 3.96062442]),\narray([-0.99903143, -0.69243737, 3.20521982, 3.9315887 ]),\narray([-0.98882191, -0.66904752, 3.19966674, 3.90573051]),\narray([-0.97415883, -0.63587402, 3.2003062 , 3.87718618]),\narray([-0.96452518, -0.61330431, 3.19380232, 3.8510462 ]),\narray([-0.95257941, -0.58551283, 3.19060737, 3.8232743 ]),\narray([-0.9405302 , -0.55717711, 3.18755498, 3.79513594]),\narray([-0.92797551, -0.52743767, 3.18526488, 3.76634082]),\narray([-0.92072072, -0.50938749, 3.17475278, 3.74036246]),\narray([-0.90510269, -0.47211112, 3.17719028, 3.70899839]),\narray([-0.89009202, -0.43569901, 3.1788934 , 3.67756566]),\narray([-0.87766924, -0.4050523 , 3.17640578, 3.64738615]),\narray([-0.87286899, -0.39228757, 3.16090415, 3.62179933]),\narray([-0.85425355, -0.34619248, 3.16885758, 3.58676224]),\narray([-0.84887206, -0.33207553, 3.15364443, 3.56032998]),\narray([-0.83147761, -0.28802875, 3.15964514, 3.52515956]),\narray([-0.81352053, -0.24176251, 3.16723112, 3.4889317 ]),\narray([-0.80378813, -0.21608039, 3.15931029, 3.45833305]),\narray([-0.7917758 , -0.1843569 , 3.15554737, 3.42568574]),\narray([-0.7759623 , -0.14232637, 3.15919161, 3.38962502]),\narray([-0.76332702, -0.10825391, 3.15647641, 3.35556836]),\narray([-0.74997069, -0.07184156, 3.15520495, 3.32047552]),\narray([-0.73849732, -0.04031354, 3.14976963, 3.28653383]),\narray([-0.72392909, 0.\n, 3.15076775, 3.24952256]),\narray([-0.72367263, 0.\narray([-0.71773131, 0.\narray([-0.72374493, 0.\narray([-0.7173857 , 0.\narray([-0.70523493, 0.\narray([-0.69782327, 0.\narray([-0.69307433, 0.\narray([-0.65156996, 0.\narray([-0.61274879, 0.\narray([-0.58509755, 0.\n, 3.12039086, 3.22470745]),\n, 3.09818066, 3.19766659]),\n, 3.05891014, 3.1747754 ]),\n, 3.03697755, 3.14715043]),\n, 3.02056866, 3.11785887]),\n,"}
11:03:59,65 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,66 openai._base_client INFO Retrying request to /chat/completions in 2.824000 seconds
11:03:59,161 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,165 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \nID3ID3C4.5\nC4.5\nID3\nC4.5\nID3C4.5ID3\ninformation value\nID3\n\nCART\nC4.5\nC4.5\n\ninformation value\nC4.5IV\nIVIV\nK\nInformation Value = \n\ni=1\nP(vi)log2P(vi)\n\nIV\n\nIV\nK  \nIV\nvi\nIn [28]:\nOut[28]:\nIn [31]:\nOut[31]:\nIn [32]:\nOut[32]:\n# 50%-50%\n- (1/2 * np.log2(1/2) + 1/2 * np.log2(1/2))\n1.0\n# 1/4-1/2-1/4\n- (1/4 * np.log2(1/4) + 1/2 * np.log2(1/2)+ 1/4 * np.log2(1/4))\n1.5\n# 1/4-1/4-1/4-1/4\n- (1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 * np.log2(\n2.0\nID3C4.5IV\nGain Ratio\nGR\nGain Ratio =\nInformation Gain\nInformation Value\nC4.5GRGR\nageInformation Gain\nIn [37]:\nOut[37]:\nIG = ent_A - ent_B\nIG\n0.24674981977443922\n1\nP(vi)\nIV\nIn [36]:\nOut[36]:\nIV = - (\n######################\nOutput:', 'kwargs': {}}
11:03:59,165 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28517, Requested 2377. Please try again in 1.788s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:03:59,168 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '\nID3ID3C4.5\nC4.5\nID3\nC4.5\nID3C4.5ID3\ninformation value\nID3\n\nCART\nC4.5\nC4.5\n\ninformation value\nC4.5IV\nIVIV\nK\nInformation Value = \n\ni=1\nP(vi)log2P(vi)\n\nIV\n\nIV\nK  \nIV\nvi\nIn [28]:\nOut[28]:\nIn [31]:\nOut[31]:\nIn [32]:\nOut[32]:\n# 50%-50%\n- (1/2 * np.log2(1/2) + 1/2 * np.log2(1/2))\n1.0\n# 1/4-1/2-1/4\n- (1/4 * np.log2(1/4) + 1/2 * np.log2(1/2)+ 1/4 * np.log2(1/4))\n1.5\n# 1/4-1/4-1/4-1/4\n- (1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 * np.log2(\n2.0\nID3C4.5IV\nGain Ratio\nGR\nGain Ratio =\nInformation Gain\nInformation Value\nC4.5GRGR\nageInformation Gain\nIn [37]:\nOut[37]:\nIG = ent_A - ent_B\nIG\n0.24674981977443922\n1\nP(vi)\nIV\nIn [36]:\nOut[36]:\nIV = - ('}
11:03:59,359 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,360 openai._base_client INFO Retrying request to /chat/completions in 2.586000 seconds
11:03:59,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,436 openai._base_client INFO Retrying request to /chat/completions in 2.396000 seconds
11:03:59,526 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,529 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\nIn [11]:\nIn [12]:\nOut[12]:\n# 34\nd = np.array(iris.data.iloc[:, 2: 4])\nplt.scatter(d[:, 0], d[:, 1], c=t)\nplt.plot(np.array([2.5]*25), np.arange(0, 2.5, 0.1), \'r--\')\n[<matplotlib.lines.Line2D at 0x7ffb7881bd30>]\n3.0\n3.2\n3.1\n3.6\n...\n3.0\n2.5\n3.0\n3.4\n3.0\n1.4\n1.4\n1.3\n1.5\n1.4\n...\n5.2\n5.0\n5.2\n5.4\n5.1\n0.2\n0.2\n0.2\n0.2\n0.2\n...\n2.3\n1.9\n2.0\n2.3\n1.8\n\n\n\npetal length (cm) <=\n2.5\n\n1\n\n\n\nl1\n0l1\nIris\n\nIn [13]:\n# \nX = np.array(iris.data)[t == 1]\ny = np.array(iris.target)[t == 1]\nl1C\n\nIn [60]:\nIn [61]:\nC_l = np.linspace(1, 0.1, 100)\ncoef_l = []\nfor C in C_l:\nclf = LogisticRegression(penalty=\'l1\', C=C, max_iter=int(1e6), solver=\'saga\'\ncoef_l.append(clf.coef_.flatten())\nIn [68]:\nax = plt.gca()\nax.plot(C_l, coef_l)\nax.set_xlim(ax.get_xlim()[::-1])\nplt.xlabel(\'C\')\nplt.ylabel(\'weights\')\nOut[68]:\nText(0, 0.5, \'weights\')\n\nIn [67]:\ncoef_l\n\nOut[67]:\n[array([-1.12493251, -0.96058774, 3.23208646, 4.18486998]),\narray([-1.10210628, -0\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:03:59,529 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28043, Requested 2349. Please try again in 784ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:03:59,532 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\nIn [11]:\nIn [12]:\nOut[12]:\n# 34\nd = np.array(iris.data.iloc[:, 2: 4])\nplt.scatter(d[:, 0], d[:, 1], c=t)\nplt.plot(np.array([2.5]*25), np.arange(0, 2.5, 0.1), 'r--')\n[<matplotlib.lines.Line2D at 0x7ffb7881bd30>]\n3.0\n3.2\n3.1\n3.6\n...\n3.0\n2.5\n3.0\n3.4\n3.0\n1.4\n1.4\n1.3\n1.5\n1.4\n...\n5.2\n5.0\n5.2\n5.4\n5.1\n0.2\n0.2\n0.2\n0.2\n0.2\n...\n2.3\n1.9\n2.0\n2.3\n1.8\n\n\n\npetal length (cm) <=\n2.5\n\n1\n\n\n\nl1\n0l1\nIris\n\nIn [13]:\n# \nX = np.array(iris.data)[t == 1]\ny = np.array(iris.target)[t == 1]\nl1C\n\nIn [60]:\nIn [61]:\nC_l = np.linspace(1, 0.1, 100)\ncoef_l = []\nfor C in C_l:\nclf = LogisticRegression(penalty='l1', C=C, max_iter=int(1e6), solver='saga'\ncoef_l.append(clf.coef_.flatten())\nIn [68]:\nax = plt.gca()\nax.plot(C_l, coef_l)\nax.set_xlim(ax.get_xlim()[::-1])\nplt.xlabel('C')\nplt.ylabel('weights')\nOut[68]:\nText(0, 0.5, 'weights')\n\nIn [67]:\ncoef_l\n\nOut[67]:\n[array([-1.12493251, -0.96058774, 3.23208646, 4.18486998]),\narray([-1.10210628, -0"}
11:03:59,539 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,540 openai._base_client INFO Retrying request to /chat/completions in 2.036000 seconds
11:03:59,737 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,738 openai._base_client INFO Retrying request to /chat/completions in 1.866000 seconds
11:03:59,888 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:03:59,889 openai._base_client INFO Retrying request to /chat/completions in 1.180000 seconds
11:04:00,575 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:00,577 openai._base_client INFO Retrying request to /chat/completions in 1.024000 seconds
11:04:00,766 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:00,767 openai._base_client INFO Retrying request to /chat/completions in 1.574000 seconds
11:04:00,810 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:00,810 openai._base_client INFO Retrying request to /chat/completions in 0.680000 seconds
11:04:01,100 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,102 openai._base_client INFO Retrying request to /chat/completions in 0.500000 seconds
11:04:01,245 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,248 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 0.\narray([-0.61274879, 0.\narray([-0.58509755, 0.\n, 3.12039086, 3.22470745]),\n, 3.09818066, 3.19766659]),\n, 3.05891014, 3.1747754 ]),\n, 3.03697755, 3.14715043]),\n, 3.02056866, 3.11785887]),\n, 2.99732931, 3.0900815 ]),\n, 2.97080741, 3.06291264]),\n, 2.97634178, 3.02961721]),\n, 2.97513264, 3.00012166]),\n, 2.96319451, 2.97216583]),\narray([-6.00820243e-01, -3.14038921e-06, 2.91819194e+00, 2.94447850e+00]),\narray([-0.54776078, 0.\n, 2.92305106, 2.91616177]),\narray([-0.49669547, 0.\narray([-0.46034651, 0.\narray([-0.43924183, 0.\narray([-0.42114809, 0.\narray([-0.37710231, 0.\narray([-0.36078815, 0.\narray([-0.32730807, 0.\narray([-0.29040147, 0.\narray([-0.26100188, 0.\narray([-0.23403905, 0.\narray([-0.19633863, 0.\narray([-0.17791327, 0.\narray([-0.12625897, 0.\narray([-0.09535538, 0.\narray([-0.05649025, 0.\n, 2.92482248, 2.88916594]),\n, 2.91500936, 2.8615579 ]),\n, 2.89357789, 2.8326846 ]),\n, 2.86936609, 2.80318528]),\n, 2.86234066, 2.77473542]),\n, 2.83524682, 2.74417042]),\n, 2.81919184, 2.7140471 ]),\n, 2.80460709, 2.68351837]),\n, 2.78395265, 2.6519696 ]),\n, 2.76072855, 2.61970054]),\n, 2.74382518, 2.58723019]),\n, 2.71294983, 2.55340083]),\n, 2.70333197, 2.51992837]),\n, 2.67864753, 2.48510602]),\n, 2.65815739, 2.44967008]),\n\narray([-0.01584183, 0.\narray([0.\n, 0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 2.63763392, 2.41346342]),\n, 2.5995733 , 2.37634385]),\n, 2.90224674, 2.23453556]),\n, 2.90064745, 2.1756571 ]),\n, 2.88959628, 2.11967691]),\n, 2.8984936 , 2.05314704]),\n, 2.89326238, 1.99161195]),\n, 2.89341202, 1.92595881]),\n, 2.89113194, 1.85983192]),\n, 2.88973273, 1.79155147]),\n, 2.8825456 , 1.72445091]),\n, 2.88019419, 1.65301627]),\n, 2.88195891, 1.57737666]),\n, 2.88257639, 1.50019671]),\n, 2.87738246, 1.42399342]),\n, 2.87838348, 1.34196882]),\n, 2.878\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': 'The provided text does not contain any identifiable entities or relationships as per the given instructions. The text appears to be a series of numerical arrays, likely data points or outputs from a computational process, rather than descriptive or narrative content from which entities and relationships can be extracted. Therefore, no entities or relationships can be identified or described based on the given criteria.\n\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:01,248 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29955, Requested 2356. Please try again in 4.622s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:01,250 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '0.\narray([-0.61274879, 0.\narray([-0.58509755, 0.\n, 3.12039086, 3.22470745]),\n, 3.09818066, 3.19766659]),\n, 3.05891014, 3.1747754 ]),\n, 3.03697755, 3.14715043]),\n, 3.02056866, 3.11785887]),\n, 2.99732931, 3.0900815 ]),\n, 2.97080741, 3.06291264]),\n, 2.97634178, 3.02961721]),\n, 2.97513264, 3.00012166]),\n, 2.96319451, 2.97216583]),\narray([-6.00820243e-01, -3.14038921e-06, 2.91819194e+00, 2.94447850e+00]),\narray([-0.54776078, 0.\n, 2.92305106, 2.91616177]),\narray([-0.49669547, 0.\narray([-0.46034651, 0.\narray([-0.43924183, 0.\narray([-0.42114809, 0.\narray([-0.37710231, 0.\narray([-0.36078815, 0.\narray([-0.32730807, 0.\narray([-0.29040147, 0.\narray([-0.26100188, 0.\narray([-0.23403905, 0.\narray([-0.19633863, 0.\narray([-0.17791327, 0.\narray([-0.12625897, 0.\narray([-0.09535538, 0.\narray([-0.05649025, 0.\n, 2.92482248, 2.88916594]),\n, 2.91500936, 2.8615579 ]),\n, 2.89357789, 2.8326846 ]),\n, 2.86936609, 2.80318528]),\n, 2.86234066, 2.77473542]),\n, 2.83524682, 2.74417042]),\n, 2.81919184, 2.7140471 ]),\n, 2.80460709, 2.68351837]),\n, 2.78395265, 2.6519696 ]),\n, 2.76072855, 2.61970054]),\n, 2.74382518, 2.58723019]),\n, 2.71294983, 2.55340083]),\n, 2.70333197, 2.51992837]),\n, 2.67864753, 2.48510602]),\n, 2.65815739, 2.44967008]),\n\narray([-0.01584183, 0.\narray([0.\n, 0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\narray([0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 0.\n, 2.63763392, 2.41346342]),\n, 2.5995733 , 2.37634385]),\n, 2.90224674, 2.23453556]),\n, 2.90064745, 2.1756571 ]),\n, 2.88959628, 2.11967691]),\n, 2.8984936 , 2.05314704]),\n, 2.89326238, 1.99161195]),\n, 2.89341202, 1.92595881]),\n, 2.89113194, 1.85983192]),\n, 2.88973273, 1.79155147]),\n, 2.8825456 , 1.72445091]),\n, 2.88019419, 1.65301627]),\n, 2.88195891, 1.57737666]),\n, 2.88257639, 1.50019671]),\n, 2.87738246, 1.42399342]),\n, 2.87838348, 1.34196882]),\n, 2.878'}
11:04:01,448 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,450 openai._base_client INFO Retrying request to /chat/completions in 5.022000 seconds
11:04:01,622 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,623 openai._base_client INFO Retrying request to /chat/completions in 4.744000 seconds
11:04:01,624 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,625 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,626 openai._base_client INFO Retrying request to /chat/completions in 4.748000 seconds
11:04:01,626 openai._base_client INFO Retrying request to /chat/completions in 3.436000 seconds
11:04:01,655 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,656 openai._base_client INFO Retrying request to /chat/completions in 4.870000 seconds
11:04:01,670 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,671 openai._base_client INFO Retrying request to /chat/completions in 4.888000 seconds
11:04:01,683 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,683 openai._base_client INFO Retrying request to /chat/completions in 4.896000 seconds
11:04:01,692 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,694 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \n\nx=b100%\npetal length (cm) <= 4.879\n93%\n\n1\n\n\nIn [89]:\nOut[89]:\n1-(y != y_pred).sum() / 150\n0.9533333333333334\n\n\n\n\n\n\n\n\npetal length (cm) <= 2.5\npetal length (cm) <= 4.879\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n######################\nOutput:', 'kwargs': {}}
11:04:01,695 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 30000, Requested 2451. Please try again in 4.902s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:01,697 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '\n\nx=b100%\npetal length (cm) <= 4.879\n93%\n\n1\n\n\nIn [89]:\nOut[89]:\n1-(y != y_pred).sum() / 150\n0.9533333333333334\n\n\n\n\n\n\n\n\npetal length (cm) <= 2.5\npetal length (cm) <= 4.879\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n'}
11:04:01,798 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,800 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: T|\nR(T) = R(T) + | T|\nR(T)\n \n\n\n\n\nmax_depth\nmax_leaf_nodes\nmin_samples_splitmin_samples_leaf\nmin_impurity_split\nmin_impurity_decrease\n\n\n\n\n\n\nsklearn\n\nimpurity_decrease\n1\n\nimpurity_decrease\n\n\n\nsplitterrandom\nmax_features\n\n\n\n\n\n\n\n\n\n\n\n\nLesson 8.3 ID3C4.5\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:01,801 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 30000, Requested 2511. Please try again in 5.022s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:01,804 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'T|\nR(T) = R(T) + | T|\nR(T)\n \n\n\n\n\nmax_depth\nmax_leaf_nodes\nmin_samples_splitmin_samples_leaf\nmin_impurity_split\nmin_impurity_decrease\n\n\n\n\n\n\nsklearn\n\nimpurity_decrease\n1\n\nimpurity_decrease\n\n\n\nsplitterrandom\nmax_features\n\n\n\n\n\n\n\n\n\n\n\n\nLesson 8.3 ID3C4.5'}
11:04:01,835 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:01,836 openai._base_client INFO Retrying request to /chat/completions in 5.304000 seconds
11:04:01,993 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:02,152 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,152 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:04:02,172 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,173 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:04:02,187 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,188 openai._base_client INFO Retrying request to /chat/completions in 5.632000 seconds
11:04:02,198 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,200 openai._base_client INFO Retrying request to /chat/completions in 5.372000 seconds
11:04:02,205 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,208 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Lesson 8.1 \n\n\n\n\n\n\n\n\n\n \n\n\n\n\nIn [1]:\n# \nimport numpy as np\nimport pandas as pd\n# \nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n# \nfrom ML_basic_function import *\n# Scikit-Learn\n# \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\n# \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n# \nfrom sklearn.datasets import load_iris\nLesson 6.5\n\nIn [2]:\n# \nX, y = load_iris(return_X_y=True)\n\nIn [3]:\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=24)\n# \n# \nclf = LogisticRegression(max_iter=int(1e6), solver=\'saga\')\n# \nparam_grid_simple = {\'penalty\': [\'l1\', \'l2\'],\n\'C\': [1, 0.5, 0.1, 0.05, 0.01]}\n# \nsearch = GridSearchCV(estimator=clf,\nparam_grid=param_grid_simple)\n# \nsearch.fit(X_train, y_train)\nOut[3]:\nGridSearchCV(estimator=LogisticRegression(max_iter=1000000, solver=\'saga\'),\nparam_grid={\'C\': [1, 0.5, 0.1, 0.05, 0.01],\n\'penalty\': [\'l1\', \'l2\']})\nIn [4]:\nOut[4]:\nIn [5]:\nOut[5]:\nsearch.best_params_\n{\'C\': 1, \'penalty\': \'l1\'}\nsearch.best_estimator_.coef_\narray([[ 0.\n, 0.\n[ 0.\n, 0.\n, -3.47337669, 0.\n, 0.\n, 0.\n],\n],\n[-0.55511761, -0.34237661, 3.03227709, 4.12148646]])\nIn [6]:\nOut[6]:\nsearch.best_estimator_.intercept_\narray([ 11.85884734, 2.65291107, -14.51175841])\n{\'C\': 1, \'penalty\': \'l1\'}\n\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>LOGISTIC REGRESSION<|>ORGANIZATION<|>A machine learning model used for classification tasks, which was applied to the iris dataset in the text)\n##\n("entity"<|>GRIDSEARCHCV<|>ORGANIZATION<|>A tool from Scikit-Learn used for hyperparameter optimization, applied to Logistic Regression in the text)\n##\n("entity"<|>IRIS DATASET<|>ORGANIZATION<|>A well-known dataset used for machine learning tasks, specifically for multi-class classification in the text)\n##\n("relationship"<|>LOGISTIC REGRESSION<|>IRIS DATASET<|>Logistic Regression was applied to the Iris dataset for multi-class classification<|>9)\n##\n("relationship"<|>GRIDSEARCHCV<|>LOGISTIC REGRESSION<|>GridSearchCV was used to find the best hyperparameters for Logistic Regression<|>8)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:02,209 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 30000, Requested 2702. Please try again in 5.404s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:02,212 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Lesson 8.1 \n\n\n\n\n\n\n\n\n\n \n\n\n\n\nIn [1]:\n# \nimport numpy as np\nimport pandas as pd\n# \nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n# \nfrom ML_basic_function import *\n# Scikit-Learn\n# \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\n# \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n# \nfrom sklearn.datasets import load_iris\nLesson 6.5\n\nIn [2]:\n# \nX, y = load_iris(return_X_y=True)\n\nIn [3]:\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=24)\n# \n# \nclf = LogisticRegression(max_iter=int(1e6), solver='saga')\n# \nparam_grid_simple = {'penalty': ['l1', 'l2'],\n'C': [1, 0.5, 0.1, 0.05, 0.01]}\n# \nsearch = GridSearchCV(estimator=clf,\nparam_grid=param_grid_simple)\n# \nsearch.fit(X_train, y_train)\nOut[3]:\nGridSearchCV(estimator=LogisticRegression(max_iter=1000000, solver='saga'),\nparam_grid={'C': [1, 0.5, 0.1, 0.05, 0.01],\n'penalty': ['l1', 'l2']})\nIn [4]:\nOut[4]:\nIn [5]:\nOut[5]:\nsearch.best_params_\n{'C': 1, 'penalty': 'l1'}\nsearch.best_estimator_.coef_\narray([[ 0.\n, 0.\n[ 0.\n, 0.\n, -3.47337669, 0.\n, 0.\n, 0.\n],\n],\n[-0.55511761, -0.34237661, 3.03227709, 4.12148646]])\nIn [6]:\nOut[6]:\nsearch.best_estimator_.intercept_\narray([ 11.85884734, 2.65291107, -14.51175841])\n{'C': 1, 'penalty': 'l1'}\n"}
11:04:02,220 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,221 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:04:02,221 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,222 openai._base_client INFO Retrying request to /chat/completions in 5.350000 seconds
11:04:02,232 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,233 openai._base_client INFO Retrying request to /chat/completions in 5.684000 seconds
11:04:02,252 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,253 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:04:02,290 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,291 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:04:02,338 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,339 openai._base_client INFO Retrying request to /chat/completions in 5.780000 seconds
11:04:02,370 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,371 openai._base_client INFO Retrying request to /chat/completions in 5.066000 seconds
11:04:02,521 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,523 openai._base_client INFO Retrying request to /chat/completions in 5.978000 seconds
11:04:02,712 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:02,714 openai._base_client INFO Retrying request to /chat/completions in 6.112000 seconds
11:04:05,399 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:05,401 openai._base_client INFO Retrying request to /chat/completions in 3.436000 seconds
11:04:06,725 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:06,727 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:06,728 openai._base_client INFO Retrying request to /chat/completions in 4.748000 seconds
11:04:06,729 openai._base_client INFO Retrying request to /chat/completions in 4.744000 seconds
11:04:06,872 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:06,874 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:06,877 openai._base_client INFO Retrying request to /chat/completions in 4.562000 seconds
11:04:06,878 openai._base_client INFO Retrying request to /chat/completions in 4.356000 seconds
11:04:06,899 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:06,902 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Out[6]:\nsearch.best_estimator_.intercept_\narray([ 11.85884734, 2.65291107, -14.51175841])\n{\'C\': 1, \'penalty\': \'l1\'}\n\n0\n0\n\n\n\n\n\nIn [7]:\nIn [8]:\n\niris = load_iris(as_frame=True)\niris.data\n\nOut[8]:\n0\n1\n2\n3\n4\n...\n145\n146\n147\n148\n149\nsepal length (cm) sepal width (cm) petal length (cm) petal width (cm)\n5.1\n3.5\n4.9\n4.7\n4.6\n5.0\n...\n6.7\n6.3\n6.5\n6.2\n5.9\n150 rows  4 columns\nIn [9]:\nOut[9]:\nt = np.array(iris.target)\nt[50:]\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\nIn [10]:\n# 23\nt[50:] = 1\nt\nOut[10]:\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>IRIS DATASET<|>ORGANIZATION<|>A dataset used for a machine learning model to classify iris flowers into three species based on sepal length, sepal width, petal length, and petal width)\n##\n("entity"<|>LOGISTIC REGRESSION MODEL<|>ORGANIZATION<|>A model used to classify iris flowers into species based on features such as sepal length, sepal width, petal length, and petal width. It includes three equations for the classification)\n##\n("entity"<|>IRIS FLOWER SPECIES<|>EVENT<|>The classification target of the logistic regression model, aiming to distinguish among three different species of iris flowers)\n##\n("relationship"<|>LOGISTIC REGRESSION MODEL<|>IRIS DATASET<|>The logistic regression model is trained using the Iris dataset to classify iris flowers into species<|>9)\n##\n("relationship"<|>IRIS FLOWER SPECIES<|>IRIS DATASET<|>The Iris dataset contains data points for different iris flower species used for classification<|>8)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:06,902 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 30000, Requested 2444. Please try again in 4.888s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:06,907 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "Out[6]:\nsearch.best_estimator_.intercept_\narray([ 11.85884734, 2.65291107, -14.51175841])\n{'C': 1, 'penalty': 'l1'}\n\n0\n0\n\n\n\n\n\nIn [7]:\nIn [8]:\n\niris = load_iris(as_frame=True)\niris.data\n\nOut[8]:\n0\n1\n2\n3\n4\n...\n145\n146\n147\n148\n149\nsepal length (cm) sepal width (cm) petal length (cm) petal width (cm)\n5.1\n3.5\n4.9\n4.7\n4.6\n5.0\n...\n6.7\n6.3\n6.5\n6.2\n5.9\n150 rows  4 columns\nIn [9]:\nOut[9]:\nt = np.array(iris.target)\nt[50:]\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\nIn [10]:\n# 23\nt[50:] = 1\nt\nOut[10]:\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,"}
11:04:06,928 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:06,929 openai._base_client INFO Retrying request to /chat/completions in 4.896000 seconds
11:04:07,486 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:07,490 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \n\n\n\n\n\n\n\n\n2.CART\n\n\n\n\n0\n\n\n\n\n\nC4.5CARTC4.5\n\nCART\n\n\n\n\n\n\nsklearn\n\nsklearn 0.22CART\n\nCARTScikit-Learn\n\n1.CART\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>CART<|>ORGANIZATION<|>CART)\n##\n("entity"<|>C4.5<|>ORGANIZATION<|>C4.5)\n##\n("entity"<|>SKLEARN<|>ORGANIZATION<|>SklearnPython)\n##\n("relationship"<|>CART<|>SKLEARN<|>SklearnCART<|>8)\n##\n("relationship"<|>C4.5<|>CART<|>C4.5CART<|>5)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:07,490 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29744, Requested 2652. Please try again in 4.792s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:07,492 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '\n\n\n\n\n\n\n\n\n2.CART\n\n\n\n\n0\n\n\n\n\n\nC4.5CARTC4.5\n\nCART\n\n\n\n\n\n\nsklearn\n\nsklearn 0.22CART\n\nCARTScikit-Learn\n\n1.CART'}
11:04:07,788 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:07,789 openai._base_client INFO Retrying request to /chat/completions in 4.248000 seconds
11:04:07,913 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:07,916 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \n\n1.CART\nCART\n1.1 \n\n\n\n\n\npetal length (cm) <= 2.5\n100%\n\n100%0\n1\n\n\n1100%ABCD2100%AB\nCD\n\n\n\n01\n\n\n\n\n\n\n\n\n\n(1)Classification error\nClassification error(t) = 1  max[p(i|t)]\n1ic\niic i\n110\n60411-6/10 = 0.4\n[0, 0.5]\np(i|t)\n\n\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>CART<|>ORGANIZATION<|>CART)\n##\n("entity"<|><|>EVENT<|>)\n##\n("entity"<|><|>EVENT<|>)\n##\n("entity"<|><|>EVENT<|>)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:07,916 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29222, Requested 2675. Please try again in 3.794s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:07,919 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '\n\n1.CART\nCART\n1.1 \n\n\n\n\n\npetal length (cm) <= 2.5\n100%\n\n100%0\n1\n\n\n1100%ABCD2100%AB\nCD\n\n\n\n01\n\n\n\n\n\n\n\n\n\n(1)Classification error\nClassification error(t) = 1  max[p(i|t)]\n1ic\niic i\n110\n60411-6/10 = 0.4\n[0, 0.5]\np(i|t)\n\n'}
11:04:07,930 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:07,931 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: sklearn\n\nsklearn 0.22CART\n\nCARTScikit-Learn\n\n1.CARTsklearn\nIn [19]:\nScikit-Learnsklearn\nsklearn.tree\nfrom sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n\nIn [38]:\n# \nX = np.array([[1, 1], [2, 2], [2, 1], [1, 2], [1, 1], [1, 2], [1, 2], [2, 1]])\ny = np.array([0, 0, 0, 1, 0, 1, 1, 0])\nIn [39]:\nIn [40]:\nOut[40]:\n# \nclf = DecisionTreeClassifier().fit(X, y)\nclf.score(X, y)\n1.0\n\n\nsklearnsklearn.treeplot_tree\n\nplot_tree\nIn [41]:\n# tree\nfrom sklearn import tree\n\nIn [42]:\n# plot_tree\nplt.figure(figsize=(6, 2), dpi=150)\ntree.plot_tree(clf)\nOut[42]:\n[Text(279.0, 188.75, \'X[1] <= 1.5\\ngini = 0.469\\nsamples = 8\\nvalue = [5, 3]\'),\nText(139.5, 113.25, \'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]\'),\nText(418.5, 113.25, \'X[0] <= 1.5\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3]\'),\nText(279.0, 37.75, \'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]\'),\nText(558.0, 37.75, \'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]\')]\nplot_treesklearn\nsklearn\n\n\n\nsklearn\nsklearn\n\nsklearn\nIn [25]:\n2.CART\nDecisionTreeClassifier\nDecisionTreeClassifier?\n\nInit signature:\nDecisionTreeClassifier(\n*,\ncriterion=\'gini\',\nsplitter=\'best\',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_imp\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>DECISIONTREECLASSIFIER<|>ORGANIZATION<|>A classifier in sklearn.tree module for creating a decision tree for classification tasks)\n##\n("entity"<|>DECISIONTREEREGRESSOR<|>ORGANIZATION<|>A regressor in sklearn.tree module for creating a decision tree for regression tasks)\n##\n("entity"<|>SKLEARN.TREE<|>ORGANIZATION<|>Module in Scikit-Learn containing tools for decision tree models)\n##\n("entity"<|>PLOT_TREE<|>ORGANIZATION<|>Function in sklearn.tree module for visualizing decision trees)\n##\n("relationship"<|>DECISIONTREECLASSIFIER<|>SKLEARN.TREE<|>DecisionTreeClassifier is a part of the sklearn.tree module<|>9)\n##\n("relationship"<|>DECISIONTREEREGRESSOR<|>SKLEARN.TREE<|>DecisionTreeRegressor is a part of the sklearn.tree module<|>9)\n##\n("relationship"<|>PLOT_TREE<|>SKLEARN.TREE<|>plot_tree function is used for visualizing decision trees from the sklearn.tree module<|>9)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:07,931 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29517, Requested 2686. Please try again in 4.406s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:07,933 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "sklearn\n\nsklearn 0.22CART\n\nCARTScikit-Learn\n\n1.CARTsklearn\nIn [19]:\nScikit-Learnsklearn\nsklearn.tree\nfrom sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n\nIn [38]:\n# \nX = np.array([[1, 1], [2, 2], [2, 1], [1, 2], [1, 1], [1, 2], [1, 2], [2, 1]])\ny = np.array([0, 0, 0, 1, 0, 1, 1, 0])\nIn [39]:\nIn [40]:\nOut[40]:\n# \nclf = DecisionTreeClassifier().fit(X, y)\nclf.score(X, y)\n1.0\n\n\nsklearnsklearn.treeplot_tree\n\nplot_tree\nIn [41]:\n# tree\nfrom sklearn import tree\n\nIn [42]:\n# plot_tree\nplt.figure(figsize=(6, 2), dpi=150)\ntree.plot_tree(clf)\nOut[42]:\n[Text(279.0, 188.75, 'X[1] <= 1.5\\ngini = 0.469\\nsamples = 8\\nvalue = [5, 3]'),\nText(139.5, 113.25, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\nText(418.5, 113.25, 'X[0] <= 1.5\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\nText(279.0, 37.75, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\nText(558.0, 37.75, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]')]\nplot_treesklearn\nsklearn\n\n\n\nsklearn\nsklearn\n\nsklearn\nIn [25]:\n2.CART\nDecisionTreeClassifier\nDecisionTreeClassifier?\n\nInit signature:\nDecisionTreeClassifier(\n*,\ncriterion='gini',\nsplitter='best',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_imp"}
11:04:07,934 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:07,934 openai._base_client INFO Retrying request to /chat/completions in 4.408000 seconds
11:04:07,938 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:07,938 openai._base_client INFO Retrying request to /chat/completions in 4.470000 seconds
11:04:07,962 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:08,108 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:08,109 openai._base_client INFO Retrying request to /chat/completions in 5.566000 seconds
11:04:08,261 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:08,261 openai._base_client INFO Retrying request to /chat/completions in 5.462000 seconds
11:04:08,289 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:08,289 openai._base_client INFO Retrying request to /chat/completions in 5.644000 seconds
11:04:08,440 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:08,441 openai._base_client INFO Retrying request to /chat/completions in 5.684000 seconds
11:04:08,469 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:08,473 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \nDecisionTreeClassifier\nDecisionTreeClassifier?\n\nInit signature:\nDecisionTreeClassifier(\n*,\ncriterion=\'gini\',\nsplitter=\'best\',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_impurity_decrease=0.0,\nmin_impurity_split=None,\nclass_weight=None,\npresort=\'deprecated\',\nccp_alpha=0.0,\n)\nDocstring:\nA decision tree classifier.\nRead more in the :ref:`User Guide <tree>`.\nParameters\n---------\ncriterion : {"gini", "entropy"}, default="gini"\nThe function to measure the quality of a split. Supported criteria are\n"gini" for the Gini impurity and "entropy" for the information gain.\nsplitter : {"best", "random"}, default="best"\nThe strategy used to choose the split at each node. Supported\nstrategies are "best" to choose the best split and "random" to choose\nthe best random split.\nmax_depth : int, default=None\nThe maximum depth of the tree. If None, then nodes are expanded until\nall leaves are pure or until all leaves contain less than\nmin_samples_split samples.\nmin_samples_split : int or float, default=2\nThe minimum number of samples required to split an internal node:\n- If int, then consider `min_samples_split` as the minimum number.\n- If float, then `min_samples_split` is a fraction and\n`ceil(min_samples_split * n_samples)` are the minimum\nnumber of samples for each split.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_samples_leaf : int or float, default=1\nThe minimum number of samples required to be at a leaf node.\nA split point at any depth will only be considered if it leaves at\nleast ``min_samples_leaf`` training samples in each of the left and\nright branches. This may have the effect of smoothing the model,\nespecially in regression.\n- If int, then consider `min_samples_leaf` as the minimum number.\n- If float, then `min_samples_leaf` is a fraction and\n`ceil(min_samples_leaf * n_samples)` are the minimum\n\nnumber of samples for each node.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_weight_fraction_leaf : float, default=0.0\nThe minimum weighted fraction of the sum total of weights (of all\nthe input samples) required to be at a leaf node. Samples have\nequal weight when sample_weight is not provided.\nmax_features : int, float or {"auto", "sqrt", "log2"}, default=None\nThe number of features to consider when looking for the best split:\n- If int, then consider `max_features` features at each split.\n- If float, then `max_features` is a fraction and\n`int(max_features * n_features)` features are considered at each\nsplit.\n- If "auto", then `max_features=sqrt(n_features)`.\n- If "sqrt", then `max_features=sqrt(n_features)`.\n- If "log2", then `max_features=log2(n_features)`.\n- If None, then `max_features=n_features`.\nNote: the search for a split does not stop until at least one\nvalid partition of the node samples is found, even if it requires to\neffectively inspect more than ``max_features`` features.\nrandom_state : int, RandomState instance, default=None\nControls the randomness of the estimator. The features are always\nrandomly permuted at each split, even if ``splitter`` is set to\n``"best"``. When ``max_features < n_features``, the algorithm will\nselect ``max_features`` at random at each split before finding the best\nsplit among them. But the best found split may vary across different\nruns, even if ``max_features=n_features``. That is the case, if the\nimprovement of the criterion is identical for several splits and one\nsplit has to be selected at random. To obtain a deterministic behaviour\nduring fitting, ``random_state`` has to be fixed to an integer.\nSee :term:`Glossary <random_state>` for details.\nmax_leaf_nodes : int, default=None\nGrow a tree with ``max_leaf_nodes`` in best-first fashion.\nBest nodes are defined as relative reduction in impurity.\nIf None then unlimited number of leaf nodes.\nmin_impurity_decrease : float, default=0.0\nA node will be split if this split induces a decrease of the impurity\ngreater than or equal to this value.\nThe weighted impurity decrease equation is the following::\nN_t / N * (impurity - N_t_R / N_t * right_impurity\n- N_t_L / N_t * left_impurity)\nwhere ``N`` is the total number of samples, ``N_t`` is the number of\nsamples at the current node, ``N_t_L`` is the number of samples in the\nleft child, and ``N_t_R`` is the number of samples in the right child.\n``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\n\nmin_impurity_split : float, default=0\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:08,473 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 30000, Requested 2890. Please try again in 5.78s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:08,476 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '\nDecisionTreeClassifier\nDecisionTreeClassifier?\n\nInit signature:\nDecisionTreeClassifier(\n*,\ncriterion=\'gini\',\nsplitter=\'best\',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_impurity_decrease=0.0,\nmin_impurity_split=None,\nclass_weight=None,\npresort=\'deprecated\',\nccp_alpha=0.0,\n)\nDocstring:\nA decision tree classifier.\nRead more in the :ref:`User Guide <tree>`.\nParameters\n---------\ncriterion : {"gini", "entropy"}, default="gini"\nThe function to measure the quality of a split. Supported criteria are\n"gini" for the Gini impurity and "entropy" for the information gain.\nsplitter : {"best", "random"}, default="best"\nThe strategy used to choose the split at each node. Supported\nstrategies are "best" to choose the best split and "random" to choose\nthe best random split.\nmax_depth : int, default=None\nThe maximum depth of the tree. If None, then nodes are expanded until\nall leaves are pure or until all leaves contain less than\nmin_samples_split samples.\nmin_samples_split : int or float, default=2\nThe minimum number of samples required to split an internal node:\n- If int, then consider `min_samples_split` as the minimum number.\n- If float, then `min_samples_split` is a fraction and\n`ceil(min_samples_split * n_samples)` are the minimum\nnumber of samples for each split.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_samples_leaf : int or float, default=1\nThe minimum number of samples required to be at a leaf node.\nA split point at any depth will only be considered if it leaves at\nleast ``min_samples_leaf`` training samples in each of the left and\nright branches. This may have the effect of smoothing the model,\nespecially in regression.\n- If int, then consider `min_samples_leaf` as the minimum number.\n- If float, then `min_samples_leaf` is a fraction and\n`ceil(min_samples_leaf * n_samples)` are the minimum\n\nnumber of samples for each node.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_weight_fraction_leaf : float, default=0.0\nThe minimum weighted fraction of the sum total of weights (of all\nthe input samples) required to be at a leaf node. Samples have\nequal weight when sample_weight is not provided.\nmax_features : int, float or {"auto", "sqrt", "log2"}, default=None\nThe number of features to consider when looking for the best split:\n- If int, then consider `max_features` features at each split.\n- If float, then `max_features` is a fraction and\n`int(max_features * n_features)` features are considered at each\nsplit.\n- If "auto", then `max_features=sqrt(n_features)`.\n- If "sqrt", then `max_features=sqrt(n_features)`.\n- If "log2", then `max_features=log2(n_features)`.\n- If None, then `max_features=n_features`.\nNote: the search for a split does not stop until at least one\nvalid partition of the node samples is found, even if it requires to\neffectively inspect more than ``max_features`` features.\nrandom_state : int, RandomState instance, default=None\nControls the randomness of the estimator. The features are always\nrandomly permuted at each split, even if ``splitter`` is set to\n``"best"``. When ``max_features < n_features``, the algorithm will\nselect ``max_features`` at random at each split before finding the best\nsplit among them. But the best found split may vary across different\nruns, even if ``max_features=n_features``. That is the case, if the\nimprovement of the criterion is identical for several splits and one\nsplit has to be selected at random. To obtain a deterministic behaviour\nduring fitting, ``random_state`` has to be fixed to an integer.\nSee :term:`Glossary <random_state>` for details.\nmax_leaf_nodes : int, default=None\nGrow a tree with ``max_leaf_nodes`` in best-first fashion.\nBest nodes are defined as relative reduction in impurity.\nIf None then unlimited number of leaf nodes.\nmin_impurity_decrease : float, default=0.0\nA node will be split if this split induces a decrease of the impurity\ngreater than or equal to this value.\nThe weighted impurity decrease equation is the following::\nN_t / N * (impurity - N_t_R / N_t * right_impurity\n- N_t_L / N_t * left_impurity)\nwhere ``N`` is the total number of samples, ``N_t`` is the number of\nsamples at the current node, ``N_t_L`` is the number of samples in the\nleft child, and ``N_t_R`` is the number of samples in the right child.\n``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\n\nmin_impurity_split : float, default=0\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity'}
11:04:08,525 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:08,526 openai._base_client INFO Retrying request to /chat/completions in 5.652000 seconds
11:04:08,843 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:08,844 openai._base_client INFO Retrying request to /chat/completions in 5.836000 seconds
11:04:09,180 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:09,182 openai._base_client INFO Retrying request to /chat/completions in 5.018000 seconds
11:04:10,537 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:10,539 openai._base_client INFO Retrying request to /chat/completions in 1.724000 seconds
11:04:11,582 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:11,584 openai._base_client INFO Retrying request to /chat/completions in 1.988000 seconds
11:04:11,786 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:11,787 openai._base_client INFO Retrying request to /chat/completions in 1.938000 seconds
11:04:11,815 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:11,816 openai._base_client INFO Retrying request to /chat/completions in 1.636000 seconds
11:04:11,928 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:11,929 openai._base_client INFO Retrying request to /chat/completions in 1.518000 seconds
11:04:12,166 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:12,167 openai._base_client INFO Retrying request to /chat/completions in 1.432000 seconds
11:04:12,453 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:12,454 openai._base_client INFO Retrying request to /chat/completions in 0.700000 seconds
11:04:12,733 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:12,734 openai._base_client INFO Retrying request to /chat/completions in 0.760000 seconds
11:04:12,760 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:12,763 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \n\n\n\nLesson 8.3 ID3C4.5\nID3C4.5sklearn\nID3C4.5\nID3C4.5CART\nID3C4.5\nID3\nC4.5ID3\nIn [9]:\nimport numpy as np\nfrom ML_basic_function import *\nID3\nID3ID3\n\n\nageincomeage30\n40\n123\n1\n\nID3CART\nID3\nCARTCART\nCART\nID3\nage\n1\n\nage\nID3\n\nIn [10]:\n# A\nent_A = -5/14 * np.log2(5/14) - 9/14 * np.log2(9/14)\nent_A\nOut[10]:\n0.9402859586706311\n\nIn [16]:\n# B\nent_B1 = entropy(2/5)\nent_B2 = entropy(2/5)\nent_B3 = 0\nent_B1, ent_B2, ent_B3\nOut[16]:\n(0.9709505944546686, 0.9709505944546686, 0)\n\n\nIn [20]:\nOut[20]:\nent_B = ent_B1 * 5/14 + ent_B2 * 5/14 + ent_B\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>ID3<|>ORGANIZATION<|>ID3 is a decision tree model that focuses on classification problems around discrete variables and cannot handle continuous features or regression problems without discretizing continuous variables first)\n##\n("entity"<|>C4.5<|>ORGANIZATION<|>C4.5 improves upon ID3 by handling the limitations of ID3, both are classic decision tree algorithms)\n##\n("entity"<|>CART<|>ORGANIZATION<|>CART tree is a type of decision tree that looks for splitting points among all features to reduce dataset impurity, unlike ID3 which expands by columns)\n##\n("relationship"<|>ID3<|>C4.5<|>C4.5 is developed as an improvement over ID3, addressing its limitations<|>8)\n##\n("relationship"<|>ID3<|>CART<|>ID3\'s process of growing and dataset splitting is fundamentally similar to that of CART, but differs in the method of expansion<|>7)\n##\n("relationship"<|>C4.5<|>CART<|>C4.5 and CART share similarities in their basic modeling approach but differ in their specific methodologies and metrics used for dataset splitting<|>6)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:12,763 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 27988, Requested 2722. Please try again in 1.42s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:12,766 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '\n\n\n\nLesson 8.3 ID3C4.5\nID3C4.5sklearn\nID3C4.5\nID3C4.5CART\nID3C4.5\nID3\nC4.5ID3\nIn [9]:\nimport numpy as np\nfrom ML_basic_function import *\nID3\nID3ID3\n\n\nageincomeage30\n40\n123\n1\n\nID3CART\nID3\nCARTCART\nCART\nID3\nage\n1\n\nage\nID3\n\nIn [10]:\n# A\nent_A = -5/14 * np.log2(5/14) - 9/14 * np.log2(9/14)\nent_A\nOut[10]:\n0.9402859586706311\n\nIn [16]:\n# B\nent_B1 = entropy(2/5)\nent_B2 = entropy(2/5)\nent_B3 = 0\nent_B1, ent_B2, ent_B3\nOut[16]:\n(0.9709505944546686, 0.9709505944546686, 0)\n\n\nIn [20]:\nOut[20]:\nent_B = ent_B1 * 5/14 + ent_B2 * 5/14 + ent_B'}
11:04:13,513 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:13,513 openai._base_client INFO Retrying request to /chat/completions in 3.084000 seconds
11:04:13,790 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:13,791 openai._base_client INFO Retrying request to /chat/completions in 3.092000 seconds
11:04:13,802 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:13,803 openai._base_client INFO Retrying request to /chat/completions in 3.088000 seconds
11:04:13,937 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:13,938 openai._base_client INFO Retrying request to /chat/completions in 3.080000 seconds
11:04:14,246 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,248 openai._base_client INFO Retrying request to /chat/completions in 3.256000 seconds
11:04:14,249 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,252 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: GRGR\nageInformation Gain\nIn [37]:\nOut[37]:\nIG = ent_A - ent_B\nIG\n0.24674981977443922\n1\nP(vi)\nIV\nIn [36]:\nOut[36]:\nIV = - (5/14 * np.log2(5/14) + 5/14 * np.log2(5/14)+ 4/14 * np.log2(4/14))\nIV\n1.5774062828523454\nGR\nIn [38]:\nGR = IG / IV\nGR\n\nOut[38]:\n0.1564275624211752\nGRGR\nC4.5\nC4.5\nCART\nGR\n\nGR\nageGR\nGR(income)GR(student)GR(credit_rating)GR(age<=26.5)GR(age<=27.5)...\n1\nC4.5\n\nCART\nsklearnsklearn\nID3C4.5\nsklearnCART\nsklearnC4.5\n\nLesson 8.4 CART\nsklearn\nCART\nCART\nCART\nsklearn\nGBDT\nCART\nCART\n\nCARTCART\nCARTsklearn\nIn [2]:\n# \nimport numpy\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>C4.5<|>ORGANIZATION<|>C4.5 is a decision tree algorithm that allows for modeling with continuous variables, comparing GR values for dataset division based on rules for continuous and discrete variables)\n##\n("entity"<|>CART<|>ORGANIZATION<|>CART (Classification And Regression Trees) is a decision tree technique that can handle both classification and regression problems and is used as a basis for ensemble methods like GBDT)\n##\n("entity"<|>SKLEARN<|>ORGANIZATION<|>Sklearn is a machine learning library for Python, known for its decision tree implementation which does not support discrete variable modeling in the manner of ID3 or C4.5 but treats features in a continuous variable fashion)\n##\n("entity"<|>GBDT<|>ORGANIZATION<|>Gradient Boosting Decision Tree, an ensemble algorithm for which CART regression trees serve as the base classifier)\n##\n("relationship"<|>C4.5<|>CART<|>C4.5 and CART are both decision tree algorithms with different approaches to handling variables and dataset division<|>5)\n##\n("relationship"<|>CART<|>GBDT<|>CART regression trees are used as the base classifier in GBDT ensemble algorithms<|>8)\n##\n("relationship"<|>SKLEARN<|>CART<|>Sklearn implements CART tree modeling rules, focusing on continuous variable treatment<|>7)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:14,252 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28946, Requested 2783. Please try again in 3.458s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:14,256 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'GRGR\nageInformation Gain\nIn [37]:\nOut[37]:\nIG = ent_A - ent_B\nIG\n0.24674981977443922\n1\nP(vi)\nIV\nIn [36]:\nOut[36]:\nIV = - (5/14 * np.log2(5/14) + 5/14 * np.log2(5/14)+ 4/14 * np.log2(4/14))\nIV\n1.5774062828523454\nGR\nIn [38]:\nGR = IG / IV\nGR\n\nOut[38]:\n0.1564275624211752\nGRGR\nC4.5\nC4.5\nCART\nGR\n\nGR\nageGR\nGR(income)GR(student)GR(credit_rating)GR(age<=26.5)GR(age<=27.5)...\n1\nC4.5\n\nCART\nsklearnsklearn\nID3C4.5\nsklearnCART\nsklearnC4.5\n\nLesson 8.4 CART\nsklearn\nCART\nCART\nCART\nsklearn\nGBDT\nCART\nCART\n\nCARTCART\nCARTsklearn\nIn [2]:\n# \nimport numpy'}
11:04:14,275 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,278 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: matplotlib.lines.Line2D at 0x7fbeaafe80d0>,\n<matplotlib.lines.Line2D at 0x7fbeaafe8100>]\n\n\n\n\nA0-1\nincomecredit_rating\n\n1\n\nIn [10]:\np = 3/8\ngini_A = 1 - np.power([p, 1-p], 2).sum()\ngini_A\nOut[10]:\n0.46875\nincome <= 1.5\nB1B2:\n\n1\nIn [11]:\np = 2/5\ngini_B1 = 1 - np.power([p, 1-p], 2).sum()\ngini_B1\nOut[11]:\n0.48\nIn [12]:\nB2B20\ngini_B2 = 0\nB1B2gini_B1gini_B2\n\nGini(B) =\n  A  \n\n|Bi|\n|A|\nBi\nB1 B2\nIn [13]:\nOut[13]:\ngini_B = gini_B1 * 5/8 + gini_B2 * 3/8\ngini_B\n0.3\n\n\n\n1.2 \n\n\nCARTslearn\n\n\nA\nincomecredit_rating\n1\n|B1|\n|A|\nGini(B1) +\n|B2|\n|A|\nGini(B2)\n1\n\nincome121.5income\n<= 1.5income1\n\nincome2\n\nincome\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>GINI_A<|>EVENT<|>Calculation of the overall Gini coefficient for dataset A, indicating the purity of labels in the dataset)\n##\n("entity"<|>GINI_B1<|>EVENT<|>Gini coefficient for subset B1 after dataset A is divided based on a certain condition)\n##\n("entity"<|>GINI_B2<|>EVENT<|>Gini coefficient for subset B2, which contains only one label, thus having a Gini coefficient of 0)\n##\n("entity"<|>INCOME<|>ORGANIZATION<|>A feature in dataset A representing the income level, used to divide the dataset into subsets)\n##\n("entity"<|>CREDIT_RATING<|>ORGANIZATION<|>A feature in dataset A representing the credit rating level, used in the analysis of the dataset\'s purity)\n##\n("relationship"<|>GINI_A<|>INCOME<|>Gini_A\'s calculation involves the income feature as part of the dataset\'s attributes<|>5)\n##\n("relationship"<|>GINI_A<|>CREDIT_RATING<|>Gini_A\'s calculation involves the credit rating feature as part of the dataset\'s attributes<|>5)\n##\n("relationship"<|>GINI_B1<|>INCOME<|>Gini_B1\'s calculation is based on a condition set on the income feature<|>7)\n##\n("relationship"<|>GINI_B2<|>INCOME<|>Gini_B2\'s calculation is influenced by the division of the dataset using the income feature, even though it directly results in a Gini coefficient of 0<|>6)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:14,278 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28933, Requested 2822. Please try again in 3.51s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:14,279 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'matplotlib.lines.Line2D at 0x7fbeaafe80d0>,\n<matplotlib.lines.Line2D at 0x7fbeaafe8100>]\n\n\n\n\nA0-1\nincomecredit_rating\n\n1\n\nIn [10]:\np = 3/8\ngini_A = 1 - np.power([p, 1-p], 2).sum()\ngini_A\nOut[10]:\n0.46875\nincome <= 1.5\nB1B2:\n\n1\nIn [11]:\np = 2/5\ngini_B1 = 1 - np.power([p, 1-p], 2).sum()\ngini_B1\nOut[11]:\n0.48\nIn [12]:\nB2B20\ngini_B2 = 0\nB1B2gini_B1gini_B2\n\nGini(B) =\n  A  \n\n|Bi|\n|A|\nBi\nB1 B2\nIn [13]:\nOut[13]:\ngini_B = gini_B1 * 5/8 + gini_B2 * 3/8\ngini_B\n0.3\n\n\n\n1.2 \n\n\nCARTslearn\n\n\nA\nincomecredit_rating\n1\n|B1|\n|A|\nGini(B1) +\n|B2|\n|A|\nGini(B2)\n1\n\nincome121.5income\n<= 1.5income1\n\nincome2\n\nincome'}
11:04:14,302 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,302 openai._base_client INFO Retrying request to /chat/completions in 2.250000 seconds
11:04:14,312 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,314 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: , 0.9709505944546686, 0)\n\n\nIn [20]:\nOut[20]:\nent_B = ent_B1 * 5/14 + ent_B2 * 5/14 + ent_B3 * 4/14\nent_B\n0.6935361388961919\n\nIn [21]:\nOut[21]:\n# \nent_A - ent_B\n0.24674981977443922\nageinformation gain\nGain(age) = 0.247\nage\nage\nincomestudentcredit_rating\nage\nGain(income)=0.026Gain(student)=0.151Gain(credit_rating)=0.048\nageage\n\n1\nB1\nstudentB2\n\ncredit_rating100%\n\n1\nID3CART\nID3CARTID3\n\nCARTID3\nCART\nCART\nCARTID3CART\nID3ID3age\nCART<=30\n>40\nID3\nID3ID3\n\nID3ID3C4.5\nC4.5\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>ID3 DECISION TREE<|>ORGANIZATION<|>A model that grows by expanding a column at each step, leading to multiple branches based on the number of categories in the current column. It is designed for datasets with discrete variables and can lead to overfitting due to its preference for variables with more categories)\n##\n("entity"<|>CART TREE<|>ORGANIZATION<|>A model that grows as a binary tree, allowing for more refined rule extraction compared to ID3. It can handle both discrete and continuous variables and offers a broader set of rules for model growth)\n##\n("entity"<|>C4.5 ALGORITHM<|>ORGANIZATION<|>An improvement over the ID3 decision tree model, addressing its limitations by allowing for the handling of continuous variables and implementing measures to prevent overfitting)\n##\n("relationship"<|>ID3 DECISION TREE<|>CART TREE<|>ID3 and CART represent different approaches to decision tree modeling, with ID3 expanding one column at a time and CART growing as a binary tree<|>5)\n##\n("relationship"<|>ID3 DECISION TREE<|>C4.5 ALGORITHM<|>The C4.5 algorithm is an evolution of the ID3 decision tree, designed to overcome its limitations<|>8)\n##\n("relationship"<|>CART TREE<|>C4.5 ALGORITHM<|>Both CART and C4.5 offer solutions to the limitations of the ID3 model, with C4.5 directly addressing ID3\'s shortcomings<|>6)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:14,314 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28935, Requested 2816. Please try again in 3.502s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:14,316 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ', 0.9709505944546686, 0)\n\n\nIn [20]:\nOut[20]:\nent_B = ent_B1 * 5/14 + ent_B2 * 5/14 + ent_B3 * 4/14\nent_B\n0.6935361388961919\n\nIn [21]:\nOut[21]:\n# \nent_A - ent_B\n0.24674981977443922\nageinformation gain\nGain(age) = 0.247\nage\nage\nincomestudentcredit_rating\nage\nGain(income)=0.026Gain(student)=0.151Gain(credit_rating)=0.048\nageage\n\n1\nB1\nstudentB2\n\ncredit_rating100%\n\n1\nID3CART\nID3CARTID3\n\nCARTID3\nCART\nCART\nCARTID3CART\nID3ID3age\nCART<=30\n>40\nID3\nID3ID3\n\nID3ID3C4.5\nC4.5'}
11:04:14,364 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,365 openai._base_client INFO Retrying request to /chat/completions in 2.672000 seconds
11:04:14,537 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,538 openai._base_client INFO Retrying request to /chat/completions in 3.258000 seconds
11:04:14,569 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,572 openai._base_client INFO Retrying request to /chat/completions in 3.298000 seconds
11:04:14,915 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:14,948 openai._base_client INFO Retrying request to /chat/completions in 3.348000 seconds
11:04:15,81 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:15,83 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: ``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\n\nmin_impurity_split : float, default=0\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead.\nclass_weight : dict, list of dict or "balanced", default=None\nWeights associated with classes in the form ``{class_label: weight}``.\nIf None, all classes are supposed to have weight one. For\nmulti-output problems, a list of dicts can be provided in the same\norder as the columns of y.\nNote that for multioutput (including multilabel) weights should be\ndefined for each class of every column in its own dict. For example,\nfor four-class multilabel classification weights should be\n[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n[{1:1}, {2:5}, {3:1}, {4:1}].\nThe "balanced" mode uses the values of y to automatically adjust\nweights inversely proportional to class frequencies in the input data\nas ``n_samples / (n_classes * np.bincount(y))``\nFor multi-output, the weights of each column of y will be multiplied.\nNote that these weights will be multiplied with sample_weight (passed\nthrough the fit method) if sample_weight is specified.\npresort : deprecated, default=\'deprecated\'\nThis parameter is deprecated and will be removed in v0.24.\n.. deprecated:: 0.22\nccp_alpha : non-negative float, default=0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. The\nsubtree with the largest cost complexity that is smaller than\n``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n:ref:`minimal_cost_complexity_pruning` for details.\n.. versionadded:: 0.22\nAttributes\n---------\nclasses_ : ndarray of shape (n_classes,) or list of ndarray\nThe classes labels (single output problem),\nor a list of arrays of class labels (multi-output problem).\nfeature_importances_ : ndarray of shape (n_features,)\nThe impurity-based feature importances.\nThe higher, the more important the feature.\nThe importance of a feature is computed as the (normalized)\ntotal reduction of the criterion brought by that feature. It is also\nknown as the Gini importance [4]_.\nWarning: impurity-based feature importances can be misleading for\nhigh cardinality features (many unique values). See\n\n:func:`sklearn.inspection.permutation_importance` as an alternative.\nmax_features_ : int\nThe inferred value of max_features.\nn_classes_ : int or list of int\nThe number of classes (for single output problems),\nor a list containing the number of classes for each\noutput (for multi-output problems).\nn_features_ : int\nThe number of features when ``fit`` is performed.\nn_outputs_ : int\nThe number of outputs when ``fit`` is performed.\ntree_ : Tree\nThe underlying Tree object. Please refer to\n``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n:ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\nfor basic usage of these attributes.\nSee Also\n-------\nDecisionTreeRegressor : A decision tree regressor.\nNotes\n----\nThe default values for the parameters controlling the size of the trees\n(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\nunpruned trees which can potentially be very large on some data sets. To\nreduce memory consumption, the complexity and size of the trees should be\ncontrolled by setting those parameter values.\nReferences\n---------\n.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n.. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, "Classification\nand Regression Trees", Wadsworth, Belmont, CA, 1984.\n.. [3] T. Hastie, R. Tibshirani and J. Friedman. "Elements of Statistical\nLearning", Springer, 2009.\n.. [4] L. Breiman, and A. Cutler, "Random Forests",\nhttps://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\nExamples\n-------\n>>> from sklearn.datasets import load_iris\n>>> from sklearn.model_selection import cross_val_score\n>>> from sklearn.tree import DecisionTreeClassifier\n>>> clf = DecisionTreeClassifier(random_state=0)\n>>> iris = load_iris()\n>>> cross_val_score(clf, iris.data, iris.target, cv=10)\n...\n# doctest: +SKIP\n...\narray([ 1.\n, 0.93..., 0.86..., 0.93..., 0.93...,\n0.93..., 0.93..., 1.\n, 0.93..., 1.\n])\n\nFile:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\ns.py\nType:\nSubclasses:\nName\ncriterion\nsplitter\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>DECISIONTREECLASSIFIER<|>ORGANIZATION<|>A classifier with a decision tree model from the sklearn library, used for classifying data based on features)\n##\n("entity"<|>SKLEARN<|>ORGANIZATION<|>A machine learning library for the Python programming language)\n##\n("entity"<|>IRIS<|>ORGANIZATION<|>A dataset used for demonstrating the DecisionTreeClassifier in sklearn, consisting of data on iris flowers)\n##\n("relationship"<|>DECISIONTREECLASSIFIER<|>SKLEARN<|>DecisionTreeClassifier is a part of the sklearn library<|>9)\n##\n("relationship"<|>DECISIONTREECLASSIFIER<|>IRIS<|>DecisionTreeClassifier is demonstrated using the iris dataset in sklearn examples<|>5)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:15,83 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28223, Requested 2989. Please try again in 2.424s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:15,85 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\n\nmin_impurity_split : float, default=0\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead.\nclass_weight : dict, list of dict or "balanced", default=None\nWeights associated with classes in the form ``{class_label: weight}``.\nIf None, all classes are supposed to have weight one. For\nmulti-output problems, a list of dicts can be provided in the same\norder as the columns of y.\nNote that for multioutput (including multilabel) weights should be\ndefined for each class of every column in its own dict. For example,\nfor four-class multilabel classification weights should be\n[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n[{1:1}, {2:5}, {3:1}, {4:1}].\nThe "balanced" mode uses the values of y to automatically adjust\nweights inversely proportional to class frequencies in the input data\nas ``n_samples / (n_classes * np.bincount(y))``\nFor multi-output, the weights of each column of y will be multiplied.\nNote that these weights will be multiplied with sample_weight (passed\nthrough the fit method) if sample_weight is specified.\npresort : deprecated, default=\'deprecated\'\nThis parameter is deprecated and will be removed in v0.24.\n.. deprecated:: 0.22\nccp_alpha : non-negative float, default=0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. The\nsubtree with the largest cost complexity that is smaller than\n``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n:ref:`minimal_cost_complexity_pruning` for details.\n.. versionadded:: 0.22\nAttributes\n---------\nclasses_ : ndarray of shape (n_classes,) or list of ndarray\nThe classes labels (single output problem),\nor a list of arrays of class labels (multi-output problem).\nfeature_importances_ : ndarray of shape (n_features,)\nThe impurity-based feature importances.\nThe higher, the more important the feature.\nThe importance of a feature is computed as the (normalized)\ntotal reduction of the criterion brought by that feature. It is also\nknown as the Gini importance [4]_.\nWarning: impurity-based feature importances can be misleading for\nhigh cardinality features (many unique values). See\n\n:func:`sklearn.inspection.permutation_importance` as an alternative.\nmax_features_ : int\nThe inferred value of max_features.\nn_classes_ : int or list of int\nThe number of classes (for single output problems),\nor a list containing the number of classes for each\noutput (for multi-output problems).\nn_features_ : int\nThe number of features when ``fit`` is performed.\nn_outputs_ : int\nThe number of outputs when ``fit`` is performed.\ntree_ : Tree\nThe underlying Tree object. Please refer to\n``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n:ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\nfor basic usage of these attributes.\nSee Also\n-------\nDecisionTreeRegressor : A decision tree regressor.\nNotes\n----\nThe default values for the parameters controlling the size of the trees\n(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\nunpruned trees which can potentially be very large on some data sets. To\nreduce memory consumption, the complexity and size of the trees should be\ncontrolled by setting those parameter values.\nReferences\n---------\n.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n.. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, "Classification\nand Regression Trees", Wadsworth, Belmont, CA, 1984.\n.. [3] T. Hastie, R. Tibshirani and J. Friedman. "Elements of Statistical\nLearning", Springer, 2009.\n.. [4] L. Breiman, and A. Cutler, "Random Forests",\nhttps://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\nExamples\n-------\n>>> from sklearn.datasets import load_iris\n>>> from sklearn.model_selection import cross_val_score\n>>> from sklearn.tree import DecisionTreeClassifier\n>>> clf = DecisionTreeClassifier(random_state=0)\n>>> iris = load_iris()\n>>> cross_val_score(clf, iris.data, iris.target, cv=10)\n...\n# doctest: +SKIP\n...\narray([ 1.\n, 0.93..., 0.86..., 0.93..., 0.93...,\n0.93..., 0.93..., 1.\n, 0.93..., 1.\n])\n\nFile:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\ns.py\nType:\nSubclasses:\nName\ncriterion\nsplitter'}
11:04:16,939 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:16,941 openai._base_client INFO Retrying request to /chat/completions in 0.304000 seconds
11:04:17,246 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:17,249 openai._base_client INFO Retrying request to /chat/completions in 4.704000 seconds
11:04:17,355 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:17,358 openai._base_client INFO Retrying request to /chat/completions in 4.710000 seconds
11:04:17,393 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:17,394 openai._base_client INFO Retrying request to /chat/completions in 4.064000 seconds
11:04:17,394 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:17,395 openai._base_client INFO Retrying request to /chat/completions in 4.672000 seconds
11:04:17,590 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:17,591 openai._base_client INFO Retrying request to /chat/completions in 4.024000 seconds
11:04:17,877 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:17,878 openai._base_client INFO Retrying request to /chat/completions in 4.688000 seconds
11:04:18,208 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:18,210 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \nCARTCART\n\n\n\n\nCHAID\nCHAIDChi-square automatic interaction detectionKass1975\nCARTCHAID\nChi-square\n\nC4.5CARTCARTCHAID\nC4.5C4.5CART\nBottom-upPruning TechniqueCHAID\nTop-DownBonsai Technique\n\n\n\nCARTScikit-Learn\nID3C4.5sklearn\n\nID3C4.5\nLesson 8.2 CART\nsklearn\nCART\nCARTCART\nsklearn\nIn [1]:\n# \nimport numpy as np\nimport pandas as pd\n# \nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n# \nfrom ML_basic_function import *\n# Scikit-Learn\n# \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\n# \nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\n# \nfrom sklearn.datasets import load_iris\nCART\n\n\nCART\n\n1.CART\n\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>CART<|>ORGANIZATION<|>CART)\n##\n("entity"<|>CHAID<|>ORGANIZATION<|>CHAID)\n##\n("entity"<|>SCIKIT-LEARN<|>ORGANIZATION<|>Scikit-Learn)\n##\n("entity"<|>ID3<|>ORGANIZATION<|>ID3)\n##\n("entity"<|>C4.5<|>ORGANIZATION<|>C4.5ID3)\n##\n("relationship"<|>CART<|>SCIKIT-LEARN<|>CARTScikit-Learn<|>8)\n##\n("relationship"<|>CHAID<|>CART<|>CHAIDCART<|>5)\n##\n("relationship"<|>ID3<|>C4.5<|>C4.5ID3<|>9)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:18,210 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29497, Requested 2826. Please try again in 4.646s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:18,212 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '\nCARTCART\n\n\n\n\nCHAID\nCHAIDChi-square automatic interaction detectionKass1975\nCARTCHAID\nChi-square\n\nC4.5CARTCARTCHAID\nC4.5C4.5CART\nBottom-upPruning TechniqueCHAID\nTop-DownBonsai Technique\n\n\n\nCARTScikit-Learn\nID3C4.5sklearn\n\nID3C4.5\nLesson 8.2 CART\nsklearn\nCART\nCARTCART\nsklearn\nIn [1]:\n# \nimport numpy as np\nimport pandas as pd\n# \nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n# \nfrom ML_basic_function import *\n# Scikit-Learn\n# \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\n# \nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\n# \nfrom sklearn.datasets import load_iris\nCART\n\n\nCART\n\n1.CART\n'}
11:04:18,219 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:18,220 openai._base_client INFO Retrying request to /chat/completions in 4.624000 seconds
11:04:18,646 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:18,650 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: C4.5\nC4.5C4.5\nIEEE10C4.5C4.5\nC4.5\nRoss QuinlanC5.0\nC5.0\nSAS\n\nRoss Quinlan\n\n\nC4.5\n\nC4.5\n\nCART\nCARTClassification and Regression Trees\nC&RT1984BreimanFriedmanOlshenStone\nCARTC4.5C4.5\n\nCARTCART\n\nCART\n\nCARTskelarn\nCART\nCART\nsklearnID3C4.5CART\n1\nsklearnCART\nsklearnCART+C4.5\n\nCARTCART\n\n\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>C4.5<|>ORGANIZATION<|>C4.5 is a widely used decision tree model framework, recognized for its significant impact in data mining and has been ranked by IEEE as one of the top 10 data mining algorithms. It is open-source and has been the most common decision tree algorithm for a long time. Ross Quinlan later introduced C5.0, an optimization of C4.5, enhancing efficiency and prediction processes but was initially proprietary and integrated into software like SAS, limiting its widespread application.)\n##\n("entity"<|>ROSS QUINLAN<|>PERSON<|>Ross Quinlan, with a strong background in mathematics, developed the C4.5 and C5.0 decision tree algorithms. His work incorporates statistical methods into the decision tree pruning process, blending statistics and machine learning in the design of these algorithms.)\n##\n("entity"<|>C5.0<|>ORGANIZATION<|>An algorithm developed by Ross Quinlan as an improvement over C4.5, focusing on operational efficiency and predictive process optimization. Initially proprietary, C5.0 was not as widely used as its predecessor due to its restricted access.)\n##\n("entity"<|>CART<|>ORGANIZATION<|>Classification and Regression Trees (CART), also known as C&RT, is a decision tree algorithm introduced in 1984 by Breiman, Friedman, Olshen, and Stone. It extends the capabilities of decision tree models to include regression problems, supports both discrete and continuous variables, and is integrated into machine learning frameworks like sklearn, reflecting its robustness and versatility in machine learning applications.)\n##\n("relationship"<|>C4.5<|>ROSS QUINLAN<|>Ross Quinlan developed the C4.5 algorithm, marking a significant contribution to the field of data mining and decision tree models.<|>9)\n##\n("relationship"<|>C5.0<|>ROSS QUINLAN<|>Ross Quinlan introduced C5.0 as an optimized version of C4.5, aiming to improve efficiency and prediction accuracy.<|>9)\n##\n("relationship"<|>C4.5<|>C5.0<|>C5.0 is an optimization and further development of the C4.5 algorithm by Ross Quinlan, designed to enhance performance and predictive processes.<|>8)\n##\n("relationship"<|>CART<|>C4.5<|>CART and C4.5 share similar construction processes but CART extends to regression problems and offers a more versatile framework for machine learning, indicating an evolution in decision tree algorithms.<|>7)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:18,650 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29257, Requested 3056. Please try again in 4.626s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:18,653 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'C4.5\nC4.5C4.5\nIEEE10C4.5C4.5\nC4.5\nRoss QuinlanC5.0\nC5.0\nSAS\n\nRoss Quinlan\n\n\nC4.5\n\nC4.5\n\nCART\nCARTClassification and Regression Trees\nC&RT1984BreimanFriedmanOlshenStone\nCARTC4.5C4.5\n\nCARTCART\n\nCART\n\nCARTskelarn\nCART\nCART\nsklearnID3C4.5CART\n1\nsklearnCART\nsklearnCART+C4.5\n\nCARTCART\n\n'}
11:04:21,878 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:21,879 openai._base_client INFO Retrying request to /chat/completions in 0.024000 seconds
11:04:21,954 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:21,955 openai._base_client INFO Retrying request to /chat/completions in 0.312000 seconds
11:04:22,287 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:22,287 openai._base_client INFO Retrying request to /chat/completions in 4.364000 seconds
11:04:22,411 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:22,412 openai._base_client INFO Retrying request to /chat/completions in 4.364000 seconds
11:04:22,423 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:22,424 openai._base_client INFO Retrying request to /chat/completions in 4.418000 seconds
11:04:22,612 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:22,613 openai._base_client INFO Retrying request to /chat/completions in 4.360000 seconds
11:04:22,858 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:22,928 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:22,929 openai._base_client INFO Retrying request to /chat/completions in 3.728000 seconds
11:04:23,201 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:23,202 openai._base_client INFO Retrying request to /chat/completions in 4.664000 seconds
11:04:23,214 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:23,215 openai._base_client INFO Retrying request to /chat/completions in 3.604000 seconds
11:04:26,991 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:26,992 openai._base_client INFO Retrying request to /chat/completions in 0.540000 seconds
11:04:27,143 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:27,144 openai._base_client INFO Retrying request to /chat/completions in 0.512000 seconds
11:04:27,189 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:27,189 openai._base_client INFO Retrying request to /chat/completions in 4.526000 seconds
11:04:27,317 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:27,319 openai._base_client INFO Retrying request to /chat/completions in 4.284000 seconds
11:04:27,537 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:27,538 openai._base_client INFO Retrying request to /chat/completions in 4.382000 seconds
11:04:27,888 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:27,889 openai._base_client INFO Retrying request to /chat/completions in 3.686000 seconds
11:04:28,10 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:28,11 openai._base_client INFO Retrying request to /chat/completions in 3.680000 seconds
11:04:28,134 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:28,225 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:28,225 openai._base_client INFO Retrying request to /chat/completions in 4.278000 seconds
11:04:29,952 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:30,303 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:30,319 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:30,320 openai._base_client INFO Retrying request to /chat/completions in 5.072000 seconds
11:04:30,686 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:30,687 openai._base_client INFO Retrying request to /chat/completions in 4.812000 seconds
11:04:31,918 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:31,920 openai._base_client INFO Retrying request to /chat/completions in 3.646000 seconds
11:04:32,42 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:32,43 openai._base_client INFO Retrying request to /chat/completions in 4.212000 seconds
11:04:32,43 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:32,44 openai._base_client INFO Retrying request to /chat/completions in 3.034000 seconds
11:04:32,252 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:32,254 openai._base_client INFO Retrying request to /chat/completions in 3.624000 seconds
11:04:32,850 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:32,852 openai._base_client INFO Retrying request to /chat/completions in 3.028000 seconds
11:04:32,900 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:32,901 openai._base_client INFO Retrying request to /chat/completions in 3.592000 seconds
11:04:35,428 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:35,431 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \n\nmin_impurity_decrease\nCARTMSE\nAurlien Gron\nScikit-LearnKerasTensorFlow\n\nMSE\ncriterion=\'mae\'\nMSEMAE\n\nMAE =\n1\nm\nm\n\ni=1\n|(yi  ^yi)|\nMSEMAE\nMSEL2MAEL1\ncriterionmaeMAE\n\nLesson 7K-Means\n\nCARTcriterion\n\ncriterion\n\ncriterioncriterion=mse\nmse\ncriterion=msemae\n\n\nmae\n\nmse\n\n\n\n\n\ncriterion=\'friedman_mse\'\nfriedman_msemseGBDT\nfriedmansklearn\ncriterion\n######################\nOutput:', 'kwargs': {}}
11:04:35,431 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 27691, Requested 2435. Please try again in 251ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:35,434 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': "\n\nmin_impurity_decrease\nCARTMSE\nAurlien Gron\nScikit-LearnKerasTensorFlow\n\nMSE\ncriterion='mae'\nMSEMAE\n\nMAE =\n1\nm\nm\n\ni=1\n|(yi  ^yi)|\nMSEMAE\nMSEL2MAEL1\ncriterionmaeMAE\n\nLesson 7K-Means\n\nCARTcriterion\n\ncriterion\n\ncriterioncriterion=mse\nmse\ncriterion=msemae\n\n\nmae\n\nmse\n\n\n\n\n\ncriterion='friedman_mse'\nfriedman_msemseGBDT\nfriedmansklearn\ncriterion"}
11:04:35,766 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:35,767 openai._base_client INFO Retrying request to /chat/completions in 1.226000 seconds
11:04:35,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:35,853 openai._base_client INFO Retrying request to /chat/completions in 0.258000 seconds
11:04:36,237 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:36,238 openai._base_client INFO Retrying request to /chat/completions in 3.606000 seconds
11:04:36,240 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:36,242 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \n\nincome\ncredit_rating\ncredit_rating <= 1.5\n\n\n1\n8\nage87\nage <= 36age <= 34.5\nNN-1\n\n\n\nCART\nC4.5\nCART\nsklearnsklearn\nscikit-learn implementation does not\nsupport categorical variables for now.\nC4.5\nC4.5\nC4.5\n\n\n\n1.3 \nA\nincome <=\n1.5\n1\ncredit_rating <= 1.5\n\n1\n\n\n\nGini(A)\nGini(B)\n\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:04:36,243 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29661, Requested 2533. Please try again in 4.388s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:36,246 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '\n\nincome\ncredit_rating\ncredit_rating <= 1.5\n\n\n1\n8\nage87\nage <= 36age <= 34.5\nNN-1\n\n\n\nCART\nC4.5\nCART\nsklearnsklearn\nscikit-learn implementation does not\nsupport categorical variables for now.\nC4.5\nC4.5\nC4.5\n\n\n\n1.3 \nA\nincome <=\n1.5\n1\ncredit_rating <= 1.5\n\n1\n\n\n\nGini(A)\nGini(B)\n'}
11:04:36,471 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:36,472 openai._base_client INFO Retrying request to /chat/completions in 4.400000 seconds
11:04:36,522 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:36,616 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:36,618 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:04:36,861 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:36,862 openai._base_client INFO Retrying request to /chat/completions in 5.540000 seconds
11:04:36,905 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:36,907 openai._base_client INFO Retrying request to /chat/completions in 4.666000 seconds
11:04:37,348 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:37,349 openai._base_client INFO Retrying request to /chat/completions in 5.528000 seconds
11:04:40,237 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:40,241 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: # \nplt.plot(np.arange(1, 1.5, 0.1), np.full_like(np.arange(1, 1.5, 0.1), 1), \'r-\')\nplt.plot(np.arange(1.5, 3.5, 0.1), np.full_like(np.arange(1.5, 3.5, 0.1), 3), \'r\nplt.plot(np.arange(3.5, 5, 0.1), np.full_like(np.arange(3.5, 5, 0.1), 6), \'r-\')\nOut[21]:\n[<matplotlib.lines.Line2D at 0x7fb9d916a4c0>]\n\n\nsklearn\n\n1\n\n\n\n\nCART\n\n\nCARTScikit-Learn\n1.CARTsklearn\nIn [26]:\nIn [35]:\nIn [36]:\nsklearn\ntree\nfrom sklearn.tree import DecisionTreeRegressor\n\nclf = DecisionTreeRegressor().fit(data[:, 0].reshape(-1, 1), data[:, 1])\n# tree.plot_tree\nplt.figure(figsize=(6, 2), dpi=150)\ntree.plot_tree(clf)\nOut[36]:\n[Text(418.5, 188.75, \'X[0] <= 3.5\\nmse = 3.76\\nsamples = 5\\nvalue = 3.8\'),\nText(279.0, 113.25, \'X[0] <= 1.5\\nmse = 0.889\\nsamples = 3\\nvalue = 2.333\'),\nText(139.5, 37.75, \'mse = 0.0\\nsamples = 1\\nvalue = 1.0\'),\nText(418.5, 37.75, \'mse = 0.0\\nsamples = 2\\nvalue = 3.0\'),\nText(558.0, 113.25, \'mse = 0.0\\nsamples = 2\\nvalue = 6.0\')]\n\n2.CART\nCARTCART\n\n\nIn [25]:\nDecisionTreeRegressor?\n\nInit signature:\nDecisionTreeRegressor(\n*,\ncriterion=\'mse\',\nsplitter=\'best\',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_impurity_decrease=0.0,\nmin_impurity_split=None,\npresort=\'deprecated\',\nccp_alpha=0.0,\n)\nDocstring:\nA decision tree regressor.\nRead more in the :ref:`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for\n######################\nOutput:', 'kwargs': {}}
11:04:40,241 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 27928, Requested 2448. Please try again in 752ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:40,243 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '# \nplt.plot(np.arange(1, 1.5, 0.1), np.full_like(np.arange(1, 1.5, 0.1), 1), \'r-\')\nplt.plot(np.arange(1.5, 3.5, 0.1), np.full_like(np.arange(1.5, 3.5, 0.1), 3), \'r\nplt.plot(np.arange(3.5, 5, 0.1), np.full_like(np.arange(3.5, 5, 0.1), 6), \'r-\')\nOut[21]:\n[<matplotlib.lines.Line2D at 0x7fb9d916a4c0>]\n\n\nsklearn\n\n1\n\n\n\n\nCART\n\n\nCARTScikit-Learn\n1.CARTsklearn\nIn [26]:\nIn [35]:\nIn [36]:\nsklearn\ntree\nfrom sklearn.tree import DecisionTreeRegressor\n\nclf = DecisionTreeRegressor().fit(data[:, 0].reshape(-1, 1), data[:, 1])\n# tree.plot_tree\nplt.figure(figsize=(6, 2), dpi=150)\ntree.plot_tree(clf)\nOut[36]:\n[Text(418.5, 188.75, \'X[0] <= 3.5\\nmse = 3.76\\nsamples = 5\\nvalue = 3.8\'),\nText(279.0, 113.25, \'X[0] <= 1.5\\nmse = 0.889\\nsamples = 3\\nvalue = 2.333\'),\nText(139.5, 37.75, \'mse = 0.0\\nsamples = 1\\nvalue = 1.0\'),\nText(418.5, 37.75, \'mse = 0.0\\nsamples = 2\\nvalue = 3.0\'),\nText(558.0, 113.25, \'mse = 0.0\\nsamples = 2\\nvalue = 6.0\')]\n\n2.CART\nCARTCART\n\n\nIn [25]:\nDecisionTreeRegressor?\n\nInit signature:\nDecisionTreeRegressor(\n*,\ncriterion=\'mse\',\nsplitter=\'best\',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_impurity_decrease=0.0,\nmin_impurity_split=None,\npresort=\'deprecated\',\nccp_alpha=0.0,\n)\nDocstring:\nA decision tree regressor.\nRead more in the :ref:`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for'}
11:04:41,289 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:41,291 openai._base_client INFO Retrying request to /chat/completions in 0.716000 seconds
11:04:42,561 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:42,565 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead.\npresort : deprecated, default=\'deprecated\'\nThis parameter is deprecated and will be removed in v0.24.\n.. deprecated:: 0.22\nccp_alpha : non-negative float, default=0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. The\nsubtree with the largest cost complexity that is smaller than\n``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n:ref:`minimal_cost_complexity_pruning` for details.\n.. versionadded:: 0.22\nAttributes\n---------\nfeature_importances_ : ndarray of shape (n_features,)\nThe feature importances.\nThe higher, the more important the feature.\nThe importance of a feature is computed as the\n(normalized) total reduction of the criterion brought\nby that feature. It is also known as the Gini importance [4]_.\nWarning: impurity-based feature importances can be misleading for\nhigh cardinality features (many unique values). See\n:func:`sklearn.inspection.permutation_importance` as an alternative.\nmax_features_ : int\nThe inferred value of max_features.\nn_features_ : int\nThe number of features when ``fit`` is performed.\nn_outputs_ : int\nThe number of outputs when ``fit`` is performed.\ntree_ : Tree\nThe underlying Tree object. Please refer to\n``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n:ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\nfor basic usage of these attributes.\nSee Also\n\n-------\nDecisionTreeClassifier : A decision tree classifier.\nNotes\n----\nThe default values for the parameters controlling the size of the trees\n(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\nunpruned trees which can potentially be very large on some data sets. To\nreduce memory consumption, the complexity and size of the trees should be\ncontrolled by setting those parameter values.\nReferences\n---------\n.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n.. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, "Classification\nand Regression Trees", Wadsworth, Belmont, CA, 1984.\n.. [3] T. Hastie, R. Tibshirani and J. Friedman. "Elements of Statistical\nLearning", Springer, 2009.\n.. [4] L. Breiman, and A. Cutler, "Random Forests",\nhttps://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\nExamples\n-------\n>>> from sklearn.datasets import load_diabetes\n>>> from sklearn.model_selection import cross_val_score\n>>> from sklearn.tree import DecisionTreeRegressor\n>>> X, y = load_diabetes(return_X_y=True)\n>>> regressor = DecisionTreeRegressor(random_state=0)\n>>> cross_val_score(regressor, X, y, cv=10)\n...\n# doctest: +SKIP\n...\narray([-0.39..., -0.46..., 0.02..., 0.06..., -0.50...,\n0.16..., 0.11..., -0.73..., -0.30..., -0.00...])\nFile:\ns.py\nType:\nSubclasses:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\nABCMeta\nExtraTreeRegressor\nLesson 8.2\ncriterioncriterionCART\nCARTmsemae\nfriedman_msesklearnpoisson\n\ncriterion=\'mse\'\ncriterionmse\n\nMSE\n1\n\nMSE\n\nmin_impurity_decrease\nCARTMSE\n\n######################\nOutput:', 'kwargs': {}}
11:04:42,565 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29516, Requested 2683. Please try again in 4.398s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:42,569 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead.\npresort : deprecated, default=\'deprecated\'\nThis parameter is deprecated and will be removed in v0.24.\n.. deprecated:: 0.22\nccp_alpha : non-negative float, default=0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. The\nsubtree with the largest cost complexity that is smaller than\n``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n:ref:`minimal_cost_complexity_pruning` for details.\n.. versionadded:: 0.22\nAttributes\n---------\nfeature_importances_ : ndarray of shape (n_features,)\nThe feature importances.\nThe higher, the more important the feature.\nThe importance of a feature is computed as the\n(normalized) total reduction of the criterion brought\nby that feature. It is also known as the Gini importance [4]_.\nWarning: impurity-based feature importances can be misleading for\nhigh cardinality features (many unique values). See\n:func:`sklearn.inspection.permutation_importance` as an alternative.\nmax_features_ : int\nThe inferred value of max_features.\nn_features_ : int\nThe number of features when ``fit`` is performed.\nn_outputs_ : int\nThe number of outputs when ``fit`` is performed.\ntree_ : Tree\nThe underlying Tree object. Please refer to\n``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n:ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\nfor basic usage of these attributes.\nSee Also\n\n-------\nDecisionTreeClassifier : A decision tree classifier.\nNotes\n----\nThe default values for the parameters controlling the size of the trees\n(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\nunpruned trees which can potentially be very large on some data sets. To\nreduce memory consumption, the complexity and size of the trees should be\ncontrolled by setting those parameter values.\nReferences\n---------\n.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n.. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, "Classification\nand Regression Trees", Wadsworth, Belmont, CA, 1984.\n.. [3] T. Hastie, R. Tibshirani and J. Friedman. "Elements of Statistical\nLearning", Springer, 2009.\n.. [4] L. Breiman, and A. Cutler, "Random Forests",\nhttps://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\nExamples\n-------\n>>> from sklearn.datasets import load_diabetes\n>>> from sklearn.model_selection import cross_val_score\n>>> from sklearn.tree import DecisionTreeRegressor\n>>> X, y = load_diabetes(return_X_y=True)\n>>> regressor = DecisionTreeRegressor(random_state=0)\n>>> cross_val_score(regressor, X, y, cv=10)\n...\n# doctest: +SKIP\n...\narray([-0.39..., -0.46..., 0.02..., 0.06..., -0.50...,\n0.16..., 0.11..., -0.73..., -0.30..., -0.00...])\nFile:\ns.py\nType:\nSubclasses:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\nABCMeta\nExtraTreeRegressor\nLesson 8.2\ncriterioncriterionCART\nCARTmsemae\nfriedman_msesklearnpoisson\n\ncriterion=\'mse\'\ncriterionmse\n\nMSE\n1\n\nMSE\n\nmin_impurity_decrease\nCARTMSE\n'}
11:04:42,578 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:42,579 openai._base_client INFO Retrying request to /chat/completions in 4.292000 seconds
11:04:43,55 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:43,56 openai._base_client INFO Retrying request to /chat/completions in 4.248000 seconds
11:04:43,239 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:43,240 openai._base_client INFO Retrying request to /chat/completions in 4.530000 seconds
11:04:47,662 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:47,666 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: :`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for potential splits,\nand "mae" for the mean absolute error, which minimizes the L1 loss\nusing the median of each terminal node.\n.. versionadded:: 0.18\nMean Absolute Error (MAE) criterion.\nsplitter : {"best", "random"}, default="best"\nThe strategy used to choose the split at each node. Supported\nstrategies are "best" to choose the best split and "random" to choose\nthe best random split.\nmax_depth : int, default=None\nThe maximum depth of the tree. If None, then nodes are expanded until\nall leaves are pure or until all leaves contain less than\nmin_samples_split samples.\nmin_samples_split : int or float, default=2\nThe minimum number of samples required to split an internal node:\n- If int, then consider `min_samples_split` as the minimum number.\n- If float, then `min_samples_split` is a fraction and\n`ceil(min_samples_split * n_samples)` are the minimum\nnumber of samples for each split.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_samples_leaf : int or float, default=1\nThe minimum number of samples required to be at a leaf node.\nA split point at any depth will only be considered if it leaves at\n\nleast ``min_samples_leaf`` training samples in each of the left and\nright branches. This may have the effect of smoothing the model,\nespecially in regression.\n- If int, then consider `min_samples_leaf` as the minimum number.\n- If float, then `min_samples_leaf` is a fraction and\n`ceil(min_samples_leaf * n_samples)` are the minimum\nnumber of samples for each node.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_weight_fraction_leaf : float, default=0.0\nThe minimum weighted fraction of the sum total of weights (of all\nthe input samples) required to be at a leaf node. Samples have\nequal weight when sample_weight is not provided.\nmax_features : int, float or {"auto", "sqrt", "log2"}, default=None\nThe number of features to consider when looking for the best split:\n- If int, then consider `max_features` features at each split.\n- If float, then `max_features` is a fraction and\n`int(max_features * n_features)` features are considered at each\nsplit.\n- If "auto", then `max_features=n_features`.\n- If "sqrt", then `max_features=sqrt(n_features)`.\n- If "log2", then `max_features=log2(n_features)`.\n- If None, then `max_features=n_features`.\nNote: the search for a split does not stop until at least one\nvalid partition of the node samples is found, even if it requires to\neffectively inspect more than ``max_features`` features.\nrandom_state : int, RandomState instance, default=None\nControls the randomness of the estimator. The features are always\nrandomly permuted at each split, even if ``splitter`` is set to\n``"best"``. When ``max_features < n_features``, the algorithm will\nselect ``max_features`` at random at each split before finding the best\nsplit among them. But the best found split may vary across different\nruns, even if ``max_features=n_features``. That is the case, if the\nimprovement of the criterion is identical for several splits and one\nsplit has to be selected at random. To obtain a deterministic behaviour\nduring fitting, ``random_state`` has to be fixed to an integer.\nSee :term:`Glossary <random_state>` for details.\nmax_leaf_nodes : int, default=None\nGrow a tree with ``max_leaf_nodes`` in best-first fashion.\nBest nodes are defined as relative reduction in impurity.\nIf None then unlimited number of leaf nodes.\nmin_impurity_decrease : float, default=0.0\nA node will be split if this split induces a decrease of the impurity\ngreater than or equal to this value.\nThe weighted impurity decrease equation is the following::\nN_t / N * (impurity - N_t_R / N_t * right_impurity\n- N_t_L / N_t * left_impurity)\nwhere ``N`` is the total number of samples, ``N_t`` is the number of\n\nsamples at the current node, ``N_t_L`` is the number of samples in the\nleft child, and ``N_t_R`` is the number of samples in the right child.\n``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\nmin_impurity_split : float, (default=0)\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead\n######################\nOutput:', 'kwargs': {}}
11:04:47,666 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29598, Requested 2842. Please try again in 4.88s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:04:47,669 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ':`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for potential splits,\nand "mae" for the mean absolute error, which minimizes the L1 loss\nusing the median of each terminal node.\n.. versionadded:: 0.18\nMean Absolute Error (MAE) criterion.\nsplitter : {"best", "random"}, default="best"\nThe strategy used to choose the split at each node. Supported\nstrategies are "best" to choose the best split and "random" to choose\nthe best random split.\nmax_depth : int, default=None\nThe maximum depth of the tree. If None, then nodes are expanded until\nall leaves are pure or until all leaves contain less than\nmin_samples_split samples.\nmin_samples_split : int or float, default=2\nThe minimum number of samples required to split an internal node:\n- If int, then consider `min_samples_split` as the minimum number.\n- If float, then `min_samples_split` is a fraction and\n`ceil(min_samples_split * n_samples)` are the minimum\nnumber of samples for each split.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_samples_leaf : int or float, default=1\nThe minimum number of samples required to be at a leaf node.\nA split point at any depth will only be considered if it leaves at\n\nleast ``min_samples_leaf`` training samples in each of the left and\nright branches. This may have the effect of smoothing the model,\nespecially in regression.\n- If int, then consider `min_samples_leaf` as the minimum number.\n- If float, then `min_samples_leaf` is a fraction and\n`ceil(min_samples_leaf * n_samples)` are the minimum\nnumber of samples for each node.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_weight_fraction_leaf : float, default=0.0\nThe minimum weighted fraction of the sum total of weights (of all\nthe input samples) required to be at a leaf node. Samples have\nequal weight when sample_weight is not provided.\nmax_features : int, float or {"auto", "sqrt", "log2"}, default=None\nThe number of features to consider when looking for the best split:\n- If int, then consider `max_features` features at each split.\n- If float, then `max_features` is a fraction and\n`int(max_features * n_features)` features are considered at each\nsplit.\n- If "auto", then `max_features=n_features`.\n- If "sqrt", then `max_features=sqrt(n_features)`.\n- If "log2", then `max_features=log2(n_features)`.\n- If None, then `max_features=n_features`.\nNote: the search for a split does not stop until at least one\nvalid partition of the node samples is found, even if it requires to\neffectively inspect more than ``max_features`` features.\nrandom_state : int, RandomState instance, default=None\nControls the randomness of the estimator. The features are always\nrandomly permuted at each split, even if ``splitter`` is set to\n``"best"``. When ``max_features < n_features``, the algorithm will\nselect ``max_features`` at random at each split before finding the best\nsplit among them. But the best found split may vary across different\nruns, even if ``max_features=n_features``. That is the case, if the\nimprovement of the criterion is identical for several splits and one\nsplit has to be selected at random. To obtain a deterministic behaviour\nduring fitting, ``random_state`` has to be fixed to an integer.\nSee :term:`Glossary <random_state>` for details.\nmax_leaf_nodes : int, default=None\nGrow a tree with ``max_leaf_nodes`` in best-first fashion.\nBest nodes are defined as relative reduction in impurity.\nIf None then unlimited number of leaf nodes.\nmin_impurity_decrease : float, default=0.0\nA node will be split if this split induces a decrease of the impurity\ngreater than or equal to this value.\nThe weighted impurity decrease equation is the following::\nN_t / N * (impurity - N_t_R / N_t * right_impurity\n- N_t_L / N_t * left_impurity)\nwhere ``N`` is the total number of samples, ``N_t`` is the number of\n\nsamples at the current node, ``N_t_L`` is the number of samples in the\nleft child, and ``N_t_R`` is the number of samples in the right child.\n``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\nmin_impurity_split : float, (default=0)\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead'}
11:04:48,127 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:48,129 openai._base_client INFO Retrying request to /chat/completions in 4.288000 seconds
11:04:52,835 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:04:52,836 openai._base_client INFO Retrying request to /chat/completions in 0.194000 seconds
11:04:53,380 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:04:54,396 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:05:11,632 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:05:18,418 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:05:24,41 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:05:24,103 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:05:24,106 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:05:24,140 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:05:24,142 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:05:24,169 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:05:24,174 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:05:24,180 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:05:24,221 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:05:24,223 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:05:24,224 graphrag.utils.storage INFO reading table from storage: communities.parquet
11:05:24,233 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 15
11:05:44,464 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:06:03,127 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:06:07,757 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
11:06:07,814 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:06:07,818 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:06:07,821 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:06:07,823 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:06:07,825 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
11:06:07,828 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
11:06:07,828 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
11:06:07,870 graphrag.index.operations.embed_text.strategies.openai INFO embedding 28 inputs via 28 snippets using 2 batches. max_batch_size=16, batch_max_tokens=8191
11:06:08,936 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:10,708 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:11,422 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
11:06:11,425 graphrag.index.operations.embed_text.strategies.openai INFO embedding 3 inputs via 3 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
11:06:12,95 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:12,353 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
11:06:12,387 graphrag.index.operations.embed_text.strategies.openai INFO embedding 33 inputs via 33 snippets using 6 batches. max_batch_size=16, batch_max_tokens=8191
11:06:13,203 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:13,309 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:13,312 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:13,415 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:13,691 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:14,297 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:06:14,819 graphrag.cli.index INFO All workflows completed successfully.
11:38:31,517 graphrag.cli.index INFO Logging enabled at /Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/logs/indexing-engine.log
11:38:33,128 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:34,233 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:38:34,238 graphrag.cli.index INFO Starting pipeline run. dry_run=False
11:38:34,239 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "encoding_model": "cl100k_base",
            "api_base": "https://ai.devtool.tech/proxy/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "api_base": null,
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
11:38:34,241 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/output
11:38:34,242 graphrag.index.input.factory INFO loading input from root_dir=input
11:38:34,242 graphrag.index.input.factory INFO using file storage for input
11:38:34,244 graphrag.storage.file_pipeline_storage INFO search /Users/bytedance/ai-bootcamp/mcp-graphrag/graphrag/input for files matching .*\.txt$
11:38:34,251 graphrag.index.input.util INFO Found 2 InputFileType.text files, loading 2
11:38:34,253 graphrag.index.input.util INFO Total number of unfiltered InputFileType.text rows: 2
11:38:34,256 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 2
11:38:34,282 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:38:34,347 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:38:34,350 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:38:34,366 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:38:36,776 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,399 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,538 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,564 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,578 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,581 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,587 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,624 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,666 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,674 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,676 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:38,922 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:39,249 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:39,685 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:39,697 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:40,400 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:40,452 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:41,416 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:41,763 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:41,765 openai._base_client INFO Retrying request to /chat/completions in 5.228000 seconds
11:38:41,987 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:43,287 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:43,656 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:43,659 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:38:44,354 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:44,720 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:44,722 openai._base_client INFO Retrying request to /chat/completions in 5.356000 seconds
11:38:46,135 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:46,506 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:46,506 openai._base_client INFO Retrying request to /chat/completions in 4.474000 seconds
11:38:46,816 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:47,194 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:47,197 openai._base_client INFO Retrying request to /chat/completions in 5.504000 seconds
11:38:47,356 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:47,357 openai._base_client INFO Retrying request to /chat/completions in 5.228000 seconds
11:38:48,260 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:48,627 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:48,629 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:38:49,360 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:49,378 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:49,380 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:38:49,699 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:49,733 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:49,734 openai._base_client INFO Retrying request to /chat/completions in 6.548000 seconds
11:38:50,70 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:50,71 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:38:50,363 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:50,431 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:50,440 openai._base_client INFO Retrying request to /chat/completions in 5.356000 seconds
11:38:50,755 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:50,756 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:38:51,27 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:51,257 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:51,351 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:51,352 openai._base_client INFO Retrying request to /chat/completions in 4.474000 seconds
11:38:51,389 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:51,389 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:38:51,509 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:51,633 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:51,634 openai._base_client INFO Retrying request to /chat/completions in 6.314000 seconds
11:38:51,901 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:51,903 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:38:52,945 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:52,947 openai._base_client INFO Retrying request to /chat/completions in 5.228000 seconds
11:38:53,13 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:53,113 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:53,114 openai._base_client INFO Retrying request to /chat/completions in 5.504000 seconds
11:38:53,632 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:54,676 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:54,679 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:54,681 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:38:55,205 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:55,208 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:55,209 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:38:55,209 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:38:55,780 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:38:56,150 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:56,151 openai._base_client INFO Retrying request to /chat/completions in 5.356000 seconds
11:38:56,376 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:56,376 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:38:56,384 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:56,384 openai._base_client INFO Retrying request to /chat/completions in 4.474000 seconds
11:38:56,626 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:56,628 openai._base_client INFO Retrying request to /chat/completions in 6.548000 seconds
11:38:56,825 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:56,828 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:38:57,456 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:57,458 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:38:58,94 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:58,96 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:38:58,326 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:58,327 openai._base_client INFO Retrying request to /chat/completions in 6.314000 seconds
11:38:58,538 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:58,539 openai._base_client INFO Retrying request to /chat/completions in 5.228000 seconds
11:38:58,968 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:38:58,969 openai._base_client INFO Retrying request to /chat/completions in 5.504000 seconds
11:39:00,483 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:00,484 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:39:00,938 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:00,940 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:39:01,223 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:01,225 openai._base_client INFO Retrying request to /chat/completions in 4.474000 seconds
11:39:01,287 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:01,288 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:01,878 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:01,879 openai._base_client INFO Retrying request to /chat/completions in 5.356000 seconds
11:39:02,522 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:02,524 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:39:02,919 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:02,921 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:03,510 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:03,511 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:39:03,545 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:03,547 openai._base_client INFO Retrying request to /chat/completions in 6.548000 seconds
11:39:04,134 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:04,134 openai._base_client INFO Retrying request to /chat/completions in 5.228000 seconds
11:39:04,302 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:04,303 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:39:04,852 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:04,852 openai._base_client INFO Retrying request to /chat/completions in 5.504000 seconds
11:39:05,4 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:05,5 openai._base_client INFO Retrying request to /chat/completions in 6.314000 seconds
11:39:06,56 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:06,57 openai._base_client INFO Retrying request to /chat/completions in 4.474000 seconds
11:39:06,276 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:06,277 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:39:06,650 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:06,651 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:39:07,350 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:07,350 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:07,587 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:07,589 openai._base_client INFO Retrying request to /chat/completions in 5.356000 seconds
11:39:08,652 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:08,653 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:39:08,999 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:09,1 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:09,560 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:09,561 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:39:09,725 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:09,726 openai._base_client INFO Retrying request to /chat/completions in 5.228000 seconds
11:39:10,467 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:10,468 openai._base_client INFO Retrying request to /chat/completions in 6.548000 seconds
11:39:10,500 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:10,501 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:39:10,875 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:10,876 openai._base_client INFO Retrying request to /chat/completions in 4.474000 seconds
11:39:10,942 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:10,943 openai._base_client INFO Retrying request to /chat/completions in 5.504000 seconds
11:39:11,690 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:11,691 openai._base_client INFO Retrying request to /chat/completions in 6.314000 seconds
11:39:12,70 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:12,71 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:39:12,380 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:12,381 openai._base_client INFO Retrying request to /chat/completions in 5.366000 seconds
11:39:13,295 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:13,295 openai._base_client INFO Retrying request to /chat/completions in 5.356000 seconds
11:39:13,421 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:13,421 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:14,776 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:14,777 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:39:15,76 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:15,77 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:15,317 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:15,318 openai._base_client INFO Retrying request to /chat/completions in 5.228000 seconds
11:39:15,603 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:15,604 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:39:15,699 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:15,700 openai._base_client INFO Retrying request to /chat/completions in 4.474000 seconds
11:39:16,703 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:16,703 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:39:16,833 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:16,834 openai._base_client INFO Retrying request to /chat/completions in 5.410000 seconds
11:39:17,829 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:17,830 openai._base_client INFO Retrying request to /chat/completions in 5.440000 seconds
11:39:17,862 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:17,863 openai._base_client INFO Retrying request to /chat/completions in 4.300000 seconds
11:39:18,331 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:18,332 openai._base_client INFO Retrying request to /chat/completions in 3.758000 seconds
11:39:18,368 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:18,368 openai._base_client INFO Retrying request to /chat/completions in 4.660000 seconds
11:39:18,996 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:18,997 openai._base_client INFO Retrying request to /chat/completions in 3.076000 seconds
11:39:19,485 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:19,486 openai._base_client INFO Retrying request to /chat/completions in 2.950000 seconds
11:39:20,527 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:20,528 openai._base_client INFO Retrying request to /chat/completions in 0.664000 seconds
11:39:20,909 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:20,910 openai._base_client INFO Retrying request to /chat/completions in 1.598000 seconds
11:39:20,911 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:20,911 openai._base_client INFO Retrying request to /chat/completions in 1.040000 seconds
11:39:21,156 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:21,157 openai._base_client INFO Retrying request to /chat/completions in 1.280000 seconds
11:39:21,655 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:21,656 openai._base_client INFO Retrying request to /chat/completions in 0.748000 seconds
11:39:22,163 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:39:22,317 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,318 openai._base_client INFO Retrying request to /chat/completions in 4.104000 seconds
11:39:22,423 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,423 openai._base_client INFO Retrying request to /chat/completions in 4.708000 seconds
11:39:22,541 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,542 openai._base_client INFO Retrying request to /chat/completions in 4.680000 seconds
11:39:22,667 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,667 openai._base_client INFO Retrying request to /chat/completions in 4.478000 seconds
11:39:22,780 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,781 openai._base_client INFO Retrying request to /chat/completions in 4.680000 seconds
11:39:22,800 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,801 openai._base_client INFO Retrying request to /chat/completions in 4.694000 seconds
11:39:22,854 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,855 openai._base_client INFO Retrying request to /chat/completions in 4.436000 seconds
11:39:22,908 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:22,909 openai._base_client INFO Retrying request to /chat/completions in 4.710000 seconds
11:39:23,24 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:23,25 openai._base_client INFO Retrying request to /chat/completions in 4.470000 seconds
11:39:23,97 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:23,98 openai._base_client INFO Retrying request to /chat/completions in 4.462000 seconds
11:39:23,387 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:23,388 openai._base_client INFO Retrying request to /chat/completions in 4.706000 seconds
11:39:23,690 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:23,691 openai._base_client INFO Retrying request to /chat/completions in 4.690000 seconds
11:39:26,868 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:26,869 openai._base_client INFO Retrying request to /chat/completions in 0.232000 seconds
11:39:27,607 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:27,607 openai._base_client INFO Retrying request to /chat/completions in 4.996000 seconds
11:39:27,655 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:27,655 openai._base_client INFO Retrying request to /chat/completions in 4.980000 seconds
11:39:27,843 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:27,846 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:39:27,876 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:27,879 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:27,974 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:27,975 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:39:28,77 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:28,78 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:28,159 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:28,160 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:39:28,456 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:28,456 openai._base_client INFO Retrying request to /chat/completions in 6.314000 seconds
11:39:28,863 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:28,864 openai._base_client INFO Retrying request to /chat/completions in 6.548000 seconds
11:39:30,232 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:39:32,967 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:32,969 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:39:33,4 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:33,5 openai._base_client INFO Retrying request to /chat/completions in 5.504000 seconds
11:39:33,902 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:33,902 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:39:33,951 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:33,952 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:34,156 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:34,157 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:34,310 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:34,311 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:39:34,424 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:34,425 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:39:34,613 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:39:35,124 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:35,125 openai._base_client INFO Retrying request to /chat/completions in 6.314000 seconds
11:39:35,772 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:35,774 openai._base_client INFO Retrying request to /chat/completions in 6.548000 seconds
11:39:38,336 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:39:38,775 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:38,776 openai._base_client INFO Retrying request to /chat/completions in 5.444000 seconds
11:39:38,871 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:38,872 openai._base_client INFO Retrying request to /chat/completions in 5.504000 seconds
11:39:39,953 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:39,954 openai._base_client INFO Retrying request to /chat/completions in 5.686000 seconds
11:39:40,18 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:40,19 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:40,227 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:40,227 openai._base_client INFO Retrying request to /chat/completions in 5.714000 seconds
11:39:40,455 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:40,456 openai._base_client INFO Retrying request to /chat/completions in 5.776000 seconds
11:39:40,620 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:40,620 openai._base_client INFO Retrying request to /chat/completions in 5.840000 seconds
11:39:41,788 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:41,789 openai._base_client INFO Retrying request to /chat/completions in 6.314000 seconds
11:39:42,692 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:42,694 openai._base_client INFO Retrying request to /chat/completions in 6.014000 seconds
11:39:44,580 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:44,590 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: # \nplt.plot(np.arange(1, 1.5, 0.1), np.full_like(np.arange(1, 1.5, 0.1), 1), \'r-\')\nplt.plot(np.arange(1.5, 3.5, 0.1), np.full_like(np.arange(1.5, 3.5, 0.1), 3), \'r\nplt.plot(np.arange(3.5, 5, 0.1), np.full_like(np.arange(3.5, 5, 0.1), 6), \'r-\')\nOut[21]:\n[<matplotlib.lines.Line2D at 0x7fb9d916a4c0>]\n\n\nsklearn\n\n1\n\n\n\n\nCART\n\n\nCARTScikit-Learn\n1.CARTsklearn\nIn [26]:\nIn [35]:\nIn [36]:\nsklearn\ntree\nfrom sklearn.tree import DecisionTreeRegressor\n\nclf = DecisionTreeRegressor().fit(data[:, 0].reshape(-1, 1), data[:, 1])\n# tree.plot_tree\nplt.figure(figsize=(6, 2), dpi=150)\ntree.plot_tree(clf)\nOut[36]:\n[Text(418.5, 188.75, \'X[0] <= 3.5\\nmse = 3.76\\nsamples = 5\\nvalue = 3.8\'),\nText(279.0, 113.25, \'X[0] <= 1.5\\nmse = 0.889\\nsamples = 3\\nvalue = 2.333\'),\nText(139.5, 37.75, \'mse = 0.0\\nsamples = 1\\nvalue = 1.0\'),\nText(418.5, 37.75, \'mse = 0.0\\nsamples = 2\\nvalue = 3.0\'),\nText(558.0, 113.25, \'mse = 0.0\\nsamples = 2\\nvalue = 6.0\')]\n\n2.CART\nCARTCART\n\n\nIn [25]:\nDecisionTreeRegressor?\n\nInit signature:\nDecisionTreeRegressor(\n*,\ncriterion=\'mse\',\nsplitter=\'best\',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_impurity_decrease=0.0,\nmin_impurity_split=None,\npresort=\'deprecated\',\nccp_alpha=0.0,\n)\nDocstring:\nA decision tree regressor.\nRead more in the :ref:`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>DECISIONTREEREGRESSOR<|>ORGANIZATION<|>A Scikit-Learn class for creating a decision tree regressor model, capable of fitting to data and predicting values)\n##\n("entity"<|>CART<|>EVENT<|>CART (Classification And Regression Trees) methodology used for constructing decision trees that can be used for classification or regression tasks)\n##\n("entity"<|>SKLEARN<|>ORGANIZATION<|>Scikit-Learn, a popular Python library for machine learning, providing tools for data mining and data analysis)\n##\n("relationship"<|>DECISIONTREEREGRESSOR<|>CART<|>DecisionTreeRegressor is an implementation of the CART algorithm in Scikit-Learn<|>9)\n##\n("relationship"<|>DECISIONTREEREGRESSOR<|>SKLEARN<|>DecisionTreeRegressor is a part of the Scikit-Learn library<|>9)\n##\n("relationship"<|>CART<|>SKLEARN<|>CART methodology is implemented in Scikit-Learn through models like DecisionTreeRegressor<|>8)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:44,590 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28791, Requested 2722. Please try again in 3.026s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:44,594 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '# \nplt.plot(np.arange(1, 1.5, 0.1), np.full_like(np.arange(1, 1.5, 0.1), 1), \'r-\')\nplt.plot(np.arange(1.5, 3.5, 0.1), np.full_like(np.arange(1.5, 3.5, 0.1), 3), \'r\nplt.plot(np.arange(3.5, 5, 0.1), np.full_like(np.arange(3.5, 5, 0.1), 6), \'r-\')\nOut[21]:\n[<matplotlib.lines.Line2D at 0x7fb9d916a4c0>]\n\n\nsklearn\n\n1\n\n\n\n\nCART\n\n\nCARTScikit-Learn\n1.CARTsklearn\nIn [26]:\nIn [35]:\nIn [36]:\nsklearn\ntree\nfrom sklearn.tree import DecisionTreeRegressor\n\nclf = DecisionTreeRegressor().fit(data[:, 0].reshape(-1, 1), data[:, 1])\n# tree.plot_tree\nplt.figure(figsize=(6, 2), dpi=150)\ntree.plot_tree(clf)\nOut[36]:\n[Text(418.5, 188.75, \'X[0] <= 3.5\\nmse = 3.76\\nsamples = 5\\nvalue = 3.8\'),\nText(279.0, 113.25, \'X[0] <= 1.5\\nmse = 0.889\\nsamples = 3\\nvalue = 2.333\'),\nText(139.5, 37.75, \'mse = 0.0\\nsamples = 1\\nvalue = 1.0\'),\nText(418.5, 37.75, \'mse = 0.0\\nsamples = 2\\nvalue = 3.0\'),\nText(558.0, 113.25, \'mse = 0.0\\nsamples = 2\\nvalue = 6.0\')]\n\n2.CART\nCARTCART\n\n\nIn [25]:\nDecisionTreeRegressor?\n\nInit signature:\nDecisionTreeRegressor(\n*,\ncriterion=\'mse\',\nsplitter=\'best\',\nmax_depth=None,\nmin_samples_split=2,\nmin_samples_leaf=1,\nmin_weight_fraction_leaf=0.0,\nmax_features=None,\nrandom_state=None,\nmax_leaf_nodes=None,\nmin_impurity_decrease=0.0,\nmin_impurity_split=None,\npresort=\'deprecated\',\nccp_alpha=0.0,\n)\nDocstring:\nA decision tree regressor.\nRead more in the :ref:`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for'}
11:39:44,738 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:44,741 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: Lesson 8.3 ID3C4.5\nID3C4.5sklearn\nID3C4.5ID3C4.5\nCARTID3\nC4.5\nID3C4.5ID3\nimport numpy as np\nfrom ML_basic_function import *\nID3\nID3ID3\n\nageincome\nage3040\n123\n\nID3CART\nID3CARTCART\n\nCARTID3\nage\nage\nID3\n\n# A\nent_A = -5/14 * np.log2(5/14) - 9/14 * np.log2(9/14)\nent_A\n0.9402859586706311\n\n# B\nent_B1 = entropy(2/5)\nent_B2 = entropy(2/5)\nent_B3 = 0\nent_B1, ent_B2, ent_B3\n\n(0.9709505944546686, 0.9709505944546686, 0)\n\n\nent_B = ent_B1 * 5/14 + ent_B2 * 5/14 + ent_B3 * 4/14\nent_B\n0.6935361388961919\n\n# \nent_A - ent_B\n0.24674981977443922\nageinformation gain\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>ID3<|>ORGANIZATION<|>ID3 is a classic decision tree algorithm that focuses on classification problems around discrete variables and cannot handle continuous features or regression problems without discretization of those continuous variables)\n##\n("entity"<|>C4.5<|>ORGANIZATION<|>C4.5 builds upon ID3 by improving the handling of continuous variables and other aspects of decision tree modeling, using information entropy as a measure for dataset splitting)\n##\n("entity"<|>CART<|>ORGANIZATION<|>CART tree is a type of decision tree that looks for splitting points across all features to reduce dataset impurity, contrasting with ID3\'s approach of expanding by columns)\n##\n("relationship"<|>ID3<|>C4.5<|>C4.5 is an improvement on the ID3 decision tree algorithm, addressing some of its limitations<|>8)\n##\n("relationship"<|>ID3<|>CART<|>ID3 and CART share the basic modeling process of reducing dataset impurity through splits, but differ in their splitting criteria<|>7)\n##\n("relationship"<|>C4.5<|>CART<|>C4.5 and CART both aim to reduce dataset impurity but use different measures and methods for splitting the dataset<|>6)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:44,741 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28711, Requested 2752. Please try again in 2.926s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:44,744 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'Lesson 8.3 ID3C4.5\nID3C4.5sklearn\nID3C4.5ID3C4.5\nCARTID3\nC4.5\nID3C4.5ID3\nimport numpy as np\nfrom ML_basic_function import *\nID3\nID3ID3\n\nageincome\nage3040\n123\n\nID3CART\nID3CARTCART\n\nCARTID3\nage\nage\nID3\n\n# A\nent_A = -5/14 * np.log2(5/14) - 9/14 * np.log2(9/14)\nent_A\n0.9402859586706311\n\n# B\nent_B1 = entropy(2/5)\nent_B2 = entropy(2/5)\nent_B3 = 0\nent_B1, ent_B2, ent_B3\n\n(0.9709505944546686, 0.9709505944546686, 0)\n\n\nent_B = ent_B1 * 5/14 + ent_B2 * 5/14 + ent_B3 * 4/14\nent_B\n0.6935361388961919\n\n# \nent_A - ent_B\n0.24674981977443922\nageinformation gain'}
11:39:46,14 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:46,17 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: \n\n\n\nABABA\nB\n(1)root node\n(2)internal node\n(3)leaf node\n\n\n\n\n\nEpetal length (cm) <= 2.5petal length\n(cm) <= 4.879False\n\n\n\n\n\n\nID3(Iterative Dichotomiser 3) C4.5C5.0\nID3\nRoss Quinlan1975\n\nC4.5ID3C4.5ID3\n\n\nID3\nC4.5\nC4.5C4.5\nIEEE10\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>ID3<|>ORGANIZATION<|>ID3 (Iterative Dichotomiser 3) is a classic decision tree algorithm developed by Ross Quinlan in 1975 as part of his PhD dissertation, laying the foundation for decision tree algorithms by establishing classification rule indicators and seeking ways to reduce information entropy rapidly for data set division)\n##\n("entity"<|>C4.5<|>ORGANIZATION<|>C4.5 is a successor to the ID3 algorithm, introduced to address limitations of ID3 by including continuous variables and improving the growth speed of tree models, making it one of the most widely used decision tree frameworks)\n##\n("entity"<|>C5.0<|>ORGANIZATION<|>C5.0 is an advanced version of the C4.5 decision tree algorithm, further optimizing the decision tree process and often considered in the lineage of classic decision tree algorithms)\n##\n("entity"<|>ROSS QUINLAN<|>PERSON<|>Ross Quinlan is a computer scientist who introduced the ID3 decision tree algorithm in 1975, significantly contributing to the field of machine learning and decision tree models)\n##\n("relationship"<|>ID3<|>ROSS QUINLAN<|>Ross Quinlan developed the ID3 decision tree algorithm<|>9)\n##\n("relationship"<|>C4.5<|>ID3<|>C4.5 was developed as a successor to the ID3 algorithm, improving upon its methodology and capabilities<|>8)\n##\n("relationship"<|>C5.0<|>C4.5<|>C5.0 is an advancement of the C4.5 decision tree algorithm, indicating a lineage of development in decision tree models<|>7)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:46,17 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 28079, Requested 2843. Please try again in 1.844s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:46,21 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '\n\n\n\nABABA\nB\n(1)root node\n(2)internal node\n(3)leaf node\n\n\n\n\n\nEpetal length (cm) <= 2.5petal length\n(cm) <= 4.879False\n\n\n\n\n\n\nID3(Iterative Dichotomiser 3) C4.5C5.0\nID3\nRoss Quinlan1975\n\nC4.5ID3C4.5ID3\n\n\nID3\nC4.5\nC4.5C4.5\nIEEE10'}
11:39:46,82 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:46,82 openai._base_client INFO Retrying request to /chat/completions in 1.796000 seconds
11:39:46,525 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:46,526 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: cv=10)\n...\n# doctest: +SKIP\n...\narray([ 1.\n, 0.93..., 0.86..., 0.93..., 0.93...,\n0.93..., 0.93..., 1.\n, 0.93..., 1.\n])\n\nFile:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\ns.py\nType:\nSubclasses:\nName\ncriterion\nsplitter\nmax_depth\nmin_samples_split\nmin_samples_leaf\nmin_weight_fraction_leaf\nmax_features\nrandom_state\nmax_leaf_nodes\nmin_impurity_decrease\nmin_impurity_split\nclass_weight\npresort\nccp_alpha\nABCMeta\nExtraTreeClassifier\nDescription\n\n\n\nmax_iter\n\n\n\n\n\n\n\n0.25\n\n0.24\nCART\n\n\ncriterion\nsklearnCART\ncriterion\nID3C4.5\n\n\n\n\n\nccp_alpha\nccpCost-Complexity Pruningsklearn0.22\nCART\nsklearn\nccp\n\n\n\nT \n   \n\nR(T)\n| T|\n\n| T|\nR(T) = R(T) + | T|\nR(T)\n \n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>SKLEARN<|>ORGANIZATION<|>Sklearn is a machine learning library for the Python programming language, providing tools for machine learning and statistical modeling including classification, regression, clustering, and dimensionality reduction)\n##\n("entity"<|>EXTRATREECLASSIFIER<|>ORGANIZATION<|>ExtraTreeClassifier is a type of decision tree classifier provided by sklearn that works by fitting a number of randomized decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting)\n##\n("entity"<|>CRITERION<|>EVENT<|>Criterion refers to the function used to measure the quality of a split in the decision tree models within sklearn, with options like Gini impurity and information gain (entropy))\n##\n("entity"<|>CCP_ALPHA<|>EVENT<|>CCP_Alpha is a parameter used in sklearn\'s decision tree and ensemble algorithms for Cost Complexity Pruning, a technique to prevent overfitting by penalizing the complexity of the decision trees)\n##\n("relationship"<|>EXTRATREECLASSIFIER<|>SKLEARN<|>ExtraTreeClassifier is a component of the sklearn library, designed for classification tasks<|>9)\n##\n("relationship"<|>CRITERION<|>EXTRATREECLASSIFIER<|>Criterion is a parameter that can be set for the ExtraTreeClassifier to define the measure for splitting the nodes<|>8)\n##\n("relationship"<|>CCP_ALPHA<|>EXTRATREECLASSIFIER<|>CCP_Alpha is a parameter available in ExtraTreeClassifier for applying Cost Complexity Pruning<|>8)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:46,526 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 27818, Requested 2857. Please try again in 1.35s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:46,526 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'cv=10)\n...\n# doctest: +SKIP\n...\narray([ 1.\n, 0.93..., 0.86..., 0.93..., 0.93...,\n0.93..., 0.93..., 1.\n, 0.93..., 1.\n])\n\nFile:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\ns.py\nType:\nSubclasses:\nName\ncriterion\nsplitter\nmax_depth\nmin_samples_split\nmin_samples_leaf\nmin_weight_fraction_leaf\nmax_features\nrandom_state\nmax_leaf_nodes\nmin_impurity_decrease\nmin_impurity_split\nclass_weight\npresort\nccp_alpha\nABCMeta\nExtraTreeClassifier\nDescription\n\n\n\nmax_iter\n\n\n\n\n\n\n\n0.25\n\n0.24\nCART\n\n\ncriterion\nsklearnCART\ncriterion\nID3C4.5\n\n\n\n\n\nccp_alpha\nccpCost-Complexity Pruningsklearn0.22\nCART\nsklearn\nccp\n\n\n\nT \n   \n\nR(T)\n| T|\n\n| T|\nR(T) = R(T) + | T|\nR(T)\n '}
11:39:46,598 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:46,600 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 8961919\n\n# \nent_A - ent_B\n0.24674981977443922\nageinformation gain\nGain(age) = 0.247\nage\nageincome\nstudentcredit_ratingage\nGain(income)=0.026Gain(student)=0.151Gain(credit_rating)=0.048\nageage\n\nB1student\nB2credit_rating\n100%\nID3CART\nID3CARTID3\nCART\nID3\nCARTCART\nCARTID3CART\nID3ID3ageCART\n<=30\n>40\n\nID3\nID3ID3\nID3\nID3C4.5C4.5\nID3\nC4.5\nID3C4.5ID3\ninformation value\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>ID3 DECISION TREE<|>ORGANIZATION<|>ID3 Decision Tree is a model that uses information gain to decide how to split data sets based on different column values to reduce impurity. It is prone to overfitting as it tends to choose variables with more categories for splitting and lacks measures to prevent overfitting.)\n##\n("entity"<|>CART TREE<|>ORGANIZATION<|>CART Tree, unlike ID3, can perform binary splits allowing for more detailed rule extraction and can handle both discrete and continuous variables. It has a broader set of rules for splitting, potentially reducing the risk of overfitting compared to ID3.)\n##\n("entity"<|>C4.5 DECISION TREE<|>ORGANIZATION<|>C4.5 Decision Tree is an improvement over the ID3 model, optimizing the process of measuring impurity reduction by introducing the concept of information value. It aims to address the limitations of ID3, including its tendency towards overfitting and its limitation to discrete variables.)\n##\n("relationship"<|>ID3 DECISION TREE<|>CART TREE<|>CART Tree is developed as an alternative to the ID3 Decision Tree, capable of binary splits and handling more complex data sets.<|>7)\n##\n("relationship"<|>ID3 DECISION TREE<|>C4.5 DECISION TREE<|>C4.5 Decision Tree is an improvement on the ID3 model, addressing its shortcomings and optimizing its decision-making process.<|>8)\n##\n("relationship"<|>C4.5 DECISION TREE<|>CART TREE<|>Both C4.5 and CART Trees offer advancements over the ID3 model, with C4.5 directly improving upon ID3\'s methodology and CART providing a different approach to tree construction.<|>6)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:46,600 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 27783, Requested 2888. Please try again in 1.342s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:46,602 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '8961919\n\n# \nent_A - ent_B\n0.24674981977443922\nageinformation gain\nGain(age) = 0.247\nage\nageincome\nstudentcredit_ratingage\nGain(income)=0.026Gain(student)=0.151Gain(credit_rating)=0.048\nageage\n\nB1student\nB2credit_rating\n100%\nID3CART\nID3CARTID3\nCART\nID3\nCARTCART\nCARTID3CART\nID3ID3ageCART\n<=30\n>40\n\nID3\nID3ID3\nID3\nID3C4.5C4.5\nID3\nC4.5\nID3C4.5ID3\ninformation value'}
11:39:46,803 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:46,805 openai._base_client INFO Retrying request to /chat/completions in 1.196000 seconds
11:39:48,431 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:48,434 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: 4.5\nID3C4.5ID3\ninformation value\nID3\nCART\n\nC4.5C4.5\n\ninformation value\nC4.5IV\nIVIV\nIV\nIV\n\nK$v_i$$P(v_i)$\nIV\n# 50%-50%\n- (1/2 * np.log2(1/2) + 1/2 * np.log2(1/2))\n1.0\n# 1/4-1/2-1/4\n- (1/4 * np.log2(1/4) + 1/2 * np.log2(1/2)+ 1/4 * np.log2(1/4))\n1.5\n\n# 1/4-1/4-1/4-1/4\n- (1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 *\nnp.log2(1/4))\n2.0\nID3C4.5IV\nGain Ratio\nGR\nC4.5GRGR\nageInformation Gain\nIG = ent_A - ent_B\nIG\n0.24674981977443922\nIV\nIV = - (5/14 * np.log2(5/14) + 5/14 * np.log2(5/14)+ 4/14 * np.log2(4/14))\nIV\n1.5774062828523454\nGR\nGR = IG / IV\nGR\n0.1564275624211752\nGRGR\n\nC4.5\nC4.5CART\n\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>ID3<|>ORGANIZATION<|>A precursor algorithm to C4.5, known for its approach to decision tree modeling by using information gain but criticized for favoring attributes with more categories and potentially leading to overfitting)##\n("entity"<|>C4.5<|>ORGANIZATION<|>An improved version of the ID3 algorithm that optimizes decision tree modeling by introducing the concept of information value (IV) to adjust information entropy calculations, handling continuous variables, and incorporating a pruning process to enhance model generalization)##\n("entity"<|>INFORMATION VALUE<|>EVENT<|>A metric used in C4.5 to measure the number of branches during data set division, aiming to adjust the calculation of information entropy and indirectly suppress model overfitting tendencies)##\n("entity"<|>GAIN RATIO<|>EVENT<|>An evaluation metric introduced by C4.5 to correct information gain calculations by using the information value (IV), guiding the selection of attributes for data set division)##\n("relationship"<|>C4.5<|>ID3<|>C4.5 is an improved version of the ID3 algorithm, designed to address its limitations and enhance decision tree modeling<|>9)##\n("relationship"<|>C4.5<|>INFORMATION VALUE<|>C4.5 uses the concept of information value (IV) to refine the process of calculating information entropy and to mitigate the tendency towards overfitting<|>8)##\n("relationship"<|>C4.5<|>GAIN RATIO<|>C4.5 introduces the gain ratio as a new metric to adjust information gain calculations and to assist in the selection of attributes for data set division<|>8)##\n("relationship"<|>INFORMATION VALUE<|>GAIN RATIO<|>The information value (IV) is used in the calculation of the gain ratio (GR) in C4.5 to evaluate data set division<|>7)<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:48,434 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29784, Requested 2857. Please try again in 5.282s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:48,437 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': '4.5\nID3C4.5ID3\ninformation value\nID3\nCART\n\nC4.5C4.5\n\ninformation value\nC4.5IV\nIVIV\nIV\nIV\n\nK$v_i$$P(v_i)$\nIV\n# 50%-50%\n- (1/2 * np.log2(1/2) + 1/2 * np.log2(1/2))\n1.0\n# 1/4-1/2-1/4\n- (1/4 * np.log2(1/4) + 1/2 * np.log2(1/2)+ 1/4 * np.log2(1/4))\n1.5\n\n# 1/4-1/4-1/4-1/4\n- (1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 * np.log2(1/4) + 1/4 *\nnp.log2(1/4))\n2.0\nID3C4.5IV\nGain Ratio\nGR\nC4.5GRGR\nageInformation Gain\nIG = ent_A - ent_B\nIG\n0.24674981977443922\nIV\nIV = - (5/14 * np.log2(5/14) + 5/14 * np.log2(5/14)+ 4/14 * np.log2(4/14))\nIV\n1.5774062828523454\nGR\nGR = IG / IV\nGR\n0.1564275624211752\nGRGR\n\nC4.5\nC4.5CART\n'}
11:39:48,465 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:48,466 openai._base_client INFO Retrying request to /chat/completions in 0.012000 seconds
11:39:48,842 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:48,845 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead.\npresort : deprecated, default=\'deprecated\'\nThis parameter is deprecated and will be removed in v0.24.\n.. deprecated:: 0.22\nccp_alpha : non-negative float, default=0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. The\nsubtree with the largest cost complexity that is smaller than\n``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n:ref:`minimal_cost_complexity_pruning` for details.\n.. versionadded:: 0.22\nAttributes\n---------\nfeature_importances_ : ndarray of shape (n_features,)\nThe feature importances.\nThe higher, the more important the feature.\nThe importance of a feature is computed as the\n(normalized) total reduction of the criterion brought\nby that feature. It is also known as the Gini importance [4]_.\nWarning: impurity-based feature importances can be misleading for\nhigh cardinality features (many unique values). See\n:func:`sklearn.inspection.permutation_importance` as an alternative.\nmax_features_ : int\nThe inferred value of max_features.\nn_features_ : int\nThe number of features when ``fit`` is performed.\nn_outputs_ : int\nThe number of outputs when ``fit`` is performed.\ntree_ : Tree\nThe underlying Tree object. Please refer to\n``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n:ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\nfor basic usage of these attributes.\nSee Also\n\n-------\nDecisionTreeClassifier : A decision tree classifier.\nNotes\n----\nThe default values for the parameters controlling the size of the trees\n(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\nunpruned trees which can potentially be very large on some data sets. To\nreduce memory consumption, the complexity and size of the trees should be\ncontrolled by setting those parameter values.\nReferences\n---------\n.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n.. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, "Classification\nand Regression Trees", Wadsworth, Belmont, CA, 1984.\n.. [3] T. Hastie, R. Tibshirani and J. Friedman. "Elements of Statistical\nLearning", Springer, 2009.\n.. [4] L. Breiman, and A. Cutler, "Random Forests",\nhttps://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\nExamples\n-------\n>>> from sklearn.datasets import load_diabetes\n>>> from sklearn.model_selection import cross_val_score\n>>> from sklearn.tree import DecisionTreeRegressor\n>>> X, y = load_diabetes(return_X_y=True)\n>>> regressor = DecisionTreeRegressor(random_state=0)\n>>> cross_val_score(regressor, X, y, cv=10)\n...\n# doctest: +SKIP\n...\narray([-0.39..., -0.46..., 0.02..., 0.06..., -0.50...,\n0.16..., 0.11..., -0.73..., -0.30..., -0.00...])\nFile:\ns.py\nType:\nSubclasses:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\nABCMeta\nExtraTreeRegressor\nLesson 8.2\ncriterioncriterionCART\nCARTmsemae\nfriedman_msesklearnpoisson\n\ncriterion=\'mse\'\ncriterionmse\n\nMSE\n1\n\nMSE\n\nmin_impurity_decrease\nCARTMSE\n\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>DECISIONTREEREGRESSOR<|>ORGANIZATION<|>A regressor that is part of the sklearn library, used for regression tasks with decision trees)\n##\n("entity"<|>SKLEARN<|>ORGANIZATION<|>A machine learning library for the Python programming language)\n##\n("entity"<|>MIN_IMPURITY_DECREASE<|>EVENT<|>A parameter in sklearn\'s DecisionTreeRegressor that controls when a node will split based on the decrease in impurity)\n##\n("entity"<|>MIN_IMPURITY_SPLIT<|>EVENT<|>A deprecated parameter in sklearn\'s DecisionTreeRegressor that was used to control the splitting of nodes)\n##\n("entity"<|>CCP_ALPHA<|>EVENT<|>A complexity parameter in sklearn\'s DecisionTreeRegressor used for Minimal Cost-Complexity Pruning)\n##\n("entity"<|>LOAD_DIABETES<|>ORGANIZATION<|>A function in sklearn to load the diabetes dataset)\n##\n("entity"<|>CROSS_VAL_SCORE<|>EVENT<|>A function in sklearn to perform cross-validation scoring)\n##\n("relationship"<|>DECISIONTREEREGRESSOR<|>SKLEARN<|>DecisionTreeRegressor is a part of the sklearn library<|>9)\n##\n("relationship"<|>MIN_IMPURITY_DECREASE<|>DECISIONTREEREGRESSOR<|>min_impurity_decrease is a parameter used in DecisionTreeRegressor<|>8)\n##\n("relationship"<|>MIN_IMPURITY_SPLIT<|>DECISIONTREEREGRESSOR<|>min_impurity_split was a parameter used in DecisionTreeRegressor but is now deprecated<|>7)\n##\n("relationship"<|>CCP_ALPHA<|>DECISIONTREEREGRESSOR<|>ccp_alpha is a parameter used in DecisionTreeRegressor for pruning<|>8)\n##\n("relationship"<|>LOAD_DIABETES<|>SKLEARN<|>load_diabetes is a function provided by sklearn to load a dataset<|>9)\n##\n("relationship"<|>CROSS_VAL_SCORE<|>SKLEARN<|>cross_val_score is a function provided by sklearn for cross-validation<|>9)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:48,845 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 29582, Requested 3157. Please try again in 5.478s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:48,848 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': 'will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead.\npresort : deprecated, default=\'deprecated\'\nThis parameter is deprecated and will be removed in v0.24.\n.. deprecated:: 0.22\nccp_alpha : non-negative float, default=0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. The\nsubtree with the largest cost complexity that is smaller than\n``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n:ref:`minimal_cost_complexity_pruning` for details.\n.. versionadded:: 0.22\nAttributes\n---------\nfeature_importances_ : ndarray of shape (n_features,)\nThe feature importances.\nThe higher, the more important the feature.\nThe importance of a feature is computed as the\n(normalized) total reduction of the criterion brought\nby that feature. It is also known as the Gini importance [4]_.\nWarning: impurity-based feature importances can be misleading for\nhigh cardinality features (many unique values). See\n:func:`sklearn.inspection.permutation_importance` as an alternative.\nmax_features_ : int\nThe inferred value of max_features.\nn_features_ : int\nThe number of features when ``fit`` is performed.\nn_outputs_ : int\nThe number of outputs when ``fit`` is performed.\ntree_ : Tree\nThe underlying Tree object. Please refer to\n``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n:ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\nfor basic usage of these attributes.\nSee Also\n\n-------\nDecisionTreeClassifier : A decision tree classifier.\nNotes\n----\nThe default values for the parameters controlling the size of the trees\n(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\nunpruned trees which can potentially be very large on some data sets. To\nreduce memory consumption, the complexity and size of the trees should be\ncontrolled by setting those parameter values.\nReferences\n---------\n.. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n.. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, "Classification\nand Regression Trees", Wadsworth, Belmont, CA, 1984.\n.. [3] T. Hastie, R. Tibshirani and J. Friedman. "Elements of Statistical\nLearning", Springer, 2009.\n.. [4] L. Breiman, and A. Cutler, "Random Forests",\nhttps://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\nExamples\n-------\n>>> from sklearn.datasets import load_diabetes\n>>> from sklearn.model_selection import cross_val_score\n>>> from sklearn.tree import DecisionTreeRegressor\n>>> X, y = load_diabetes(return_X_y=True)\n>>> regressor = DecisionTreeRegressor(random_state=0)\n>>> cross_val_score(regressor, X, y, cv=10)\n...\n# doctest: +SKIP\n...\narray([-0.39..., -0.46..., 0.02..., 0.06..., -0.50...,\n0.16..., 0.11..., -0.73..., -0.30..., -0.00...])\nFile:\ns.py\nType:\nSubclasses:\n~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classe\nABCMeta\nExtraTreeRegressor\nLesson 8.2\ncriterioncriterionCART\nCARTmsemae\nfriedman_msesklearnpoisson\n\ncriterion=\'mse\'\ncriterionmse\n\nMSE\n1\n\nMSE\n\nmin_impurity_decrease\nCARTMSE\n'}
11:39:49,7 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:39:49,59 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:49,60 openai._base_client INFO Retrying request to /chat/completions in 5.494000 seconds
11:39:55,372 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
11:39:55,375 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'prompt': 'MANY entities and relationships were missed in the last extraction. Remember to ONLY emit entities that match any of the previously extracted types. Add them below using the same format:\n', 'kwargs': {'history': [{'content': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: One of the following types: [organization,person,geo,event]\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nEntity_types: ORGANIZATION,PERSON\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nEntity_types: ORGANIZATION\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nEntity_types: ORGANIZATION,GEO,PERSON\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n\n######################\n-Real Data-\n######################\nEntity_types: organization,person,geo,event\nText: :`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for potential splits,\nand "mae" for the mean absolute error, which minimizes the L1 loss\nusing the median of each terminal node.\n.. versionadded:: 0.18\nMean Absolute Error (MAE) criterion.\nsplitter : {"best", "random"}, default="best"\nThe strategy used to choose the split at each node. Supported\nstrategies are "best" to choose the best split and "random" to choose\nthe best random split.\nmax_depth : int, default=None\nThe maximum depth of the tree. If None, then nodes are expanded until\nall leaves are pure or until all leaves contain less than\nmin_samples_split samples.\nmin_samples_split : int or float, default=2\nThe minimum number of samples required to split an internal node:\n- If int, then consider `min_samples_split` as the minimum number.\n- If float, then `min_samples_split` is a fraction and\n`ceil(min_samples_split * n_samples)` are the minimum\nnumber of samples for each split.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_samples_leaf : int or float, default=1\nThe minimum number of samples required to be at a leaf node.\nA split point at any depth will only be considered if it leaves at\n\nleast ``min_samples_leaf`` training samples in each of the left and\nright branches. This may have the effect of smoothing the model,\nespecially in regression.\n- If int, then consider `min_samples_leaf` as the minimum number.\n- If float, then `min_samples_leaf` is a fraction and\n`ceil(min_samples_leaf * n_samples)` are the minimum\nnumber of samples for each node.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_weight_fraction_leaf : float, default=0.0\nThe minimum weighted fraction of the sum total of weights (of all\nthe input samples) required to be at a leaf node. Samples have\nequal weight when sample_weight is not provided.\nmax_features : int, float or {"auto", "sqrt", "log2"}, default=None\nThe number of features to consider when looking for the best split:\n- If int, then consider `max_features` features at each split.\n- If float, then `max_features` is a fraction and\n`int(max_features * n_features)` features are considered at each\nsplit.\n- If "auto", then `max_features=n_features`.\n- If "sqrt", then `max_features=sqrt(n_features)`.\n- If "log2", then `max_features=log2(n_features)`.\n- If None, then `max_features=n_features`.\nNote: the search for a split does not stop until at least one\nvalid partition of the node samples is found, even if it requires to\neffectively inspect more than ``max_features`` features.\nrandom_state : int, RandomState instance, default=None\nControls the randomness of the estimator. The features are always\nrandomly permuted at each split, even if ``splitter`` is set to\n``"best"``. When ``max_features < n_features``, the algorithm will\nselect ``max_features`` at random at each split before finding the best\nsplit among them. But the best found split may vary across different\nruns, even if ``max_features=n_features``. That is the case, if the\nimprovement of the criterion is identical for several splits and one\nsplit has to be selected at random. To obtain a deterministic behaviour\nduring fitting, ``random_state`` has to be fixed to an integer.\nSee :term:`Glossary <random_state>` for details.\nmax_leaf_nodes : int, default=None\nGrow a tree with ``max_leaf_nodes`` in best-first fashion.\nBest nodes are defined as relative reduction in impurity.\nIf None then unlimited number of leaf nodes.\nmin_impurity_decrease : float, default=0.0\nA node will be split if this split induces a decrease of the impurity\ngreater than or equal to this value.\nThe weighted impurity decrease equation is the following::\nN_t / N * (impurity - N_t_R / N_t * right_impurity\n- N_t_L / N_t * left_impurity)\nwhere ``N`` is the total number of samples, ``N_t`` is the number of\n\nsamples at the current node, ``N_t_L`` is the number of samples in the\nleft child, and ``N_t_R`` is the number of samples in the right child.\n``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\nmin_impurity_split : float, (default=0)\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead\n######################\nOutput:', 'role': 'user'}, {'role': 'assistant', 'content': '("entity"<|>MSE<|>EVENT<|>Mean Squared Error (MSE) is a criterion for measuring the quality of a split in decision trees, focusing on minimizing the L2 loss by using the mean of each terminal node)\n##\n("entity"<|>FRIEDMAN_MSE<|>EVENT<|>Friedman MSE uses mean squared error with Friedman\'s improvement score for potential splits in decision trees)\n##\n("entity"<|>MAE<|>EVENT<|>Mean Absolute Error (MAE) is a criterion that minimizes the L1 loss using the median of each terminal node in decision trees)\n##\n("entity"<|>BEST<|>EVENT<|>A strategy used in decision trees to choose the best split at each node)\n##\n("entity"<|>RANDOM<|>EVENT<|>A strategy used in decision trees to choose a split randomly at each node)\n##\n("entity"<|>RANDOM_STATE<|>EVENT<|>Controls the randomness of the estimator in decision trees, affecting feature permutation and split selection)\n##\n("relationship"<|>MSE<|>MAE<|>Both MSE and MAE are criteria used to measure the quality of a split in decision trees, but they focus on minimizing different types of loss<|>5)\n##\n("relationship"<|>BEST<|>RANDOM<|>Both are strategies used to choose the split at each node in decision trees, but they follow different approaches<|>5)\n##\n("relationship"<|>RANDOM_STATE<|>BEST<|>Random state controls the randomness in the \'best\' strategy by affecting feature permutation and split selection<|>4)\n##\n("relationship"<|>RANDOM_STATE<|>RANDOM<|>Random state also influences the \'random\' strategy by determining how features and splits are selected randomly<|>4)\n<|COMPLETE|>'}], 'name': 'extract-continuation-0'}}
11:39:55,375 graphrag.index.operations.extract_graph.graph_extractor ERROR error extracting graph
Traceback (most recent call last):
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/index/operations/extract_graph/graph_extractor.py", line 158, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 84, in achat
    response = await self.model(prompt, history=history, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/json.py", line 78, in invoke
    return await delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 137, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 166, in _execute_llm
    raw_response = await self._client.chat.completions.with_raw_response.create(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/bytedance/ai-bootcamp/mcp-graphrag/.venv/lib/python3.12/site-packages/openai/_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-turbo-preview in organization org-wY1yr4zVlHgYvUtkOAocC076 on tokens per min (TPM): Limit 30000, Used 26861, Requested 3274. Please try again in 270ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
11:39:55,377 graphrag.callbacks.file_workflow_callbacks INFO Entity Extraction Error details={'doc_index': 0, 'text': ':`User Guide <tree>`.\nParameters\n---------\ncriterion : {"mse", "friedman_mse", "mae"}, default="mse"\nThe function to measure the quality of a split. Supported criteria\nare "mse" for the mean squared error, which is equal to variance\nreduction as feature selection criterion and minimizes the L2 loss\nusing the mean of each terminal node, "friedman_mse", which uses mean\nsquared error with Friedman\'s improvement score for potential splits,\nand "mae" for the mean absolute error, which minimizes the L1 loss\nusing the median of each terminal node.\n.. versionadded:: 0.18\nMean Absolute Error (MAE) criterion.\nsplitter : {"best", "random"}, default="best"\nThe strategy used to choose the split at each node. Supported\nstrategies are "best" to choose the best split and "random" to choose\nthe best random split.\nmax_depth : int, default=None\nThe maximum depth of the tree. If None, then nodes are expanded until\nall leaves are pure or until all leaves contain less than\nmin_samples_split samples.\nmin_samples_split : int or float, default=2\nThe minimum number of samples required to split an internal node:\n- If int, then consider `min_samples_split` as the minimum number.\n- If float, then `min_samples_split` is a fraction and\n`ceil(min_samples_split * n_samples)` are the minimum\nnumber of samples for each split.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_samples_leaf : int or float, default=1\nThe minimum number of samples required to be at a leaf node.\nA split point at any depth will only be considered if it leaves at\n\nleast ``min_samples_leaf`` training samples in each of the left and\nright branches. This may have the effect of smoothing the model,\nespecially in regression.\n- If int, then consider `min_samples_leaf` as the minimum number.\n- If float, then `min_samples_leaf` is a fraction and\n`ceil(min_samples_leaf * n_samples)` are the minimum\nnumber of samples for each node.\n.. versionchanged:: 0.18\nAdded float values for fractions.\nmin_weight_fraction_leaf : float, default=0.0\nThe minimum weighted fraction of the sum total of weights (of all\nthe input samples) required to be at a leaf node. Samples have\nequal weight when sample_weight is not provided.\nmax_features : int, float or {"auto", "sqrt", "log2"}, default=None\nThe number of features to consider when looking for the best split:\n- If int, then consider `max_features` features at each split.\n- If float, then `max_features` is a fraction and\n`int(max_features * n_features)` features are considered at each\nsplit.\n- If "auto", then `max_features=n_features`.\n- If "sqrt", then `max_features=sqrt(n_features)`.\n- If "log2", then `max_features=log2(n_features)`.\n- If None, then `max_features=n_features`.\nNote: the search for a split does not stop until at least one\nvalid partition of the node samples is found, even if it requires to\neffectively inspect more than ``max_features`` features.\nrandom_state : int, RandomState instance, default=None\nControls the randomness of the estimator. The features are always\nrandomly permuted at each split, even if ``splitter`` is set to\n``"best"``. When ``max_features < n_features``, the algorithm will\nselect ``max_features`` at random at each split before finding the best\nsplit among them. But the best found split may vary across different\nruns, even if ``max_features=n_features``. That is the case, if the\nimprovement of the criterion is identical for several splits and one\nsplit has to be selected at random. To obtain a deterministic behaviour\nduring fitting, ``random_state`` has to be fixed to an integer.\nSee :term:`Glossary <random_state>` for details.\nmax_leaf_nodes : int, default=None\nGrow a tree with ``max_leaf_nodes`` in best-first fashion.\nBest nodes are defined as relative reduction in impurity.\nIf None then unlimited number of leaf nodes.\nmin_impurity_decrease : float, default=0.0\nA node will be split if this split induces a decrease of the impurity\ngreater than or equal to this value.\nThe weighted impurity decrease equation is the following::\nN_t / N * (impurity - N_t_R / N_t * right_impurity\n- N_t_L / N_t * left_impurity)\nwhere ``N`` is the total number of samples, ``N_t`` is the number of\n\nsamples at the current node, ``N_t_L`` is the number of samples in the\nleft child, and ``N_t_R`` is the number of samples in the right child.\n``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\nif ``sample_weight`` is passed.\n.. versionadded:: 0.19\nmin_impurity_split : float, (default=0)\nThreshold for early stopping in tree growth. A node will split\nif its impurity is above the threshold, otherwise it is a leaf.\n.. deprecated:: 0.19\n``min_impurity_split`` has been deprecated in favor of\n``min_impurity_decrease`` in 0.19. The default value of\n``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it\nwill be removed in 0.25. Use ``min_impurity_decrease`` instead'}
11:40:03,658 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:08,817 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:08,829 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:10,235 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:10,429 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:11,834 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:12,20 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:13,216 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:14,142 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:15,485 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:23,890 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:27,116 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:27,174 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:40:27,180 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:40:27,224 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:40:27,226 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:40:27,255 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:40:27,257 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:40:27,259 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:40:27,291 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:40:27,292 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:40:27,294 graphrag.utils.storage INFO reading table from storage: communities.parquet
11:40:27,300 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 23
11:40:45,432 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:40:57,953 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:41:04,526 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:41:05,212 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:41:13,842 httpx INFO HTTP Request: POST https://ai.devtool.tech/proxy/v1/chat/completions "HTTP/1.1 200 OK"
11:41:13,903 graphrag.utils.storage INFO reading table from storage: documents.parquet
11:41:13,910 graphrag.utils.storage INFO reading table from storage: relationships.parquet
11:41:13,915 graphrag.utils.storage INFO reading table from storage: text_units.parquet
11:41:13,921 graphrag.utils.storage INFO reading table from storage: entities.parquet
11:41:13,929 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
11:41:13,936 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
11:41:13,936 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
11:41:14,200 graphrag.index.operations.embed_text.strategies.openai INFO embedding 52 inputs via 52 snippets using 4 batches. max_batch_size=16, batch_max_tokens=8191
11:41:15,329 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:41:16,705 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:41:16,844 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:41:17,28 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:41:17,755 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
11:41:17,759 graphrag.index.operations.embed_text.strategies.openai INFO embedding 5 inputs via 5 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
11:41:18,251 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:41:18,689 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
11:41:18,714 graphrag.index.operations.embed_text.strategies.openai INFO embedding 37 inputs via 37 snippets using 6 batches. max_batch_size=16, batch_max_tokens=8191
11:41:19,453 httpx INFO HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
11:41:19,933 graphrag.cli.index INFO All workflows completed successfully.
